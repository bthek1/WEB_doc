{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Gradio\n",
    "output-file: gradio.html\n",
    "skip_exec: true\n",
    "skip_showdoc: true\n",
    "title: Gradio\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b58fda-cf9a-4703-978f-02168c08d772",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradio                              4.27.0\n",
      "gradio_client                       0.15.1\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eb823f-d3b9-46b6-82a6-f6ffb765aafe",
   "metadata": {},
   "source": [
    "## Basic Interface: text, slider -> text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7edc947-6a1e-480e-ac1c-4f9b11a976cf",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def greet(name, intensity):\n",
    "    return \"Hello, \" + name + \"!\" * int(intensity)\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=greet,\n",
    "    inputs=[\"text\", \"slider\"],\n",
    "    outputs=[\"text\"],\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce7e180-c4a7-4be5-ac32-f014cdf27330",
   "metadata": {},
   "source": [
    "```python\n",
    "gr.Interface(\n",
    "    fn: 'Callable',\n",
    "    inputs: 'str | Component | list[str | Component] | None',\n",
    "    outputs: 'str | Component | list[str | Component] | None',\n",
    "    examples: 'list[Any] | list[list[Any]] | str | None' = None,\n",
    "    cache_examples: \"bool | Literal['lazy'] | None\" = None,\n",
    "    examples_per_page: 'int' = 10,\n",
    "    live: 'bool' = False,\n",
    "    title: 'str | None' = None,\n",
    "    description: 'str | None' = None,\n",
    "    article: 'str | None' = None,\n",
    "    thumbnail: 'str | None' = None,\n",
    "    theme: 'Theme | str | None' = None,\n",
    "    css: 'str | None' = None,\n",
    "    allow_flagging: \"Literal['never'] | Literal['auto'] | Literal['manual'] | None\" = None,\n",
    "    flagging_options: 'list[str] | list[tuple[str, str]] | None' = None,\n",
    "    flagging_dir: 'str' = 'flagged',\n",
    "    flagging_callback: 'FlaggingCallback | None' = None,\n",
    "    analytics_enabled: 'bool | None' = None,\n",
    "    batch: 'bool' = False,\n",
    "    max_batch_size: 'int' = 4,\n",
    "    api_name: 'str | Literal[False] | None' = 'predict',\n",
    "    _api_mode: 'bool' = False,\n",
    "    allow_duplication: 'bool' = False,\n",
    "    concurrency_limit: \"int | None | Literal['default']\" = 'default',\n",
    "    js: 'str | None' = None,\n",
    "    head: 'str | None' = None,\n",
    "    additional_inputs: 'str | Component | list[str | Component] | None' = None,\n",
    "    additional_inputs_accordion: 'str | Accordion | None' = None,\n",
    "    *,\n",
    "    submit_btn: 'str | Button' = 'Submit',\n",
    "    stop_btn: 'str | Button' = 'Stop',\n",
    "    clear_btn: 'str | Button' = 'Clear',\n",
    "    delete_cache: 'tuple[int, int] | None' = None,\n",
    "    **kwargs,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4241a02-5e31-4c46-8997-c9850275f8e4",
   "metadata": {},
   "source": [
    "## Image output: slider -> image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc00fd8-5046-40ac-bd58-10e5b07ea38e",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def fake_diffusion(steps):\n",
    "    rng = np.random.default_rng()\n",
    "    for i in range(steps):\n",
    "        time.sleep(1)\n",
    "        image = rng.random(size=(600, 600, 3))\n",
    "        yield image\n",
    "    image = np.ones((1000,1000,3), np.uint8)\n",
    "    image[:] = [255, 124, 0]\n",
    "    yield image\n",
    "\n",
    "\n",
    "demo = gr.Interface(fake_diffusion,\n",
    "                    inputs=gr.Slider(1, 10, 3, step=1),\n",
    "                    outputs=\"image\")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c9410c-bbe6-4c0e-a0ba-01641bef4cbc",
   "metadata": {},
   "source": [
    "## Progress bar: text -> text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faea314-9564-4288-8109-eb4c577972ef",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import time\n",
    "\n",
    "def slowly_reverse(word, progress=gr.Progress()):\n",
    "    progress(0, desc=\"Starting\")\n",
    "    time.sleep(1)\n",
    "    progress(0.05)\n",
    "    new_string = \"\"\n",
    "    for letter in progress.tqdm(word, desc=\"Reversing\"):\n",
    "        time.sleep(0.25)\n",
    "        new_string = letter + new_string\n",
    "    return new_string\n",
    "\n",
    "demo = gr.Interface(slowly_reverse, gr.Text(), gr.Text())\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd995ef-967f-4f15-b6b8-eee8460155c9",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "secret_word = \"gradio\"\n",
    "\n",
    "with gr.Blocks() as demo:    \n",
    "    used_letters_var = gr.State([])\n",
    "    with gr.Row() as row:\n",
    "        with gr.Column():\n",
    "            input_letter = gr.Textbox(label=\"Enter letter\")\n",
    "            btn = gr.Button(\"Guess Letter\")\n",
    "        with gr.Column():\n",
    "            hangman = gr.Textbox(\n",
    "                label=\"Hangman\",\n",
    "                value=\"_\"*len(secret_word)\n",
    "            )\n",
    "            used_letters_box = gr.Textbox(label=\"Used Letters\")\n",
    "\n",
    "    def guess_letter(letter, used_letters):\n",
    "        used_letters.append(letter)\n",
    "        answer = \"\".join([\n",
    "            (letter if letter in used_letters else \"_\")\n",
    "            for letter in secret_word\n",
    "        ])\n",
    "        return {\n",
    "            used_letters_var: used_letters,\n",
    "            used_letters_box: \", \".join(used_letters),\n",
    "            hangman: answer\n",
    "        }\n",
    "    btn.click(\n",
    "        guess_letter, \n",
    "        [input_letter, used_letters_var],\n",
    "        [used_letters_var, used_letters_box, hangman]\n",
    "        )\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5c6568-46dd-4feb-afa0-3d19f76a0b77",
   "metadata": {},
   "source": [
    "## Audio: audio -> audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817c4c72-53ea-4f66-8fef-8cd27bfa4fe6",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7865\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/gradio/queueing.py\", line 527, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/gradio/route_utils.py\", line 261, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/gradio/blocks.py\", line 1784, in process_api\n",
      "    inputs = await self.preprocess_data(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/gradio/blocks.py\", line 1506, in preprocess_data\n",
      "    processed_input.append(block.preprocess(inputs_cached))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/gradio/components/audio.py\", line 231, in preprocess\n",
      "    processing_utils.audio_to_file(\n",
      "  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/gradio/processing_utils.py\", line 560, in audio_to_file\n",
      "    file = audio.export(filename, format=format)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/pydub/audio_segment.py\", line 970, in export\n",
      "    raise CouldntEncodeError(\n",
      "pydub.exceptions.CouldntEncodeError: Encoding failed. ffmpeg/avlib returned error code: 127\n",
      "\n",
      "Command:['ffmpeg', '-y', '-f', 'wav', '-i', '/tmp/tmplaiefr8j', '-f', 'mp3', '/tmp/tmpiojnrpsx']\n",
      "\n",
      "Output from ffmpeg/avlib:\n",
      "\n",
      "ffmpeg: error while loading shared libraries: libopenh264.so.5: cannot open shared object file: No such file or directory\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/gradio/queueing.py\", line 527, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/gradio/route_utils.py\", line 261, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/gradio/blocks.py\", line 1784, in process_api\n",
      "    inputs = await self.preprocess_data(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/gradio/blocks.py\", line 1506, in preprocess_data\n",
      "    processed_input.append(block.preprocess(inputs_cached))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/gradio/components/audio.py\", line 231, in preprocess\n",
      "    processing_utils.audio_to_file(\n",
      "  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/gradio/processing_utils.py\", line 560, in audio_to_file\n",
      "    file = audio.export(filename, format=format)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/pydub/audio_segment.py\", line 970, in export\n",
      "    raise CouldntEncodeError(\n",
      "pydub.exceptions.CouldntEncodeError: Encoding failed. ffmpeg/avlib returned error code: 127\n",
      "\n",
      "Command:['ffmpeg', '-y', '-f', 'wav', '-i', '/tmp/tmpuqq4b20d', '-f', 'mp3', '/tmp/tmphx041ptn']\n",
      "\n",
      "Output from ffmpeg/avlib:\n",
      "\n",
      "ffmpeg: error while loading shared libraries: libopenh264.so.5: cannot open shared object file: No such file or directory\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from pydub import AudioSegment\n",
    "from time import sleep\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    input_audio = gr.Audio(label=\"Input Audio\", type=\"filepath\", format=\"mp3\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            stream_as_file_btn = gr.Button(\"Stream as File\")\n",
    "            format = gr.Radio([\"wav\", \"mp3\"], value=\"wav\", label=\"Format\")\n",
    "            stream_as_file_output = gr.Audio(streaming=True)\n",
    "\n",
    "            def stream_file(audio_file, format):\n",
    "                audio = AudioSegment.from_file(audio_file)\n",
    "                i = 0\n",
    "                chunk_size = 1000\n",
    "                while chunk_size * i < len(audio):\n",
    "                    chunk = audio[chunk_size * i : chunk_size * (i + 1)]\n",
    "                    i += 1\n",
    "                    if chunk:\n",
    "                        file = f\"/tmp/{i}.{format}\"\n",
    "                        chunk.export(file, format=format)\n",
    "                        yield file\n",
    "                        sleep(0.5)\n",
    "\n",
    "            stream_as_file_btn.click(\n",
    "                stream_file, [input_audio, format], stream_as_file_output\n",
    "            )\n",
    "\n",
    "            gr.Examples(\n",
    "                [[\"audio/cantina.wav\", \"wav\"], [\"audio/cantina.wav\", \"mp3\"]],\n",
    "                [input_audio, format],\n",
    "                fn=stream_file,\n",
    "                outputs=stream_as_file_output,\n",
    "            )\n",
    "\n",
    "        with gr.Column():\n",
    "            stream_as_bytes_btn = gr.Button(\"Stream as Bytes\")\n",
    "            stream_as_bytes_output = gr.Audio(format=\"bytes\", streaming=True)\n",
    "\n",
    "            def stream_bytes(audio_file):\n",
    "                chunk_size = 20_000\n",
    "                with open(audio_file, \"rb\") as f:\n",
    "                    while True:\n",
    "                        chunk = f.read(chunk_size)\n",
    "                        if chunk:\n",
    "                            yield chunk\n",
    "                            sleep(1)\n",
    "                        else:\n",
    "                            break\n",
    "            stream_as_bytes_btn.click(stream_bytes, input_audio, stream_as_bytes_output)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.queue().launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98916ad-701c-4c81-b3f4-78e20675b34b",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/vision/zipball/v0.6.0\" to /home/ben/.cache/torch/hub/v0.6.0.zip\n",
      "/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749ef1c3-dd2e-46e1-9321-c9cc67daefe9",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# Download human-readable labels for ImageNet.\n",
    "response = requests.get(\"https://git.io/JJkYN\")\n",
    "labels = response.text.split(\"\\n\")\n",
    "\n",
    "def predict(inp):\n",
    "  inp = transforms.ToTensor()(inp).unsqueeze(0)\n",
    "  with torch.no_grad():\n",
    "    prediction = torch.nn.functional.softmax(model(inp)[0], dim=0)\n",
    "    confidences = {labels[i]: float(prediction[i]) for i in range(1000)}\n",
    "  return confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3788d3-62ad-40d3-83e1-5d9c02ce85c6",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7869\n",
      "\n",
      "Thanks for being a Gradio user! If you have questions or feedback, please join our Discord server and chat with us: https://discord.gg/feTf9x3ZSB\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7869/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/gradio/queueing.py\", line 527, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/gradio/route_utils.py\", line 261, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/gradio/blocks.py\", line 1788, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/gradio/blocks.py\", line 1340, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/gradio/utils.py\", line 759, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_145374/855710716.py\", line 10, in predict\n",
      "    inp = transforms.ToTensor()(inp).unsqueeze(0)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/torchvision/transforms/transforms.py\", line 137, in __call__\n",
      "    return F.to_tensor(pic)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/torchvision/transforms/functional.py\", line 140, in to_tensor\n",
      "    raise TypeError(f\"pic should be PIL Image or ndarray. Got {type(pic)}\")\n",
      "TypeError: pic should be PIL Image or ndarray. Got <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "gr.Interface(fn=predict,\n",
    "             inputs=gr.Image(type=\"pil\"),\n",
    "             outputs=gr.Label(num_top_classes=3),\n",
    "             examples=[\"tiger.jpg\", \"cheetah.jpg\"]).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67f4a12-9e1e-478c-9193-655103de431c",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
