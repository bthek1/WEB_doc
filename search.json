[
  {
    "objectID": "github.html",
    "href": "github.html",
    "title": "Github",
    "section": "",
    "text": "ssh-keygen -t ed25519 -C \"your_email@example.com\"\n\n\n\neval \"$(ssh-agent -s)\"\nssh-add ~/.ssh/id_ed25519\n\n\n\n\n\n\nssh -T git@github.com",
    "crumbs": [
      "Blog",
      "Github"
    ]
  },
  {
    "objectID": "github.html#inital-connection",
    "href": "github.html#inital-connection",
    "title": "Github",
    "section": "",
    "text": "ssh-keygen -t ed25519 -C \"your_email@example.com\"\n\n\n\neval \"$(ssh-agent -s)\"\nssh-add ~/.ssh/id_ed25519\n\n\n\n\n\n\nssh -T git@github.com",
    "crumbs": [
      "Blog",
      "Github"
    ]
  },
  {
    "objectID": "github.html#automation",
    "href": "github.html#automation",
    "title": "Github",
    "section": "Automation",
    "text": "Automation\n\nQuickstart\nFor GitHub to discover any GitHub Actions workflows in your repository, you must save the workflow files in a directory called .github/workflows.\nYou can give the workflow file any name you like, but you must use .yml or .yaml as the file name extension. YAML is a markup language that‚Äôs commonly used for configuration files.\nCreate .github/workflows/actions.yml\nname: GitHub Actions Demo\nrun-name: ${{ github.actor }} is testing out GitHub Actions üöÄ\non: [push]\njobs:\n  Explore-GitHub-Actions:\n    runs-on: ubuntu-latest\n    steps:\n      - run: echo \"üéâ The job was automatically triggered by a ${{ github.event_name }} event.\"\n      - run: echo \"üêß This job is now running on a ${{ runner.os }} server hosted by GitHub!\"\n      - run: echo \"üîé The name of your branch is ${{ github.ref }} and your repository is ${{ github.repository }}.\"\n      - name: Check out repository code\n        uses: actions/checkout@v4\n      - run: echo \"üí° The ${{ github.repository }} repository has been cloned to the runner.\"\n      - run: echo \"üñ•Ô∏è The workflow is now ready to test your code on the runner.\"\n      - name: List files in the repository\n        run: |\n          ls ${{ github.workspace }}\n      - run: echo \"üçè This job's status is ${{ job.status }}.\"\n\n\nOverview\nGitHub Actions is a continuous integration and continuous delivery (CI/CD) platform that allows you to automate your build, test, and deployment pipeline. You can create workflows that build and test every pull request to your repository, or deploy merged pull requests to production.\nGitHub Actions goes beyond just DevOps and lets you run workflows when other events happen in your repository. For example, you can run a workflow to automatically add the appropriate labels whenever someone creates a new issue in your repository.\nGitHub provides Linux, Windows, and macOS virtual machines to run your workflows, or you can host your own self-hosted runners in your own data center or cloud infrastructure.\n\n\nEvents\n\nAn event is a specific activity in a repository that triggers a workflow run. For example, an activity can originate from GitHub when someone creates a pull request, opens an issue, or pushes a commit to a repository. You can also trigger a workflow to run on a schedule, by posting to a REST API, or manually.\n\n\n\nJobs\n\nA workflow run is made up of one or more jobs, which run in parallel by default. To run jobs sequentially, you can define dependencies on other jobs using the jobs..needs keyword.\n\njobs:\n  my_first_job:\n    name: My first job\n  my_second_job:\n    name: My second job\n\n\nActions\nAn action is a custom application for the GitHub Actions platform that performs a complex but frequently repeated task. Use an action to help reduce the amount of repetitive code that you write in your workflow files. An action can pull your git repository from GitHub, set up the correct toolchain for your build environment, or set up the authentication to your cloud provider.\n\n\nRunners\nA runner is a server that runs your workflows when they‚Äôre triggered. Each runner can run a single job at a time.\n# Optional - The name of the workflow as it will appear in the \"Actions\" tab of the GitHub repository. If this field is omitted, the name of the workflow file will be used instead.\nname: learn-github-actions\n\n# Optional - The name for workflow runs generated from the workflow, which will appear in the list of workflow runs on your repository's \"Actions\" tab. This example uses an expression with the `github` context to display the username of the actor that triggered the workflow run. For more information, see \"[AUTOTITLE](/actions/using-workflows/workflow-syntax-for-github-actions#run-name).\"\nrun-name: ${{ github.actor }} is learning GitHub Actions\n\n# Specifies the trigger for this workflow. This example uses the `push` event, so a workflow run is triggered every time someone pushes a change to the repository or merges a pull request.  This is triggered by a push to every branch; for examples of syntax that runs only on pushes to specific branches, paths, or tags, see \"[AUTOTITLE](/actions/reference/workflow-syntax-for-github-actions#onpushpull_requestpull_request_targetpathspaths-ignore).\"\non: [push]\n\n# Groups together all the jobs that run in the `learn-github-actions` workflow.\njobs:\n\n# Defines a job named `check-bats-version`. The child keys will define properties of the job.\n  check-bats-version:\n\n# Configures the job to run on the latest version of an Ubuntu Linux runner. This means that the job will execute on a fresh virtual machine hosted by GitHub. For syntax examples using other runners, see \"[AUTOTITLE](/actions/reference/workflow-syntax-for-github-actions#jobsjob_idruns-on)\"\n    runs-on: ubuntu-latest\n\n# Groups together all the steps that run in the `check-bats-version` job. Each item nested under this section is a separate action or shell script.\n    steps:\n\n# The `uses` keyword specifies that this step will run `v4` of the `actions/checkout` action. This is an action that checks out your repository onto the runner, allowing you to run scripts or other actions against your code (such as build and test tools). You should use the checkout action any time your workflow will use the repository's code.\n      - uses: actions/checkout@v4\n\n# This step uses the `actions/setup-node@v4` action to install the specified version of the Node.js. (This example uses version 20.) This puts both the `node` and `npm` commands in your `PATH`.\n      - uses: actions/setup-node@v4\n        with:\n          node-version: '20'\n\n# The `run` keyword tells the job to execute a command on the runner. In this case, you are using `npm` to install the `bats` software testing package.\n      - run: npm install -g bats\n\n# Finally, you'll run the `bats` command with a parameter that outputs the software version.\n      - run: bats -v\n\n!cat ../.github/workflows/deploy.yaml\n\nname: Deploy to GitHub Pages\n\npermissions:\n  contents: write\n  pages: write\n\non:\n  push:\n    branches: [ \"main\", \"master\" ]\n  workflow_dispatch:\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps: [uses: fastai/workflows/quarto-ghp@master]\n\n\n\n!cat ../.github/workflows/test.yaml\n\nname: CI\non:  [workflow_dispatch, pull_request, push]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps: [uses: fastai/workflows/nbdev-ci@master]",
    "crumbs": [
      "Blog",
      "Github"
    ]
  },
  {
    "objectID": "github.html#cli",
    "href": "github.html#cli",
    "title": "Github",
    "section": "CLI",
    "text": "CLI\n\n!gh\n\nWork seamlessly with GitHub from the command line.\n\nUSAGE\n  gh &lt;command&gt; &lt;subcommand&gt; [flags]\n\nCORE COMMANDS\n  auth:        Authenticate gh and git with GitHub\n  browse:      Open the repository in the browser\n  codespace:   Connect to and manage codespaces\n  gist:        Manage gists\n  issue:       Manage issues\n  org:         Manage organizations\n  pr:          Manage pull requests\n  project:     Work with GitHub Projects.\n  release:     Manage releases\n  repo:        Manage repositories\n\nGITHUB ACTIONS COMMANDS\n  cache:       Manage GitHub Actions caches\n  run:         View details about workflow runs\n  workflow:    View details about GitHub Actions workflows\n\nALIAS COMMANDS\n  co:          Alias for \"pr checkout\"\n\nADDITIONAL COMMANDS\n  alias:       Create command shortcuts\n  api:         Make an authenticated GitHub API request\n  attestation: Work with artifact attestations\n  completion:  Generate shell completion scripts\n  config:      Manage configuration for gh\n  extension:   Manage gh extensions\n  gpg-key:     Manage GPG keys\n  label:       Manage labels\n  ruleset:     View info about repo rulesets\n  search:      Search for repositories, issues, and pull requests\n  secret:      Manage GitHub secrets\n  ssh-key:     Manage SSH keys\n  status:      Print information about relevant issues, pull requests, and notifications across repositories\n  variable:    Manage GitHub Actions variables\n\nHELP TOPICS\n  actions:     Learn about working with GitHub Actions\n  environment: Environment variables that can be used with gh\n  exit-codes:  Exit codes used by gh\n  formatting:  Formatting options for JSON data exported from gh\n  mintty:      Information about using gh with MinTTY\n  reference:   A comprehensive reference of all gh commands\n\nFLAGS\n  --help      Show help for command\n  --version   Show gh version\n\nEXAMPLES\n  $ gh issue create\n  $ gh repo clone cli/cli\n  $ gh pr checkout 321\n\nLEARN MORE\n  Use `gh &lt;command&gt; &lt;subcommand&gt; --help` for more information about a command.\n  Read the manual at https://cli.github.com/manual\n\n\n\n\nAuthentication\n\nOnly if needed\n\n\n!gh auth\n\nAuthenticate gh and git with GitHub\n\nUSAGE\n  gh auth &lt;command&gt; [flags]\n\nAVAILABLE COMMANDS\n  login:       Log in to a GitHub account\n  logout:      Log out of a GitHub account\n  refresh:     Refresh stored authentication credentials\n  setup-git:   Setup git with GitHub CLI\n  status:      Display active account and authentication state on each known GitHub host\n  switch:      Switch active GitHub account\n  token:       Print the authentication token gh uses for a hostname and account\n\nINHERITED FLAGS\n  --help   Show help for command\n\nLEARN MORE\n  Use `gh &lt;command&gt; &lt;subcommand&gt; --help` for more information about a command.\n  Read the manual at https://cli.github.com/manual\n\n\n\n\nUseful commands\n\ngh auth login\n\n!gh auth status\n\ngithub.com\n  ‚úì Logged in to github.com account bthek1 (GITHUB_TOKEN)\n  - Active account: true\n  - Git operations protocol: https\n  - Token: ghp_************************************\n  - Token scopes: 'admin:enterprise', 'admin:gpg_key', 'admin:org', 'admin:org_hook', 'admin:public_key', 'admin:repo_hook', 'admin:ssh_signing_key', 'audit_log', 'codespace', 'copilot', 'delete:packages', 'delete_repo', 'gist', 'notifications', 'project', 'repo', 'user', 'workflow', 'write:discussion', 'write:packages'\n\n\n\n\nAlias\n\n!gh help alias set\n\nDefine a word that will expand to a full gh command when invoked.\n\nThe expansion may specify additional arguments and flags. If the expansion includes\npositional placeholders such as `$1`, extra arguments that follow the alias will be\ninserted appropriately. Otherwise, extra arguments will be appended to the expanded\ncommand.\n\nUse `-` as expansion argument to read the expansion string from standard input. This\nis useful to avoid quoting issues when defining expansions.\n\nIf the expansion starts with `!` or if `--shell` was given, the expansion is a shell\nexpression that will be evaluated through the `sh` interpreter when the alias is\ninvoked. This allows for chaining multiple commands via piping and redirection.\n\n\nUSAGE\n  gh alias set &lt;alias&gt; &lt;expansion&gt; [flags]\n\nFLAGS\n      --clobber   Overwrite existing aliases of the same name\n  -s, --shell     Declare an alias to be passed through a shell interpreter\n\nINHERITED FLAGS\n  --help   Show help for command\n\nEXAMPLES\n  # note: Command Prompt on Windows requires using double quotes for arguments\n  $ gh alias set pv 'pr view'\n  $ gh pv -w 123  #=&gt; gh pr view -w 123\n  \n  $ gh alias set bugs 'issue list --label=bugs'\n  $ gh bugs\n  \n  $ gh alias set homework 'issue list --assignee @me'\n  $ gh homework\n  \n  $ gh alias set 'issue mine' 'issue list --mention @me'\n  $ gh issue mine\n  \n  $ gh alias set epicsBy 'issue list --author=\"$1\" --label=\"epic\"'\n  $ gh epicsBy vilmibm  #=&gt; gh issue list --author=\"vilmibm\" --label=\"epic\"\n  \n  $ gh alias set --shell igrep 'gh issue list --label=\"$1\" | grep \"$2\"'\n  $ gh igrep epic foo  #=&gt; gh issue list --label=\"epic\" | grep \"foo\"\n\nLEARN MORE\n  Use `gh &lt;command&gt; &lt;subcommand&gt; --help` for more information about a command.\n  Read the manual at https://cli.github.com/manual\n\n\n\n\n!gh alias list\n\nco: pr checkout\n\n\n\n\nRepos\n\n!gh repo\n\nWork with GitHub repositories.\n\nUSAGE\n  gh repo &lt;command&gt; [flags]\n\nGENERAL COMMANDS\n  create:      Create a new repository\n  list:        List repositories owned by user or organization\n\nTARGETED COMMANDS\n  archive:     Archive a repository\n  clone:       Clone a repository locally\n  delete:      Delete a repository\n  deploy-key:  Manage deploy keys in a repository\n  edit:        Edit repository settings\n  fork:        Create a fork of a repository\n  rename:      Rename a repository\n  set-default: Configure default repository for this directory\n  sync:        Sync a repository\n  unarchive:   Unarchive a repository\n  view:        View a repository\n\nINHERITED FLAGS\n  --help   Show help for command\n\nARGUMENTS\n  A repository can be supplied as an argument in any of the following formats:\n  - \"OWNER/REPO\"\n  - by URL, e.g. \"https://github.com/OWNER/REPO\"\n\nEXAMPLES\n  $ gh repo create\n  $ gh repo clone cli/cli\n  $ gh repo view --web\n\nLEARN MORE\n  Use `gh &lt;command&gt; &lt;subcommand&gt; --help` for more information about a command.\n  Read the manual at https://cli.github.com/manual\n\n\n\n\nCreating a Repository\ngh repo create my-new-repo\n\nExample\n\ngh repo create test_gh --public --add-readme --description \"Github CLI Testing\"\n\n\nList Repos\n\n!gh repo list -L 10\n\n\nShowing 10 of 47 repositories in @bthek1\n\nNAME                   DESCRIPTION              INFO          UPDATED           \nbthek1/WEB_doc         webdevelopment_doc       public        about 16 hours ago\nbthek1/githubAuto      Testing github Autom...  public        about 17 hours ago\nbthek1/keybr.com       The smartest way to ...  public, fork  about 18 hours ago\nbthek1/Dotfiles        Dotfiles                 private       about 18 hours ago\nbthek1/Business_doc                             private       about 21 hours ago\nbthek1/DL_methods      Deep Learning models...  public        about 1 day ago\nbthek1/Python_Libs     Usefull libraries fo...  public        about 2 days ago\nbthek1/Resume          latex resume             private       about 2 days ago\nbthek1/Philosophy_doc                           private       about 2 days ago\nbthek1/B_Blog          Personal Blog            public        about 2 days ago\n\n\n\n\nDelete a Repo\ngh repo delete &lt;name&gt;\n\n!gh repo deploy-key list\n\nno deploy keys found in bthek1/WEB_doc\n\n\n\n\n\nRelease\n\n!gh release\n\nManage releases\n\nUSAGE\n  gh release &lt;command&gt; [flags]\n\nGENERAL COMMANDS\n  create:      Create a new release\n  list:        List releases in a repository\n\nTARGETED COMMANDS\n  delete:      Delete a release\n  delete-asset: Delete an asset from a release\n  download:    Download release assets\n  edit:        Edit a release\n  upload:      Upload assets to a release\n  view:        View information about a release\n\nFLAGS\n  -R, --repo [HOST/]OWNER/REPO   Select another repository using the [HOST/]OWNER/REPO format\n\nINHERITED FLAGS\n  --help   Show help for command\n\nLEARN MORE\n  Use `gh &lt;command&gt; &lt;subcommand&gt; --help` for more information about a command.\n  Read the manual at https://cli.github.com/manual\n\n\n\n\nCreate Release\ngh repo create\n\n\nList Releases\n\n!gh release list\n\nTITLE               TYPE         TAG NAME      PUBLISHED          \ntest_release_title  Pre-release  test_release  about 6 minutes ago\n\n\n\n\nView Release\ngh release view [&lt;tag&gt;] [flags]\n\n!gh release view test_release\n\n11;?test_release\nPre-release ‚Ä¢ bthek1 released this about 7 minutes ago\n\n  test release notes                                                          \n\n\nView on GitHub: https://github.com/bthek1/WEB_doc/releases/tag/test_release\n\n\n\n\n\nCodespaces\n\n!gh codespace\n\nConnect to and manage codespaces\n\nUSAGE\n  gh codespace [flags]\n\nALIASES\n  gh cs\n\nAVAILABLE COMMANDS\n  code:        Open a codespace in Visual Studio Code\n  cp:          Copy files between local and remote file systems\n  create:      Create a codespace\n  delete:      Delete codespaces\n  edit:        Edit a codespace\n  jupyter:     Open a codespace in JupyterLab\n  list:        List codespaces\n  logs:        Access codespace logs\n  ports:       List ports in a codespace\n  rebuild:     Rebuild a codespace\n  ssh:         SSH into a codespace\n  stop:        Stop a running codespace\n  view:        View details about a codespace\n\nINHERITED FLAGS\n  --help   Show help for command\n\nLEARN MORE\n  Use `gh &lt;command&gt; &lt;subcommand&gt; --help` for more information about a command.\n  Read the manual at https://cli.github.com/manual\n\n\n\n\n\nExtensions\n\n!gh extension\n\nGitHub CLI extensions are repositories that provide additional gh commands.\n\nThe name of the extension repository must start with `gh-` and it must contain an\nexecutable of the same name. All arguments passed to the `gh &lt;extname&gt;` invocation\nwill be forwarded to the `gh-&lt;extname&gt;` executable of the extension.\n\nAn extension cannot override any of the core gh commands. If an extension name conflicts\nwith a core gh command, you can use `gh extension exec &lt;extname&gt;`.\n\nFor the list of available extensions, see &lt;https://github.com/topics/gh-extension&gt;.\n\n\nUSAGE\n  gh extension [flags]\n\nALIASES\n  gh extensions, gh ext\n\nAVAILABLE COMMANDS\n  browse:      Enter a UI for browsing, adding, and removing extensions\n  create:      Create a new extension\n  exec:        Execute an installed extension\n  install:     Install a gh extension from a repository\n  list:        List installed extension commands\n  remove:      Remove an installed extension\n  search:      Search extensions to the GitHub CLI\n  upgrade:     Upgrade installed extensions\n\nINHERITED FLAGS\n  --help   Show help for command\n\nLEARN MORE\n  Use `gh &lt;command&gt; &lt;subcommand&gt; --help` for more information about a command.\n  Read the manual at https://cli.github.com/manual\n\n\n\n\n!gh extension list\n\nno installed extensions found\n\n\n\n\ngpg-key\n\n!gh gpg-key\n\nManage GPG keys registered with your GitHub account.\n\nUSAGE\n  gh gpg-key &lt;command&gt; [flags]\n\nAVAILABLE COMMANDS\n  add:         Add a GPG key to your GitHub account\n  delete:      Delete a GPG key from your GitHub account\n  list:        Lists GPG keys in your GitHub account\n\nINHERITED FLAGS\n  --help   Show help for command\n\nLEARN MORE\n  Use `gh &lt;command&gt; &lt;subcommand&gt; --help` for more information about a command.\n  Read the manual at https://cli.github.com/manual\n\n\n\n\n\nLabel\n\n!gh label\n\nWork with GitHub labels.\n\nUSAGE\n  gh label &lt;command&gt; [flags]\n\nAVAILABLE COMMANDS\n  clone:       Clones labels from one repository to another\n  create:      Create a new label\n  delete:      Delete a label from a repository\n  edit:        Edit a label\n  list:        List labels in a repository\n\nFLAGS\n  -R, --repo [HOST/]OWNER/REPO   Select another repository using the [HOST/]OWNER/REPO format\n\nINHERITED FLAGS\n  --help   Show help for command\n\nLEARN MORE\n  Use `gh &lt;command&gt; &lt;subcommand&gt; --help` for more information about a command.\n  Read the manual at https://cli.github.com/manual\n\n\n\n\n!gh label list\n\n6m‚¢ø\nShowing 9 of 9 labels in bthek1/WEB_doc\n\nNAME              DESCRIPTION                                 COLOR  \nbug               Something isn't working                     #d73a4a\ndocumentation     Improvements or additions to documentation  #0075ca\nduplicate         This issue or pull request already exists   #cfd3d7\nenhancement       New feature or request                      #a2eeef\ngood first issue  Good for newcomers                          #7057ff\nhelp wanted       Extra attention is needed                   #008672\ninvalid           This doesn't seem right                     #e4e669\nquestion          Further information is requested            #d876e3\nwontfix           This will not be worked on                  #ffffff\n\n\n\n\nOrganisation\n\n!gh org\n\nWork with GitHub organizations.\n\nUSAGE\n  gh org &lt;command&gt; [flags]\n\nGENERAL COMMANDS\n  list:        List organizations for the authenticated user.\n\nINHERITED FLAGS\n  --help   Show help for command\n\nEXAMPLES\n  $ gh org list\n\nLEARN MORE\n  Use `gh &lt;command&gt; &lt;subcommand&gt; --help` for more information about a command.\n  Read the manual at https://cli.github.com/manual\n\n\n\n\n!gh org list\n\n\nShowing 2 of 2 organizations\n\nLaser-org\nRecovery-Mertics\n\n\n\n\nProjects\n\n!gh project\n\nWork with GitHub Projects. Note that the token you are using must have 'project' scope, which is not set by default. You can verify your token scope by running 'gh auth status' and add the project scope by running 'gh auth refresh -s project'.\n\nUSAGE\n  gh project &lt;command&gt; [flags]\n\nAVAILABLE COMMANDS\n  close:       Close a project\n  copy:        Copy a project\n  create:      Create a project\n  delete:      Delete a project\n  edit:        Edit a project\n  field-create: Create a field in a project\n  field-delete: Delete a field in a project\n  field-list:  List the fields in a project\n  item-add:    Add a pull request or an issue to a project\n  item-archive: Archive an item in a project\n  item-create: Create a draft issue item in a project\n  item-delete: Delete an item from a project by ID\n  item-edit:   Edit an item in a project\n  item-list:   List the items in a project\n  link:        Link a project to a repository or a team\n  list:        List the projects for an owner\n  mark-template: Mark a project as a template\n  unlink:      Unlink a project from a repository or a team\n  view:        View a project\n\nINHERITED FLAGS\n  --help   Show help for command\n\nEXAMPLES\n  $ gh project create --owner monalisa --title \"Roadmap\"\n  $ gh project view 1 --owner cli --web\n  $ gh project field-list 1 --owner cli\n  $ gh project item-list 1 --owner cli\n\nLEARN MORE\n  Use `gh &lt;command&gt; &lt;subcommand&gt; --help` for more information about a command.\n  Read the manual at https://cli.github.com/manual\n\n\n\n\n!gh project list\n\nNUMBER  TITLE     STATE  ID                  \n8       Schedule  open   PVT_kwHOBNe82M4AgAdx\n\n\n\n!gh project field-list 8 --owner \"@me\"\n\nNAME                  DATA TYPE                   ID                            \nTitle                 ProjectV2Field              PVTF_lAHOBNe82M4AgAdxzgVNpz0\nAssignees             ProjectV2Field              PVTF_lAHOBNe82M4AgAdxzgVNpz4\nStatus                ProjectV2SingleSelectField  PVTSSF_lAHOBNe82M4AgAdxzgVNpz8\nLabels                ProjectV2Field              PVTF_lAHOBNe82M4AgAdxzgVNp0A\nLinked pull requests  ProjectV2Field              PVTF_lAHOBNe82M4AgAdxzgVNp0E\nMilestone             ProjectV2Field              PVTF_lAHOBNe82M4AgAdxzgVNp0I\nRepository            ProjectV2Field              PVTF_lAHOBNe82M4AgAdxzgVNp0M\nReviewers             ProjectV2Field              PVTF_lAHOBNe82M4AgAdxzgVNp0Y\ndate                  ProjectV2Field              PVTF_lAHOBNe82M4AgAdxzgVNp0k\nend date              ProjectV2Field              PVTF_lAHOBNe82M4AgAdxzgVNp0o\nPriority              ProjectV2SingleSelectField  PVTSSF_lAHOBNe82M4AgAdxzgVNp0w\nDifficulty            ProjectV2SingleSelectField  PVTSSF_lAHOBNe82M4AgAdxzgVNp00\nIteration             ProjectV2IterationField     PVTIF_lAHOBNe82M4AgAdxzgVNxEY\n\n\n\n!gh project item-list 8 --owner \"@me\"\n\nTYPE   TITLE              NUMBER  REPOSITORY        ID                          \nIssue  state manageme...  12      bthek1/WEB_doc    PVTI_lAHOBNe82M4AgAdxzgOMt94\nIssue  provide link t...  22      bthek1/WEB_doc    PVTI_lAHOBNe82M4AgAdxzgOMuBI\nIssue  persisting use...  21      bthek1/WEB_doc    PVTI_lAHOBNe82M4AgAdxzgOMuBQ\nIssue  login via Goog...  20      bthek1/WEB_doc    PVTI_lAHOBNe82M4AgAdxzgOMuBU\nIssue  dynamic action...  19      bthek1/WEB_doc    PVTI_lAHOBNe82M4AgAdxzgOMuBY\nIssue  notifications ...  18      bthek1/WEB_doc    PVTI_lAHOBNe82M4AgAdxzgOMuBc\nIssue  login via phis...  17      bthek1/WEB_doc    PVTI_lAHOBNe82M4AgAdxzgOMuBg\nIssue  Django             7       bthek1/WEB_doc    PVTI_lAHOBNe82M4AgAdxzgOMuCE\nIssue  React              8       bthek1/WEB_doc    PVTI_lAHOBNe82M4AgAdxzgOMuB8\nIssue  Oracle: deploy...  6       bthek1/WEB_doc    PVTI_lAHOBNe82M4AgAdxzgOMuB0\nIssue  navigation (do...  14      bthek1/WEB_doc    PVTI_lAHOBNe82M4AgAdxzgOMuBs\nIssue  connecting to ...  13      bthek1/WEB_doc    PVTI_lAHOBNe82M4AgAdxzgOMuBw\nIssue  3D vision          11      bthek1/WEB_doc    PVTI_lAHOBNe82M4AgAdxzgOMuB4\nIssue  DRF                28      bthek1/WEB_doc    PVTI_lAHOBNe82M4AgAdxzgQf6rg\nIssue  DjangoX            29      bthek1/WEB_doc    PVTI_lAHOBNe82M4AgAdxzgQf9Lo\nIssue  nookal             30      bthek1/WEB_doc    PVTI_lAHOBNe82M4AgAdxzgQf9L8\nIssue  json serializa...  15      bthek1/WEB_doc    PVTI_lAHOBNe82M4AgAdxzgOMuBo\nIssue  displaying a c...  16      bthek1/WEB_doc    PVTI_lAHOBNe82M4AgAdxzgOMuBk\nIssue  Random forward...  2       bthek1/DL_met...  PVTI_lAHOBNe82M4AgAdxzgOMvTc\nIssue  github automation  26      bthek1/WEB_doc    PVTI_lAHOBNe82M4AgAdxzgOMx7c\nIssue  Image classifi...  18      bthek1/DL_met...  PVTI_lAHOBNe82M4AgAdxzgPE1cc\nIssue  Image mulit cl...  19      bthek1/DL_met...  PVTI_lAHOBNe82M4AgAdxzgPE1ew\nIssue  object detecti...  20      bthek1/DL_met...  PVTI_lAHOBNe82M4AgAdxzgPE1hk\nIssue  semantic segme...  21      bthek1/DL_met...  PVTI_lAHOBNe82M4AgAdxzgPE1zc\nIssue  instance segme...  22      bthek1/DL_met...  PVTI_lAHOBNe82M4AgAdxzgPE12c\nIssue  panoptic segme...  23      bthek1/DL_met...  PVTI_lAHOBNe82M4AgAdxzgPE18Y\nIssue  Ideas - model ...  24      bthek1/DL_met...  PVTI_lAHOBNe82M4AgAdxzgPE1-8\nIssue  ideas - image ...  25      bthek1/DL_met...  PVTI_lAHOBNe82M4AgAdxzgPE2BI\nIssue  random propaga...  26      bthek1/DL_met...  PVTI_lAHOBNe82M4AgAdxzgPE2Cg\nIssue  do one kaggle ...  27      bthek1/DL_met...  PVTI_lAHOBNe82M4AgAdxzgPE3BM\n\n\n\n\nIssue\n\n!gh issue\n\nWork with GitHub issues.\n\nUSAGE\n  gh issue &lt;command&gt; [flags]\n\nGENERAL COMMANDS\n  create:      Create a new issue\n  list:        List issues in a repository\n  status:      Show status of relevant issues\n\nTARGETED COMMANDS\n  close:       Close issue\n  comment:     Add a comment to an issue\n  delete:      Delete issue\n  develop:     Manage linked branches for an issue\n  edit:        Edit issues\n  lock:        Lock issue conversation\n  pin:         Pin a issue\n  reopen:      Reopen issue\n  transfer:    Transfer issue to another repository\n  unlock:      Unlock issue conversation\n  unpin:       Unpin a issue\n  view:        View an issue\n\nFLAGS\n  -R, --repo [HOST/]OWNER/REPO   Select another repository using the [HOST/]OWNER/REPO format\n\nINHERITED FLAGS\n  --help   Show help for command\n\nARGUMENTS\n  An issue can be supplied as argument in any of the following formats:\n  - by number, e.g. \"123\"; or\n  - by URL, e.g. \"https://github.com/OWNER/REPO/issues/123\".\n\nEXAMPLES\n  $ gh issue list\n  $ gh issue create --label bug\n  $ gh issue view 123 --web\n\nLEARN MORE\n  Use `gh &lt;command&gt; &lt;subcommand&gt; --help` for more information about a command.\n  Read the manual at https://cli.github.com/manual\n\n\n\n\n!gh issue list\n\n\nShowing 17 of 17 open issues in bthek1/WEB_doc\n\nID   TITLE                                            LABELS  UPDATED           \n#30  nookal                                                   about 11 days ago\n#29  DjangoX                                                  about 11 days ago\n#28  DRF                                                      about 11 days ago\n#22  provide link to external website (analytics....          about 4 months ago\n#21  persisting user settings (built-in?)                     about 4 months ago\n#20  login via Google (todo), done in Django, the...          about 4 months ago\n#19  dynamic actions in chart: e.g change time range          about 4 months ago\n#18  notifications (todo) - poll a REST API (todo...          about 4 months ago\n#17  login via phisaver REST API (done)                       about 4 months ago\n#16  displaying a chart - fl_chart (done)                     about 4 months ago\n#15  json serialization / deserialisation (done)              about 4 months ago\n#14  navigation (done), forget the name of framew...          about 4 months ago\n#13  connecting to a REST API (done)                          about 4 months ago\n#12  state management: riverpod (done)                        about 4 months ago\n#11  3D vision                                                about 6 months ago\n#8   React                                                    about 6 months ago\n#6   Oracle: deploy server website and server                 about 4 months ago\n\n\n\n!gh issue view 28\n\ngithub automation bthek1/WEB_doc#26\nOpen ‚Ä¢ bthek1 opened about 2 months ago ‚Ä¢ 0 comments\n\n\n  No description provided\n\n\nView this issue on GitHub: https://github.com/bthek1/WEB_doc/issues/26\n\n\n\n!gh issue edit 28 --add-label \"enhancement\"\n\nhttps://github.com/bthek1/WEB_doc/issues/265h\n\n\n\n!gh issue close 26\n\n! Issue bthek1/WEB_doc#26 (github automation) is already closed\n\n\n\n\nPull Request\n\n!gh pr\n\nWork with GitHub pull requests.\n\nUSAGE\n  gh pr &lt;command&gt; [flags]\n\nGENERAL COMMANDS\n  create:      Create a pull request\n  list:        List pull requests in a repository\n  status:      Show status of relevant pull requests\n\nTARGETED COMMANDS\n  checkout:    Check out a pull request in git\n  checks:      Show CI status for a single pull request\n  close:       Close a pull request\n  comment:     Add a comment to a pull request\n  diff:        View changes in a pull request\n  edit:        Edit a pull request\n  lock:        Lock pull request conversation\n  merge:       Merge a pull request\n  ready:       Mark a pull request as ready for review\n  reopen:      Reopen a pull request\n  review:      Add a review to a pull request\n  unlock:      Unlock pull request conversation\n  view:        View a pull request\n\nFLAGS\n  -R, --repo [HOST/]OWNER/REPO   Select another repository using the [HOST/]OWNER/REPO format\n\nINHERITED FLAGS\n  --help   Show help for command\n\nARGUMENTS\n  A pull request can be supplied as argument in any of the following formats:\n  - by number, e.g. \"123\";\n  - by URL, e.g. \"https://github.com/OWNER/REPO/pull/123\"; or\n  - by the name of its head branch, e.g. \"patch-1\" or \"OWNER:patch-1\".\n\nEXAMPLES\n  $ gh pr checkout 353\n  $ gh pr create --fill\n  $ gh pr view --web\n\nLEARN MORE\n  Use `gh &lt;command&gt; &lt;subcommand&gt; --help` for more information about a command.\n  Read the manual at https://cli.github.com/manual\n\n\n\n\n\nWorkflows\n\n!gh workflow\n\nList, view, and run workflows in GitHub Actions.\n\nUSAGE\n  gh workflow &lt;command&gt; [flags]\n\nAVAILABLE COMMANDS\n  disable:     Disable a workflow\n  enable:      Enable a workflow\n  list:        List workflows\n  run:         Run a workflow by creating a workflow_dispatch event\n  view:        View the summary of a workflow\n\nFLAGS\n  -R, --repo [HOST/]OWNER/REPO   Select another repository using the [HOST/]OWNER/REPO format\n\nINHERITED FLAGS\n  --help   Show help for command\n\nLEARN MORE\n  Use `gh &lt;command&gt; &lt;subcommand&gt; --help` for more information about a command.\n  Read the manual at https://cli.github.com/manual\n\n\n\n\n!gh workflow list\n\nNAME                    STATE   ID      \nDeploy to GitHub Pages  active  75582852\nCI                      active  75582853\npages-build-deployment  active  75583140\n\n\n\n\nRuns\n\n!gh run\n\nList, view, and watch recent workflow runs from GitHub Actions.\n\nUSAGE\n  gh run &lt;command&gt; [flags]\n\nAVAILABLE COMMANDS\n  cancel:      Cancel a workflow run\n  delete:      Delete a workflow run\n  download:    Download artifacts generated by a workflow run\n  list:        List recent workflow runs\n  rerun:       Rerun a run\n  view:        View a summary of a workflow run\n  watch:       Watch a run until it completes, showing its progress\n\nFLAGS\n  -R, --repo [HOST/]OWNER/REPO   Select another repository using the [HOST/]OWNER/REPO format\n\nINHERITED FLAGS\n  --help   Show help for command\n\nLEARN MORE\n  Use `gh &lt;command&gt; &lt;subcommand&gt; --help` for more information about a command.\n  Read the manual at https://cli.github.com/manual\n\n\n\n\n!gh run list\n\nSTATUS  TITLE       WORKFLOW   BRANCH     EVENT    ID         ELAPSED  AGE      \n‚úì       pages b...  pages-...  gh-pages   dynamic  986951...  27s      about ...\n‚úì       D  _pro...  CI         main       push     986950...  2m44s    about ...\n‚úì       D  _pro...  Deploy...  main       push     986950...  3m19s    about ...\n‚úì       R  nbs/...  CI         test_r...  push     986910...  32s      about ...\n‚úì       pages b...  pages-...  gh-pages   dynamic  985771...  29s      about ...\n‚úì       R  nbs/...  Deploy...  main       push     985769...  3m37s    about ...\n‚úì       R  nbs/...  CI         main       push     985769...  3m0s     about ...\n‚úì       pages b...  pages-...  gh-pages   dynamic  980833...  21s      about ...\n‚úì       M  nbs/...  CI         main       push     980831...  2m45s    about ...\n‚úì       M  nbs/...  Deploy...  main       push     980831...  3m27s    about ...\n‚úì       pages b...  pages-...  gh-pages   dynamic  980335...  23s      about ...\n‚úì       R  nbs/...  CI         main       push     980334...  2m50s    about ...\n‚úì       R  nbs/...  Deploy...  main       push     980334...  3m30s    about ...\n‚úì       pages b...  pages-...  gh-pages   dynamic  979506...  24s      about ...\n‚úì       A  nbs/...  Deploy...  main       push     979505...  3m14s    about ...\n‚úì       A  nbs/...  CI         main       push     979505...  2m53s    about ...\n‚úì       pages b...  pages-...  gh-pages   dynamic  979453...  32s      about ...\n‚úì       A  nbs/...  CI         main       push     979452...  2m44s    about ...\n‚úì       A  nbs/...  Deploy...  main       push     979452...  3m16s    about ...\n‚úì       pages b...  pages-...  gh-pages   dynamic  979437...  23s      about ...\n\n\n\n\nSearch\n\n!gh search\n\nSearch across all of GitHub.\n\nUSAGE\n  gh search &lt;command&gt; [flags]\n\nAVAILABLE COMMANDS\n  code:        Search within code\n  commits:     Search for commits\n  issues:      Search for issues\n  prs:         Search for pull requests\n  repos:       Search for repositories\n\nINHERITED FLAGS\n  --help   Show help for command\n\nLEARN MORE\n  Use `gh &lt;command&gt; &lt;subcommand&gt; --help` for more information about a command.\n  Read the manual at https://cli.github.com/manual\n\n\n\n\n!gh search issues --owner bthek1\n\n6m‚°ø\nShowing 30 of 121 issues\n\nREPO                ID   TITLE                         LABELS  UPDATED          \nbthek1/WEB_doc      #30  nookal                                about 11 days ago\nbthek1/WEB_doc      #29  DjangoX                               about 11 days ago\nbthek1/WEB_doc      #28  DRF                                   about 11 days ago\nbthek1/nbdevAuto    #2   git status                            about 11 days ago\nbthek1/nbdevAuto    #1   update gacp                           about 11 days ago\nbthek1/ML_methods   #15  Gaussian models                       about 28 days ago\nbthek1/ML_methods   #14  Kernel Ridge regression               about 28 days ago\nbthek1/ML_methods   #13  Bayesian models                       about 28 days ago\nbthek1/Python_Libs  #20  bash scripts                          about 1 month ago\nbthek1/DL_methods   #31  captum                                about 1 month ago\nbthek1/Python_Libs  #19  timm                                  about 22 days ago\nbthek1/Python_Libs  #18  kaggle                                about 22 days ago\nbthek1/Python_Libs  #17  mermaid                               about 22 days ago\nbthek1/Python_Libs  #16  graphviz                              about 22 days ago\nbthek1/DL_methods   #30  create repo of model                  about 4 days ago\nbthek1/DL_methods   #29  ideas - sine wave initali...          about 1 month ago\nbthek1/DL_methods   #28  andrew ng                             about 1 month ago\nbthek1/DL_methods   #27  do one kaggle competition             about 1 month ago\nbthek1/DL_methods   #26  random propagation                    about 1 month ago\nbthek1/DL_methods   #25  ideas - image classificat...          about 1 month ago\nbthek1/DL_methods   #24  Ideas - model looper                  about 1 month ago\nbthek1/DL_methods   #23  panoptic segmentation dee...          about 1 month ago\nbthek1/DL_methods   #22  instance segmentation dee...          about 1 month ago\nbthek1/DL_methods   #21  semantic segmentation dee...          about 1 month ago\nbthek1/DL_methods   #20  object detection deep div...          about 1 month ago\nbthek1/DL_methods   #19  Image mulit classificatio...          about 1 month ago\nbthek1/DL_methods   #18  Image classification deep...          about 1 month ago\nbthek1/DL_methods   #17  move thesis pages to reit...          about 22 days ago\nbthek1/WEB_doc      #27  github automation                     about 22 days ago\nbthek1/Python_Libs  #15  roboflow                              about 1 month ago\n\n\n\n\nSecret\n\n!gh secret\n\nSecrets can be set at the repository, or organization level for use in\nGitHub Actions or Dependabot. User, organization, and repository secrets can be set for\nuse in GitHub Codespaces. Environment secrets can be set for use in\nGitHub Actions. Run `gh help secret set` to learn how to get started.\n\n\nUSAGE\n  gh secret &lt;command&gt; [flags]\n\nAVAILABLE COMMANDS\n  delete:      Delete secrets\n  list:        List secrets\n  set:         Create or update secrets\n\nFLAGS\n  -R, --repo [HOST/]OWNER/REPO   Select another repository using the [HOST/]OWNER/REPO format\n\nINHERITED FLAGS\n  --help   Show help for command\n\nLEARN MORE\n  Use `gh &lt;command&gt; &lt;subcommand&gt; --help` for more information about a command.\n  Read the manual at https://cli.github.com/manual\n\n\n\n\n!gh secret list\n\nNAME         UPDATED          \nTEST_SECRET  about 12 days ago\n\n\n\n\nSSH-KEY\n\n!gh ssh-key\n\nManage SSH keys registered with your GitHub account.\n\nUSAGE\n  gh ssh-key &lt;command&gt; [flags]\n\nAVAILABLE COMMANDS\n  add:         Add an SSH key to your GitHub account\n  delete:      Delete an SSH key from your GitHub account\n  list:        Lists SSH keys in your GitHub account\n\nINHERITED FLAGS\n  --help   Show help for command\n\nLEARN MORE\n  Use `gh &lt;command&gt; &lt;subcommand&gt; --help` for more information about a command.\n  Read the manual at https://cli.github.com/manual\n\n\n\n\n!gh ssh-key list\n\nTITLE         ID        KEY                    TYPE            ADDED            \nthekkel       91043211  ssh-ed255...r/x2XqozE  authentication  about 7 months...\nnew_main      92029161  ssh-ed255...gm+IHN+ix  authentication  about 6 months...\nlinux laptop  92203051  ssh-ed255...U7UtGrWSr  authentication  about 6 months...\noracle        97589482  ssh-ed255...GQaF1/TAK  authentication  about 3 months...\n\n\n\n\nStatus\n\n!gh status\n\nAssigned Issues                       ‚îÇ Assigned Pull Requests                \nbthek1/flutter_test#2  Webdevelopment ‚îÇ Nothing here ^_^                      \nbthek1/flutter_test#1  App development‚îÇ                                       \n                                      ‚îÇ                                       \nReview Requests                       ‚îÇ Mentions                              \nNothing here ^_^                      ‚îÇ Nothing here ^_^                      \n                                      ‚îÇ                                       \nRepository Activity\nNothing here ^_^\n\n\n\n\n\nVariable\n\n!gh variable\n\nVariables can be set at the repository, environment or organization level for use in\nGitHub Actions or Dependabot. Run `gh help variable set` to learn how to get started.\n \n\nUSAGE\n  gh variable &lt;command&gt; [flags]\n\nAVAILABLE COMMANDS\n  delete:      Delete variables\n  get:         Get variables\n  list:        List variables\n  set:         Create or update variables\n\nFLAGS\n  -R, --repo [HOST/]OWNER/REPO   Select another repository using the [HOST/]OWNER/REPO format\n\nINHERITED FLAGS\n  --help   Show help for command\n\nLEARN MORE\n  Use `gh &lt;command&gt; &lt;subcommand&gt; --help` for more information about a command.\n  Read the manual at https://cli.github.com/manual\n\n\n\n\n!gh variable list\n\nNAME           VALUE  UPDATED               \nTEST_VARIABLE  5      less than a minute ago",
    "crumbs": [
      "Blog",
      "Github"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Webdevelopment Documentation",
    "section": "",
    "text": "This file will become your README and also the index of your documentation.",
    "crumbs": [
      "Blog",
      "Webdevelopment Documentation"
    ]
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "Webdevelopment Documentation",
    "section": "Install",
    "text": "Install\npip install webdevelopment_doc",
    "crumbs": [
      "Blog",
      "Webdevelopment Documentation"
    ]
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "Webdevelopment Documentation",
    "section": "How to use",
    "text": "How to use\nFill me in please! Don‚Äôt forget code examples:\n\n1+1\n\n2",
    "crumbs": [
      "Blog",
      "Webdevelopment Documentation"
    ]
  },
  {
    "objectID": "gunicorn.html",
    "href": "gunicorn.html",
    "title": "Gunicorn",
    "section": "",
    "text": "pip install gunicorn",
    "crumbs": [
      "Blog",
      "Gunicorn"
    ]
  },
  {
    "objectID": "gunicorn.html#installation",
    "href": "gunicorn.html#installation",
    "title": "Gunicorn",
    "section": "",
    "text": "pip install gunicorn",
    "crumbs": [
      "Blog",
      "Gunicorn"
    ]
  },
  {
    "objectID": "gunicorn.html#basic-usage",
    "href": "gunicorn.html#basic-usage",
    "title": "Gunicorn",
    "section": "Basic Usage",
    "text": "Basic Usage\n\nTo run your Django application using Gunicorn, navigate to your project‚Äôs root directory and use the following command\n\ngunicorn your_project_name.wsgi:application\n\nReplace your_project_name with the name of your Django project.",
    "crumbs": [
      "Blog",
      "Gunicorn"
    ]
  },
  {
    "objectID": "gunicorn.html#configuration-options",
    "href": "gunicorn.html#configuration-options",
    "title": "Gunicorn",
    "section": "Configuration Options",
    "text": "Configuration Options\n\nGunicorn provides various options to configure the server:\n\n\nBinding to a Specific Address and Port\ngunicorn --bind 0.0.0.0:8000 your_project_name.wsgi:application\n\n\nNumber of Workers\n\nThe number of worker processes for handling requests. More workers can handle more requests concurrently but consume more memory.\n\ngunicorn --workers 3 your_project_name.wsgi:application\n\n\nTimeout\n\nThe maximum number of seconds a worker can spend handling a request before it is killed and restarted.\n\ngunicorn --timeout 30 your_project_name.wsgi:application\n\n\nLogging\n\nYou can specify log files for Gunicorn\n\ngunicorn --access-logfile access.log --error-logfile error.log your_project_name.wsgi:application",
    "crumbs": [
      "Blog",
      "Gunicorn"
    ]
  },
  {
    "objectID": "gunicorn.html#deployment-with-systemd",
    "href": "gunicorn.html#deployment-with-systemd",
    "title": "Gunicorn",
    "section": "Deployment with Systemd",
    "text": "Deployment with Systemd\n\nFor a production deployment, it‚Äôs common to use systemd to manage Gunicorn. Here‚Äôs an example of a systemd service file\nIn file /etc/systemd/system/gunicorn.service\n\n[Unit]\nDescription=gunicorn daemon\nAfter=network.target\n\n[Service]\nUser=your_user\nGroup=www-data\nWorkingDirectory=/path/to/your/project\nExecStart=/path/to/your/venv/bin/gunicorn --workers 3 --bind unix:/path/to/your/project/gunicorn.sock your_project_name.wsgi:application\n\n[Install]\nWantedBy=multi-user.target\n\nReplace your_user with your system username.\nReplace /path/to/your/project with the path to your Django project.\nReplace /path/to/your/venv with the path to your virtual environment.\n\n\nExample\n\n[Unit]\nDescription=gunicorn daemon\nAfter=network.target\n\n[Service]\nUser=ubuntu\nGroup=www-data\nWorkingDirectory=/home/ubuntu/django_todo\nUMask=007\nExecStartPre=/bin/bash -c 'mkdir -p /home/ubuntu/django_todo && chown ubuntu:www-data /home/ubuntu/django_todo'\nExecStart=/home/ubuntu/django_todo/.venv/bin/gunicorn --access-logfile - --workers 3 --bind unix:/home/ubuntu/django_todo/gunicorn.sock config.wsgi:application\n\n[Install]\nWantedBy=multi-user.target\n\nAfter creating the service file, enable and start the service\nsudo systemctl daemon-reload\nsudo systemctl enable gunicorn\nsudo systemctl start gunicorn",
    "crumbs": [
      "Blog",
      "Gunicorn"
    ]
  },
  {
    "objectID": "gunicorn.html#security-considerations",
    "href": "gunicorn.html#security-considerations",
    "title": "Gunicorn",
    "section": "Security Considerations",
    "text": "Security Considerations\n\nKeep Gunicorn and your Django project dependencies up to date.\nUse HTTPS for secure communication.\nUse a firewall to restrict access to the Gunicorn server, allowing only the web server (e.g., Nginx) to communicate with it.",
    "crumbs": [
      "Blog",
      "Gunicorn"
    ]
  },
  {
    "objectID": "gunicorn.html#performance-tuning",
    "href": "gunicorn.html#performance-tuning",
    "title": "Gunicorn",
    "section": "Performance Tuning",
    "text": "Performance Tuning\n\nNumber of Workers: Start with (2 x $num_cores) + 1 workers. Monitor and adjust based on your application‚Äôs performance and server‚Äôs resource availability.\nWorker Class: Use different worker classes based on your application‚Äôs nature, e.g., gevent for async applications.\nKeep-Alive: Adjust the keep-alive setting for persistent connections, especially in high-traffic scenarios.",
    "crumbs": [
      "Blog",
      "Gunicorn"
    ]
  },
  {
    "objectID": "gunicorn.html#monitoring-and-logging",
    "href": "gunicorn.html#monitoring-and-logging",
    "title": "Gunicorn",
    "section": "Monitoring and Logging",
    "text": "Monitoring and Logging\n\nUse monitoring tools like New Relic, Datadog, or Prometheus to keep an eye on the performance and health of your application.\nLog files should be monitored for errors and access patterns.",
    "crumbs": [
      "Blog",
      "Gunicorn"
    ]
  },
  {
    "objectID": "gunicorn.html#common-issues-and-troubleshooting",
    "href": "gunicorn.html#common-issues-and-troubleshooting",
    "title": "Gunicorn",
    "section": "Common Issues and Troubleshooting",
    "text": "Common Issues and Troubleshooting\n\n502 Bad Gateway: Often due to Gunicorn not running or configuration issues with the reverse proxy server.\nSlow Performance: Could be due to insufficient worker processes or server resources. Profiling the application can help identify bottlenecks.\nMemory Leaks: Regularly monitor memory usage and ensure proper resource management in the application.",
    "crumbs": [
      "Blog",
      "Gunicorn"
    ]
  },
  {
    "objectID": "Cloud/AWS/boto3.html",
    "href": "Cloud/AWS/boto3.html",
    "title": "Boto3",
    "section": "",
    "text": "Clients are used to make low-level service calls to AWS APIs.\n\n\nThe client gives you access to a set of methods for each AWS service, which correspond directly to AWS API operations.\n\n\nExample\n\nimport boto3\nclient = boto3.client('s3')  # S3 client\nresponse = client.list_buckets()  # List all S3 buckets\nprint(response)\n\n\n\n\nResources are higher-level abstractions that wrap around AWS service objects, providing an object-oriented way of interacting with AWS.\n\n\nResources hide much of the complexity of working with AWS APIs.\n\n\nExample\n\ns3 = boto3.resource('s3')\nbucket = s3.Bucket('my-bucket')\nfor obj in bucket.objects.all():\n    print(obj.key)\n\n\n\n\nA session manages your AWS credentials, region, and configurations. If no session is explicitly created, Boto3 creates a default one.\n\n\nYou can create a session to manage different profiles, regions, or credentials.\n\n\nExample\n\nsession = boto3.Session(profile_name='myprofile')\ns3 = session.resource('s3')\n\n\n\n\nPaginators automatically handle the pagination of results, which is required when an API call returns too many results to fit into a single response.\n\n\nExample\n\nclient = boto3.client('s3')\npaginator = client.get_paginator('list_objects_v2')\nfor page in paginator.paginate(Bucket='my-bucket'):\n    for obj in page['Contents']:\n        print(obj['Key'])\n\n\n\n\nWaiters provide a convenient way to wait for a resource to reach a specific state, such as an EC2 instance becoming available or an S3 object being fully uploaded.\n\n\nExample\n\nec2 = boto3.client('ec2')\nec2.start_instances(InstanceIds=['i-1234567890abcdef0'])\nwaiter = ec2.get_waiter('instance_running')\nwaiter.wait(InstanceIds=['i-1234567890abcdef0'])",
    "crumbs": [
      "Blog",
      "Cloud",
      "AWS",
      "Boto3"
    ]
  },
  {
    "objectID": "Cloud/AWS/boto3.html#key-concepts-in-boto3",
    "href": "Cloud/AWS/boto3.html#key-concepts-in-boto3",
    "title": "Boto3",
    "section": "",
    "text": "Clients are used to make low-level service calls to AWS APIs.\n\n\nThe client gives you access to a set of methods for each AWS service, which correspond directly to AWS API operations.\n\n\nExample\n\nimport boto3\nclient = boto3.client('s3')  # S3 client\nresponse = client.list_buckets()  # List all S3 buckets\nprint(response)\n\n\n\n\nResources are higher-level abstractions that wrap around AWS service objects, providing an object-oriented way of interacting with AWS.\n\n\nResources hide much of the complexity of working with AWS APIs.\n\n\nExample\n\ns3 = boto3.resource('s3')\nbucket = s3.Bucket('my-bucket')\nfor obj in bucket.objects.all():\n    print(obj.key)\n\n\n\n\nA session manages your AWS credentials, region, and configurations. If no session is explicitly created, Boto3 creates a default one.\n\n\nYou can create a session to manage different profiles, regions, or credentials.\n\n\nExample\n\nsession = boto3.Session(profile_name='myprofile')\ns3 = session.resource('s3')\n\n\n\n\nPaginators automatically handle the pagination of results, which is required when an API call returns too many results to fit into a single response.\n\n\nExample\n\nclient = boto3.client('s3')\npaginator = client.get_paginator('list_objects_v2')\nfor page in paginator.paginate(Bucket='my-bucket'):\n    for obj in page['Contents']:\n        print(obj['Key'])\n\n\n\n\nWaiters provide a convenient way to wait for a resource to reach a specific state, such as an EC2 instance becoming available or an S3 object being fully uploaded.\n\n\nExample\n\nec2 = boto3.client('ec2')\nec2.start_instances(InstanceIds=['i-1234567890abcdef0'])\nwaiter = ec2.get_waiter('instance_running')\nwaiter.wait(InstanceIds=['i-1234567890abcdef0'])",
    "crumbs": [
      "Blog",
      "Cloud",
      "AWS",
      "Boto3"
    ]
  },
  {
    "objectID": "Cloud/AWS/boto3.html#common-aws-services-with-boto3",
    "href": "Cloud/AWS/boto3.html#common-aws-services-with-boto3",
    "title": "Boto3",
    "section": "Common AWS Services with Boto3",
    "text": "Common AWS Services with Boto3\n\nAmazon S3 (Simple Storage Service)\n\nS3 is used for scalable object storage. With Boto3, you can create, read, and manage S3 buckets and objects.\n\n\nCreate a bucket\ns3 = boto3.client('s3')\ns3.create_bucket(Bucket='my-bucket')\n\n\nUpload a file\ns3 = boto3.client('s3')\ns3.upload_file('localfile.txt', 'my-bucket', 'remote.txt')\n\n\nDownload a file\ns3 = boto3.client('s3')\ns3.download_file('my-bucket', 'remote.txt', 'localfile.txt')\n\n\n\nList buckets\ns3 = boto3.client('s3')\nresponse = s3.list_buckets()\nfor bucket in response['Buckets']:\n    print(bucket['Name'])\n\n\nDelete a bucket\ns3 = boto3.client('s3')\ns3.delete_bucket(Bucket='my-bucket')\n\n\n\nAmazon EC2 (Elastic Compute Cloud)\n\nEC2 is a service that provides resizable compute capacity. With Boto3, you can manage instances, security groups, and key pairs.\n\n\nLaunch an EC2 instance\nec2 = boto3.resource('ec2')\ninstance = ec2.create_instances(\n    ImageId='ami-0abcdef1234567890',\n    MinCount=1,\n    MaxCount=1,\n    InstanceType='t2.micro'\n)\n\n\nStop an instance\nec2 = boto3.client('ec2')\nec2.stop_instances(InstanceIds=['i-1234567890abcdef0'])\n\n\nTerminate an instance\nec2 = boto3.client('ec2')\nec2.terminate_instances(InstanceIds=['i-1234567890abcdef0'])\n\n\nList all instances\nec2 = boto3.resource('ec2')\nfor instance in ec2.instances.all():\n    print(instance.id, instance.state)\n\n\n\n\nAmazon DynamoDB\n\nDynamoDB is a fully managed NoSQL database service. Boto3 lets you interact with tables, items, and queries.\n\n\nCreate a table\ndynamodb = boto3.resource('dynamodb')\ntable = dynamodb.create_table(\n    TableName='Users',\n    KeySchema=[\n        {\n            'AttributeName': 'user_id',\n            'KeyType': 'HASH'\n        }\n    ],\n    AttributeDefinitions=[\n        {\n            'AttributeName': 'user_id',\n            'AttributeType': 'S'\n        }\n    ],\n    ProvisionedThroughput={\n        'ReadCapacityUnits': 10,\n        'WriteCapacityUnits': 10\n    }\n)\n\n\n\nPut an item in a table\ntable = boto3.resource('dynamodb').Table('Users')\ntable.put_item(Item={'user_id': '123', 'name': 'John Doe'})\n\n\nGet an item from a table\ntable = boto3.resource('dynamodb').Table('Users')\nresponse = table.get_item(Key={'user_id': '123'})\nprint(response['Item'])\n\n\n\nDelete an item\ntable = boto3.resource('dynamodb').Table('Users')\ntable.delete_item(Key={'user_id': '123'})\n\n\n\nAWS Lambda\n\nAWS Lambda allows you to run code in response to events without provisioning servers. With Boto3, you can manage Lambda functions.\n\n\nCreate a Lambda function\nlambda_client = boto3.client('lambda')\nwith open('my-deployment-package.zip', 'rb') as f:\n    zipped_code = f.read()\n\nlambda_client.create_function(\n    FunctionName='MyLambdaFunction',\n    Runtime='python3.8',\n    Role='arn:aws:iam::123456789012:role/service-role/MyLambdaRole',\n    Handler='lambda_function.lambda_handler',\n    Code=dict(ZipFile=zipped_code),\n    Timeout=300\n)\n\n\n\nInvoke a Lambda function\nlambda_client = boto3.client('lambda')\nresponse = lambda_client.invoke(\n    FunctionName='MyLambdaFunction',\n    InvocationType='RequestResponse',\n    Payload=b'{\"key\": \"value\"}'\n)\nprint(response['Payload'].read())\n\n\nDelete a Lambda function\nlambda_client = boto3.client('lambda')\nlambda_client.delete_function(FunctionName='MyLambdaFunction')\n\n\n\nAmazon SNS (Simple Notification Service)\n\nSNS allows you to send notifications via email, SMS, or to other AWS services.\n\n\nCreate an SNS topic\nsns = boto3.client('sns')\nresponse = sns.create_topic(Name='MyTopic')\ntopic_arn = response['TopicArn']\n\n\nSubscribe to an SNS topic\nsns = boto3.client('sns')\nsns.subscribe(\n    TopicArn=topic_arn,\n    Protocol='email',\n    Endpoint='example@example.com'\n)\n\n\n\nPublish a message to an SNS topic\nsns = boto3.client('sns')\nsns.publish(\n    TopicArn=topic_arn,\n    Message='This is a test message.'\n)",
    "crumbs": [
      "Blog",
      "Cloud",
      "AWS",
      "Boto3"
    ]
  },
  {
    "objectID": "Cloud/AWS/boto3.html#handling-credentials-in-boto3",
    "href": "Cloud/AWS/boto3.html#handling-credentials-in-boto3",
    "title": "Boto3",
    "section": "Handling Credentials in Boto3",
    "text": "Handling Credentials in Boto3\n\nBoto3 automatically looks for credentials in the following order:\n\n\nEnvironment Variables:\n\nAWS_ACCESS_KEY_ID\nAWS_SECRET_ACCESS_KEY\nAWS_SESSION_TOKEN (optional)\n\nShared Credentials File (~/.aws/credentials):\n\n\nProfiles can be configured here, like [default].\n\n\nEC2 Instance Metadata:\n\nFor instances running in AWS, Boto3 can retrieve credentials from the metadata service.\n\n\n\nYou can also pass credentials explicitly\n\nsession = boto3.Session(\n    aws_access_key_id='YOUR_ACCESS_KEY',\n    aws_secret_access_key='YOUR_SECRET_KEY',\n    region_name='us-west-2'\n)\ns3 = session.resource('s3')",
    "crumbs": [
      "Blog",
      "Cloud",
      "AWS",
      "Boto3"
    ]
  },
  {
    "objectID": "Cloud/AWS/boto3.html#error-handling-in-boto3",
    "href": "Cloud/AWS/boto3.html#error-handling-in-boto3",
    "title": "Boto3",
    "section": "Error Handling in Boto3",
    "text": "Error Handling in Boto3\n\nBoto3 includes exceptions that you can catch to handle errors gracefully.\n\nimport boto3\nfrom botocore.exceptions import NoCredentialsError, PartialCredentialsError\n\ntry:\n    s3 = boto3.client('s3')\n    s3.list_buckets()\nexcept NoCredentialsError:\n    print(\"Credentials not available.\")\nexcept PartialCredentialsError:\n    print(\"Incomplete credentials provided.\")",
    "crumbs": [
      "Blog",
      "Cloud",
      "AWS",
      "Boto3"
    ]
  },
  {
    "objectID": "Cloud/AWS/boto3.html#optimizations-in-boto3",
    "href": "Cloud/AWS/boto3.html#optimizations-in-boto3",
    "title": "Boto3",
    "section": "Optimizations in Boto3",
    "text": "Optimizations in Boto3\n\nMulti-threading with concurrent.futures: You can speed up Boto3 operations (especially with S3) by using multi-threading or multi-processing.\n\nfrom concurrent.futures import ThreadPoolExecutor\n\ndef upload_file(bucket, filename):\n    s3 = boto3.client('s3')\n    s3.upload_file(filename, bucket, filename)\n\nwith ThreadPoolExecutor(max_workers=5) as executor:\n    executor.map(upload_file, ['my-bucket'] * 10, ['file1.txt', 'file2.txt', ...])\n\nSession Caching: Reuse the same session across multiple Boto3 resource or client invocations to avoid repeatedly initializing the session.\nUsing Paginators: For services like S3 that return paginated results, using paginators avoids issues with large datasets.",
    "crumbs": [
      "Blog",
      "Cloud",
      "AWS",
      "Boto3"
    ]
  },
  {
    "objectID": "Cloud/AWS/Untitled.html",
    "href": "Cloud/AWS/Untitled.html",
    "title": "webdevelopment_doc",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "certbot.html",
    "href": "certbot.html",
    "title": "Certbot",
    "section": "",
    "text": "1. What is Certbot?\nCertbot is a client application for Let‚Äôs Encrypt that helps users automatically obtain and install SSL/TLS certificates for their web servers. It simplifies the process of transitioning websites from HTTP to HTTPS by handling the creation, validation, issuance, and renewal of certificates.\n\n\nKey Features:\n\nFree Certificates: Certbot works with Let‚Äôs Encrypt, a free CA, to obtain free SSL/TLS certificates.\nAutomation: Certbot automates the process of obtaining and renewing certificates, ensuring that HTTPS is always enabled.\nIntegration with Web Servers: Certbot can automatically configure popular web servers (e.g., Apache, Nginx) to use SSL.\nCross-Platform: Certbot works on most Unix-based systems (e.g., Linux, macOS), as well as Windows.\n\n\n\n2. How SSL/TLS Certificates Work\nSSL/TLS certificates enable secure HTTPS connections by encrypting data exchanged between clients (e.g., browsers) and servers.\nThe process involves: - Public/Private Key Pair: A certificate is a public key associated with a domain name. The server holds the private key, and the client encrypts messages using the public key, ensuring only the server can decrypt them. - Certificate Validation: Certbot verifies the ownership of the domain for which the certificate is requested. - Certificate Expiry: Let‚Äôs Encrypt certificates are valid for 90 days. Certbot can be set to automatically renew them.\n\n\n3. How Certbot Works\nCertbot works through a challenge-response process where Let‚Äôs Encrypt validates that you control the domain for which you‚Äôre requesting the certificate. The most common validation method is HTTP-01 challenge.\n\nHTTP-01 Challenge: Certbot temporarily creates a special file on your web server that Let‚Äôs Encrypt checks over HTTP. If Let‚Äôs Encrypt can access the file, the challenge is completed successfully, and the certificate is issued.\nDNS-01 Challenge: For wildcard certificates or in some special configurations, Certbot may use a DNS challenge where it verifies ownership by checking a DNS TXT record.\n\nOnce Certbot obtains the certificate, it configures your web server to use it, ensuring a secure HTTPS connection.\n\n\n4. Installation of Certbot\nCertbot can be installed on most operating systems, and it integrates well with popular web servers such as Apache and Nginx.\n\na. Installation on Ubuntu/Debian (Nginx)\n\nAdd Certbot‚Äôs PPA (Personal Package Archive):\nsudo apt update\nsudo apt install software-properties-common\nsudo add-apt-repository universe\nsudo add-apt-repository ppa:certbot/certbot\nsudo apt update\nInstall Certbot for Nginx:\nsudo apt install certbot python3-certbot-nginx\n\n\n\nb. Installation on CentOS/RHEL (Nginx)\n\nEnable EPEL repository:\nsudo yum install epel-release\nInstall Certbot for Nginx:\nsudo yum install certbot python3-certbot-nginx\n\n\n\nc.¬†Installation on Windows\nCertbot can also be installed on Windows through the official Certbot repository.\n\n\nd.¬†Docker Installation\nCertbot can be run as a Docker container:\ndocker run -it --rm --name certbot \\\n    -v \"/etc/letsencrypt:/etc/letsencrypt\" \\\n    -v \"/var/lib/letsencrypt:/var/lib/letsencrypt\" \\\n    certbot/certbot certonly --nginx\n\n\n\n5. Obtaining and Installing SSL Certificates with Certbot\nOnce Certbot is installed, you can use it to obtain and install SSL certificates for your domain.\n\na. Nginx Auto-Configuration\nCertbot can automatically obtain a certificate and configure Nginx for HTTPS:\n\nRun the Certbot command for Nginx:\nsudo certbot --nginx\nCertbot will prompt you to enter your email, agree to the terms, and select the domain names for which you want to obtain certificates.\nCertbot will automatically update your Nginx configuration to use the new certificates, and your site will be accessible via HTTPS.\n\n\n\nb. Apache Auto-Configuration\nIf you‚Äôre using Apache, the process is similar:\n\nInstall Certbot for Apache:\nsudo apt install python3-certbot-apache\nObtain and configure certificates:\nsudo certbot --apache\n\n\n\nc.¬†Manual Mode\nIf you‚Äôre using a web server that Certbot doesn‚Äôt support for automatic configuration, or if you want to handle installation manually, you can use Certonly mode:\nsudo certbot certonly --manual\nCertbot will provide instructions on setting up the challenge (e.g., placing a file on your server or configuring DNS), and once validated, it will generate the certificate files in /etc/letsencrypt/live.\n\n\n\n6. Auto-Renewal of Certificates\nLet‚Äôs Encrypt certificates expire after 90 days, but Certbot can be configured to automatically renew them.\n\na. Automatic Renewal\nCertbot installs a cron job or systemd timer that checks your certificates regularly and renews them if they‚Äôre nearing expiration. You can check whether the renewal service is active by running:\nsystemctl list-timers | grep certbot\n\n\nb. Testing Auto-Renewal\nYou can simulate the renewal process to ensure it works:\nsudo certbot renew --dry-run\nIf successful, Certbot will automatically renew certificates before they expire.\n\n\nc.¬†Manual Renewal\nIf you prefer to renew certificates manually, you can use the following command:\nsudo certbot renew\n\n\n\n7. Wildcard Certificates\nWildcard certificates allow you to secure multiple subdomains with a single certificate. For example, a wildcard certificate for *.example.com would cover www.example.com, api.example.com, etc.\nCertbot supports obtaining wildcard certificates using the DNS-01 challenge, which requires adding a DNS TXT record to your domain‚Äôs DNS settings.\n\nObtaining a Wildcard Certificate:\n\nRun Certbot in manual mode with the DNS challenge:\nsudo certbot certonly --manual --preferred-challenges dns -d *.example.com -d example.com\nCertbot will instruct you to create a TXT record in your DNS with a specified value. After adding the DNS record, Certbot will verify it and issue the wildcard certificate.\n\n\n\n\n8. Certbot Commands Overview\nCertbot offers various commands for obtaining, renewing, and managing certificates:\n\nObtain and Install Certificate (Nginx/Apache):\nsudo certbot --nginx  # For Nginx\nsudo certbot --apache  # For Apache\nObtain Certificate without Web Server Configuration:\nsudo certbot certonly --manual\nRenew All Certificates:\nsudo certbot renew\nSimulate Renewal for Testing:\nsudo certbot renew --dry-run\nList All Certificates:\nsudo certbot certificates\nRevoke a Certificate:\nsudo certbot revoke --cert-path /etc/letsencrypt/live/example.com/fullchain.pem\nDelete a Certificate:\nsudo certbot delete --cert-name example.com\n\n\n\n9. Certbot with DNS API for Automatic DNS-01 Challenge\nFor fully automating wildcard certificate issuance or using the DNS-01 challenge, Certbot integrates with DNS providers via their APIs. You‚Äôll need credentials (API keys) for your DNS provider.\nHere‚Äôs an example of how to use Certbot with the Cloudflare DNS API:\n\nInstall the Cloudflare plugin:\nsudo apt install python3-certbot-dns-cloudflare\nUse the DNS challenge with Cloudflare:\nsudo certbot certonly \\\n  --dns-cloudflare \\\n  --dns-cloudflare-credentials /path/to/your/cloudflare.ini \\\n  -d example.com \\\n  -d *.example.com\n\n\n\n10. Certbot Advanced Configuration\nCertbot provides additional flexibility for different use cases:\n\na. Custom Webroot\nYou can specify a custom webroot directory to place the validation challenge file for HTTP-01 challenges:\nsudo certbot certonly --webroot -w /var/www/html -d example.com\n\n\nb. Using Hooks\nCertbot allows you to run custom commands during certificate issuance or renewal using hooks. Hooks can be used to restart services or perform actions after a successful\nrenewal.\n\nPre-Hook: Runs before obtaining or renewing a certificate.\nPost-Hook: Runs after the certificate is obtained.\nRenew-Hook: Runs after every renewal.\n\nExample of a renewal hook to reload Nginx:\nsudo certbot renew --deploy-hook \"systemctl reload nginx\"\n\n\nc.¬†Staging Environment\nYou can use Certbot‚Äôs staging environment to test the issuance process without hitting Let‚Äôs Encrypt‚Äôs rate limits:\nsudo certbot --staging --nginx\n\n\n\n11. Managing Multiple Domains\nCertbot allows you to manage certificates for multiple domains, even combining multiple domain names in a single certificate.\n\nIssue a Multi-Domain Certificate:\nsudo certbot --nginx -d example.com -d www.example.com -d blog.example.com\nThis will issue a certificate that covers all specified domains.\n\n\n\n12. Certbot for Other Web Servers\nAlthough Certbot offers automated configuration for Nginx and Apache, you can use it with other web servers (e.g., Caddy, HAProxy, Lighttpd) by using certonly mode and manually configuring the certificate.\nExample for HAProxy:\n\nObtain the certificate:\nsudo certbot certonly --standalone -d example.com\nConfigure HAProxy to use the generated certificate:\nbind *:443 ssl crt /etc/letsencrypt/live/example.com/fullchain.pem\n\n\n\n13. Certbot Logging\nCertbot logs its actions to /var/log/letsencrypt/. This directory contains detailed logs about every certificate issuance or renewal attempt, which can be helpful for debugging or reviewing the certificate process.\n\n\n14. Rate Limits\nLet‚Äôs Encrypt imposes rate limits to prevent abuse:\n\nCertificates per Registered Domain: You can issue a maximum of 50 certificates per domain per week.\nDuplicate Certificate Limit: 5 duplicate certificates for the same domain set per week.\nAccount Limits: Each account can create up to 300 new orders per 3 hours.\n\nYou can check Let‚Äôs Encrypt‚Äôs official rate limits documentation for detailed information: Let‚Äôs Encrypt Rate Limits.\n\n\n15. Certbot Security Considerations\n\na. Private Key Security\nThe private key for your certificates is stored in /etc/letsencrypt/live/domain_name/privkey.pem. Ensure that this directory is accessible only to root and the necessary services to prevent unauthorized access.\n\n\nb. Firewall Configuration\nEnsure that your firewall allows incoming traffic on port 80 (for the HTTP-01 challenge) and port 443 for HTTPS.\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Blog",
      "Certbot"
    ]
  },
  {
    "objectID": "git.html",
    "href": "git.html",
    "title": "GIT",
    "section": "",
    "text": "!git -h\n\nunknown option: -h\nusage: git [--version] [--help] [-C &lt;path&gt;] [-c &lt;name&gt;=&lt;value&gt;]\n           [--exec-path[=&lt;path&gt;]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=&lt;path&gt;] [--work-tree=&lt;path&gt;] [--namespace=&lt;name&gt;]\n           [--super-prefix=&lt;path&gt;] [--config-env=&lt;name&gt;=&lt;envvar&gt;]\n           &lt;command&gt; [&lt;args&gt;]",
    "crumbs": [
      "Blog",
      "GIT"
    ]
  },
  {
    "objectID": "git.html#git-files",
    "href": "git.html#git-files",
    "title": "GIT",
    "section": "Git Files",
    "text": "Git Files\n.git : main file managing git stuff\n.gitignore : list of files and files types to ignore\n.github : git hub automation",
    "crumbs": [
      "Blog",
      "GIT"
    ]
  },
  {
    "objectID": "git.html#install",
    "href": "git.html#install",
    "title": "GIT",
    "section": "Install",
    "text": "Install\nsudo apt install git",
    "crumbs": [
      "Blog",
      "GIT"
    ]
  },
  {
    "objectID": "git.html#configure-git",
    "href": "git.html#configure-git",
    "title": "GIT",
    "section": "Configure Git",
    "text": "Configure Git\ngit config --global user.name \"Your Name\"\ngit config --global user.email \"you@example.com\"",
    "crumbs": [
      "Blog",
      "GIT"
    ]
  },
  {
    "objectID": "git.html#creating-new-repo",
    "href": "git.html#creating-new-repo",
    "title": "GIT",
    "section": "Creating New Repo",
    "text": "Creating New Repo\n\nOption 1: Create repo in Github and clone it\ngit clone &lt;ssh url&gt;\n\n\nOption 2: Create a Git repository locally\ngit init\n\nOptional\n\ngit branch -m main\n\nAdd and commit files\ngit add . \ngit commit -m \"Your commit message\"\n\n\nSet up a remote repository\ngit remote add &lt;name&gt; &lt;url&gt;\nExample:\ngit remote add origin your_remote_repository_url\n\n\nSync\ngit branch --set-upstream-to=&lt;remote name&gt;/&lt;remote branch&gt; &lt;local branch&gt;\n\nExample\n\ngit branch --set-upstream-to=origin/main master\n\nsync\n\ngit pull\n\n\nPush changes to remote\ngit push\n\n\nVerify remote connection\ngit remote -v",
    "crumbs": [
      "Blog",
      "GIT"
    ]
  },
  {
    "objectID": "git.html#basic-commands",
    "href": "git.html#basic-commands",
    "title": "GIT",
    "section": "Basic Commands",
    "text": "Basic Commands\n\nChecking git status\ngit status\n\n\nAdding files to git repo\ngit add &lt;filenames&gt; \nFor adding all the files in the folder\ngit add * \n\n\nCommit it to local repo\ngit commit -m \"&lt;message&gt;\"\n\n\nFor pushing to github\ngit push",
    "crumbs": [
      "Blog",
      "GIT"
    ]
  },
  {
    "objectID": "git.html#git-branches",
    "href": "git.html#git-branches",
    "title": "GIT",
    "section": "Git Branches",
    "text": "Git Branches\n\nFor viewing Braches\n\n!git branch\n\n* main\n\n\n\n\nAdding branches\ngit branch &lt;name&gt;\n\n\nSwitching branches\ngit checkout &lt;branch name&gt;\ncreate branch and move into it\ngit checkout -b &lt;branch name&gt;\n\n\nPush branch to github\ngit push --set-upstream &lt;online branch name&gt; &lt;local branch name&gt;\n\n\nDelete branch\ngit branch -d &lt;branch name&gt;",
    "crumbs": [
      "Blog",
      "GIT"
    ]
  },
  {
    "objectID": "git.html#review-history",
    "href": "git.html#review-history",
    "title": "GIT",
    "section": "Review History",
    "text": "Review History\n\ngit log: Lists version history for the current branch\ngit log --follow [file]: Lists version history for a file, including renames\ngit diff [first-branch]...[second-branch]: Shows content differences between two branches\ngit show [commit]: Outputs metadata and content changes of the specified commit",
    "crumbs": [
      "Blog",
      "GIT"
    ]
  },
  {
    "objectID": "git.html#git-forking",
    "href": "git.html#git-forking",
    "title": "GIT",
    "section": "Git Forking",
    "text": "Git Forking",
    "crumbs": [
      "Blog",
      "GIT"
    ]
  },
  {
    "objectID": "git.html#git-submodules",
    "href": "git.html#git-submodules",
    "title": "GIT",
    "section": "Git submodules",
    "text": "Git submodules\n\nA Git submodule is a repository embedded inside another Git repository. The submodule itself is a separate Git repository that is maintained independently.\n\n\nThe main repository (also called the superproject) includes a reference to a specific commit in the submodule repository.\n\n\nAdding a Submodule\ngit submodule add &lt;repository-url&gt; &lt;path&gt;\n\nExample\n\ngit submodule add https://github.com/example/repo.git external/repo\n\n\nCloning a Repository with Submodules\n\nWhen you clone a repository that contains submodules, the submodules are not cloned by default. You can initialize and update the submodules after cloning\n\ngit clone &lt;repository-url&gt;\ncd &lt;repository-directory&gt;\ngit submodule update --init --recursive\n\nAlternatively, you can clone the repository and its submodules in one command:\n\ngit clone --recursive &lt;repository-url&gt;\n\n\nUpdating Submodules\ngit submodule update --remote --merge\n\n\nSynchronizing Submodules\ngit submodule sync --recursive\n\n\nRemoving a Submodule\ngit submodule deinit -f -- &lt;submodule-path&gt;\ngit rm -f &lt;submodule-path&gt;\nrm -rf .git/modules/&lt;submodule-path&gt;",
    "crumbs": [
      "Blog",
      "GIT"
    ]
  },
  {
    "objectID": "iptables.html",
    "href": "iptables.html",
    "title": "Iptables",
    "section": "",
    "text": "iptables organizes rules into different tables. Each table contains a set of chains:\n\n\nFilter Table: The default table for filtering packets. It has three built-in chains: INPUT, FORWARD, and OUTPUT.\nNAT Table: Used for Network Address Translation (NAT). It has three built-in chains: PREROUTING, POSTROUTING, and OUTPUT.\nMangle Table: Used for specialized packet alterations. It has five built-in chains: PREROUTING, INPUT, FORWARD, OUTPUT, and POSTROUTING.\nRaw Table: Used for configuring exemptions from connection tracking. It has two built-in chains: PREROUTING and OUTPUT.\n\n\n\n\n\nChains are lists of rules that iptables uses to determine the fate of packets:\n\n\nINPUT: Handles packets destined for the local machine.\nFORWARD: Handles packets routed through the machine.\nOUTPUT: Handles packets originating from the local machine.\n\n\n\n\n\nEach rule in a chain specifies conditions for matching packets and an action to take (e.g., ACCEPT, DROP).",
    "crumbs": [
      "Blog",
      "Iptables"
    ]
  },
  {
    "objectID": "iptables.html#basic-concepts",
    "href": "iptables.html#basic-concepts",
    "title": "Iptables",
    "section": "",
    "text": "iptables organizes rules into different tables. Each table contains a set of chains:\n\n\nFilter Table: The default table for filtering packets. It has three built-in chains: INPUT, FORWARD, and OUTPUT.\nNAT Table: Used for Network Address Translation (NAT). It has three built-in chains: PREROUTING, POSTROUTING, and OUTPUT.\nMangle Table: Used for specialized packet alterations. It has five built-in chains: PREROUTING, INPUT, FORWARD, OUTPUT, and POSTROUTING.\nRaw Table: Used for configuring exemptions from connection tracking. It has two built-in chains: PREROUTING and OUTPUT.\n\n\n\n\n\nChains are lists of rules that iptables uses to determine the fate of packets:\n\n\nINPUT: Handles packets destined for the local machine.\nFORWARD: Handles packets routed through the machine.\nOUTPUT: Handles packets originating from the local machine.\n\n\n\n\n\nEach rule in a chain specifies conditions for matching packets and an action to take (e.g., ACCEPT, DROP).",
    "crumbs": [
      "Blog",
      "Iptables"
    ]
  },
  {
    "objectID": "iptables.html#basic-commands",
    "href": "iptables.html#basic-commands",
    "title": "Iptables",
    "section": "Basic Commands",
    "text": "Basic Commands\n\nHere are some common iptables commands\n\n\nView Existing Rules\n\nTo list rules in a specific table\n\nsudo iptables -L -t filter\nsudo iptables -L -t nat\nsudo iptables -L -t mangle\n\n\nTo list rules with extended information\n\nsudo iptables -L -v -n\n\n\nAdding Rules\n\nTo append a rule to a chain\n\nsudo iptables -A INPUT -p tcp --dport 22 -j ACCEPT\nThis rule allows incoming TCP traffic on port 22 (SSH)\n\nTo insert a rule at a specific position\n\nsudo iptables -I INPUT 1 -p tcp --dport 80 -j ACCEPT\nThis rule inserts a new rule at position 1 of the INPUT chain allowing incoming HTTP traffic.\n\n\nDeleting Rules\n\nTo delete a specific rule\n\nsudo iptables -D INPUT -p tcp --dport 22 -j ACCEPT\n\nTo delete a rule by its line number\n\nsudo iptables -D INPUT 1\n\n\nFlushing Rules\n\nTo remove all rules from a specific table\n\nsudo iptables -F -t filter\nsudo iptables -F -t nat\nsudo iptables -F -t mangle\n\n\nSaving Rules\n\nTo save rules so they persist across reboots, you can use\n\nsudo iptables-save &gt; /etc/iptables/rules.v4\n\nTo restore saved rules\n\nsudo iptables-restore &lt; /etc/iptables/rules.v4",
    "crumbs": [
      "Blog",
      "Iptables"
    ]
  },
  {
    "objectID": "iptables.html#common-use-cases",
    "href": "iptables.html#common-use-cases",
    "title": "Iptables",
    "section": "Common Use Cases",
    "text": "Common Use Cases\n\nBasic Firewall Setup\n\nTo set up a basic firewall that allows only SSH and HTTP traffic\n\n# Flush existing rules\nsudo iptables -F\n\n# Allow loopback traffic\nsudo iptables -A INPUT -i lo -j ACCEPT\n\n# Allow incoming SSH and HTTP\nsudo iptables -A INPUT -p tcp --dport 22 -j ACCEPT\nsudo iptables -A INPUT -p tcp --dport 80 -j ACCEPT\n\n# Drop all other incoming traffic\nsudo iptables -P INPUT DROP\n\n\nNAT Configuration\n\nTo set up NAT (e.g., for a home router)\n\n# Enable IP forwarding\nsudo sysctl -w net.ipv4.ip_forward=1\n\n# Configure NAT for outgoing traffic\nsudo iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE\n\n\nPort Forwarding\n\nTo forward traffic from port 8080 on the local machine to port 80 on a remote server\n\nsudo iptables -t nat -A PREROUTING -p tcp --dport 8080 -j DNAT --to-destination 192.168.1.100:80\nsudo iptables -A FORWARD -p tcp -d 192.168.1.100 --dport 80 -j ACCEPT",
    "crumbs": [
      "Blog",
      "Iptables"
    ]
  },
  {
    "objectID": "iptables.html#advanced-features",
    "href": "iptables.html#advanced-features",
    "title": "Iptables",
    "section": "Advanced Features",
    "text": "Advanced Features\n\nConnection Tracking\n\niptables can track the state of connections\n\nsudo iptables -A INPUT -m conntrack --ctstate ESTABLISHED,RELATED -j ACCEPT\nThis rule allows incoming traffic that is part of an established or related connection.\n\n\nRate Limiting\n\nTo limit the rate of incoming connections\n\nsudo iptables -A INPUT -p tcp --dport 22 -m limit --limit 2/minute -j ACCEPT\nThis rule limits SSH connections to 2 per minute.\n\n\nLogging\n\nTo log packets that match a rule\n\nsudo iptables -A INPUT -p tcp --dport 22 -j LOG --log-prefix \"SSH Access: \"\nLogs will appear in /var/log/syslog or /var/log/messages, depending on your system",
    "crumbs": [
      "Blog",
      "Iptables"
    ]
  },
  {
    "objectID": "iptables.html#configuration-files",
    "href": "iptables.html#configuration-files",
    "title": "Iptables",
    "section": "Configuration Files",
    "text": "Configuration Files\niptables rules are typically saved in /etc/iptables/rules.v4 for IPv4 and /etc/iptables/rules.v6 for IPv6. You can use tools like iptables-persistent to automatically apply saved rules on boot\nsudo apt-get install iptables-persistent",
    "crumbs": [
      "Blog",
      "Iptables"
    ]
  },
  {
    "objectID": "iptables.html#transition-to-nftables",
    "href": "iptables.html#transition-to-nftables",
    "title": "Iptables",
    "section": "Transition to nftables",
    "text": "Transition to nftables\nnftables is the successor to iptables and is intended to replace it in the future.\nTesting: Use tools like curl, telnet, or netcat to test network connectivity and rule effectiveness.",
    "crumbs": [
      "Blog",
      "Iptables"
    ]
  },
  {
    "objectID": "prefect.html",
    "href": "prefect.html",
    "title": "Prefect",
    "section": "",
    "text": "prefect server start\n\nhttp://127.0.0.1:4200\n\n\n\nprefect config set PREFECT_API_URL=\"http://127.0.0.1:4200/api\"\n\n\n\nprefect config view --show-defaults",
    "crumbs": [
      "Blog",
      "Prefect"
    ]
  },
  {
    "objectID": "prefect.html#start-prefect-server",
    "href": "prefect.html#start-prefect-server",
    "title": "Prefect",
    "section": "",
    "text": "prefect server start\n\nhttp://127.0.0.1:4200\n\n\n\nprefect config set PREFECT_API_URL=\"http://127.0.0.1:4200/api\"\n\n\n\nprefect config view --show-defaults",
    "crumbs": [
      "Blog",
      "Prefect"
    ]
  },
  {
    "objectID": "prefect.html#flows",
    "href": "prefect.html#flows",
    "title": "Prefect",
    "section": "Flows",
    "text": "Flows\nFlows can be thought of as special types of functions. They can take inputs, perform work, and return an output. In fact, you can turn any function into a Prefect flow by adding the @flow decorator. When a function becomes a flow, its behavior changes, giving it the following advantages:\nTask called within Flows\n\nfrom prefect import flow, task\n\n@task\ndef print_hello(name):\n    print(f\"Hello {name}!\")\n\n@flow(name=\"Hello Flow\")\ndef hello_world(name=\"world\"):\n    print_hello(name)\n\n\nimport datetime\nfrom prefect import flow\n\n@flow(flow_run_name=\"{name}-on-{date:%A}\")\ndef my_flow(name: str, date: datetime.datetime):\n    pass\n\n# creates a flow run called 'marvin-on-Thursday'\nmy_flow(name=\"marvin\", date=datetime.datetime.now(datetime.timezone.utc))\n\n18:17:46.247 | INFO    | prefect.engine - Created flow run 'placid-finch' for flow 'my-flow'\n\n\n\n18:17:46.320 | INFO    | Flow run 'placid-finch' - Finished in state Completed()\n\n\n\n\nFlow settings\nFlows allow a great deal of configuration by passing arguments to the decorator. Flows accept the following optional settings.\n\n\n\nArgument\nDescription\n\n\n\n\ndescription\nAn optional string description for the flow. If not provided, the description will be pulled from the docstring for the decorated function.\n\n\nname\nAn optional name for the flow. If not provided, the name will be inferred from the function.\n\n\nretries\nAn optional number of times to retry on flow run failure.\n\n\nretry_delay_seconds\nAn optional number of seconds to wait before retrying the flow after failure. This is only applicable if retries is nonzero.\n\n\nflow_run_name\nAn optional name to distinguish runs of this flow; this name can be provided as a string template with the flow‚Äôs parameters as variables; this name can also be provided as a function that returns a string.\n\n\ntask_runner\nAn optional task runner to use for task execution within the flow when you .submit() tasks. If not provided and you .submit() tasks, the ConcurrentTaskRunner will be used.\n\n\ntimeout_seconds\nAn optional number of seconds indicating a maximum runtime for the flow. If the flow exceeds this runtime, it will be marked as failed. Flow execution may continue until the next task is called.\n\n\nvalidate_parameters\nBoolean indicating whether parameters passed to flows are validated by Pydantic. Default is True.\n\n\nversion\nAn optional version string for the flow. If not provided, we will attempt to create a version string as a hash of the file containing the wrapped function. If the file cannot be located, the version will be null.\n\n\n\n\n\nFlow Example\n\nfrom prefect import flow, task\nimport datetime\nfrom prefect.runtime import flow_run\nfrom prefect.task_runners import SequentialTaskRunner\n\ndef generate_flow_run_name():\n    flow_name = flow_run.flow_name\n    parameters = flow_run.parameters\n    name = parameters[\"name\"]\n\n    \n    date = datetime.datetime.now(datetime.timezone.utc)\n\n    return f\"flow run name test: {flow_name}-with-{name}: {date:%A}\"\n\n@task(name=\"task test\")\ndef print_hello(name:str) -&gt; str:\n    msg = f\"Hello {name}!\"\n    print(msg)\n    return msg\n\n@flow(name=\"flow test\",\n      description=\"flow test description\",\n      task_runner=SequentialTaskRunner(),\n      flow_run_name=generate_flow_run_name\n      )\ndef hello_world(name:str =\"world\") -&gt; None:\n    message = print_hello(name)\n\nhello_world(\"Ben\")\n\n/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/tasks.py:348: UserWarning: A task named 'task test' and defined at '/tmp/ipykernel_23433/1543666974.py:16' conflicts with another task. Consider specifying a unique `name` parameter in the task definition:\n\n `@task(name='my_unique_name', ...)`\n  warnings.warn(\n/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/flows.py:357: UserWarning: A flow named 'flow test' and defined at '/tmp/ipykernel_23433/1543666974.py:22' conflicts with another flow. Consider specifying a unique `name` parameter in the flow definition:\n\n `@flow(name='my_unique_name', ...)`\n  warnings.warn(\n\n\n18:31:47.848 | INFO    | prefect.engine - Created flow run 'caped-swan' for flow 'flow test'\n\n\n\n18:31:47.927 | INFO    | Flow run 'flow run name test: flow test-with-Ben: Wednesday' - Created task run 'task test-0' for task 'task test'\n\n\n\n18:31:47.929 | INFO    | Flow run 'flow run name test: flow test-with-Ben: Wednesday' - Executing 'task test-0' immediately...\n\n\n\nHello Ben!\n\n\n18:31:47.998 | INFO    | Task run 'task test-0' - Finished in state Completed()\n\n\n\n18:31:48.025 | INFO    | Flow run 'caped-swan' - Finished in state Completed('All states completed.')\n\n\n\n[Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `str`'))]\n\n\n\nimport graphviz\n\n\nfrom prefect import flow, task\n\n@task(name=\"Print Hello\")\ndef print_hello(name):\n    msg = f\"Hello {name}!\"\n    print(msg)\n    return msg\n\n@task(name=\"Print Hello Again\")\ndef print_hello_again(name):\n    msg = f\"Hello {name}!\"\n    print(msg)\n    return msg\n\n@flow(name=\"Hello Flow\")\ndef hello_world(name=\"world\"):\n    message = print_hello(name)\n    message2 = print_hello_again(message)\n\nhello_world.visualize()\n\n&lt;coroutine object Flow.visualize&gt;\n\n\n\n\nSubflows\nA subflow run is created when a flow function is called inside the execution of another flow. The primary flow is the ‚Äúparent‚Äù flow. The flow created within the parent is the ‚Äúchild‚Äù flow or ‚Äúsubflow.‚Äù\nSubflow runs behave like normal flow runs. There is a full representation of the flow run in the backend as if it had been called separately. When a subflow starts, it will create a new task runner for tasks within the subflow. When the subflow completes, the task runner is shut down.\n\nfrom prefect import flow, task\n\n@task(name=\"Print Hello\")\ndef print_hello(name):\n    msg = f\"Hello {name}!\"\n    print(msg)\n    return msg\n\n@flow(name=\"Subflow\")\ndef my_subflow(msg):\n    print(f\"Subflow says: {msg}\")\n\n@flow(name=\"Hello Flow\")\ndef hello_world(name=\"world\"):\n    for _ in range(3):\n        message = print_hello(name)\n        my_subflow(message)\n\nhello_world(\"Marvin\")\n\n/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/tasks.py:348: UserWarning: A task named 'Print Hello' and defined at '/tmp/ipykernel_23433/3107251931.py:3' conflicts with another task. Consider specifying a unique `name` parameter in the task definition:\n\n `@task(name='my_unique_name', ...)`\n  warnings.warn(\n/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/flows.py:357: UserWarning: A flow named 'Subflow' and defined at '/tmp/ipykernel_23433/3107251931.py:9' conflicts with another flow. Consider specifying a unique `name` parameter in the flow definition:\n\n `@flow(name='my_unique_name', ...)`\n  warnings.warn(\n/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/flows.py:357: UserWarning: A flow named 'Hello Flow' and defined at '/tmp/ipykernel_23433/3107251931.py:13' conflicts with another flow. Consider specifying a unique `name` parameter in the flow definition:\n\n `@flow(name='my_unique_name', ...)`\n  warnings.warn(\n\n\n18:41:19.292 | INFO    | prefect.engine - Created flow run 'wonderful-wolf' for flow 'Hello Flow'\n\n\n\n18:41:19.356 | INFO    | Flow run 'wonderful-wolf' - Created task run 'Print Hello-0' for task 'Print Hello'\n\n\n\n18:41:19.358 | INFO    | Flow run 'wonderful-wolf' - Executing 'Print Hello-0' immediately...\n\n\n\nHello Marvin!\n\n\n18:41:19.430 | INFO    | Task run 'Print Hello-0' - Finished in state Completed()\n\n\n\n/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/tasks.py:348: UserWarning: A task named 'Subflow' and defined at '/tmp/ipykernel_23433/3107251931.py:9' conflicts with another task. Consider specifying a unique `name` parameter in the task definition:\n\n `@task(name='my_unique_name', ...)`\n  warnings.warn(\n\n\n18:41:19.504 | INFO    | Flow run 'wonderful-wolf' - Created subflow run 'aspiring-aardwark' for flow 'Subflow'\n\n\n\nSubflow says: Hello Marvin!\n\n\n18:41:19.585 | INFO    | Flow run 'aspiring-aardwark' - Finished in state Completed()\n\n\n\n18:41:19.607 | INFO    | Flow run 'wonderful-wolf' - Created task run 'Print Hello-1' for task 'Print Hello'\n\n\n\n18:41:19.608 | INFO    | Flow run 'wonderful-wolf' - Executing 'Print Hello-1' immediately...\n\n\n\nHello Marvin!\n\n\n18:41:19.672 | INFO    | Task run 'Print Hello-1' - Finished in state Completed()\n\n\n\n/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/tasks.py:348: UserWarning: A task named 'Subflow' and defined at '/tmp/ipykernel_23433/3107251931.py:9' conflicts with another task. Consider specifying a unique `name` parameter in the task definition:\n\n `@task(name='my_unique_name', ...)`\n  warnings.warn(\n\n\n18:41:19.738 | INFO    | Flow run 'wonderful-wolf' - Created subflow run 'garrulous-starling' for flow 'Subflow'\n\n\n\nSubflow says: Hello Marvin!\n\n\n18:41:19.815 | INFO    | Flow run 'garrulous-starling' - Finished in state Completed()\n\n\n\n18:41:19.839 | INFO    | Flow run 'wonderful-wolf' - Created task run 'Print Hello-2' for task 'Print Hello'\n\n\n\n18:41:19.840 | INFO    | Flow run 'wonderful-wolf' - Executing 'Print Hello-2' immediately...\n\n\n\nHello Marvin!\n\n\n18:41:19.904 | INFO    | Task run 'Print Hello-2' - Finished in state Completed()\n\n\n\n/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/tasks.py:348: UserWarning: A task named 'Subflow' and defined at '/tmp/ipykernel_23433/3107251931.py:9' conflicts with another task. Consider specifying a unique `name` parameter in the task definition:\n\n `@task(name='my_unique_name', ...)`\n  warnings.warn(\n\n\n18:41:19.976 | INFO    | Flow run 'wonderful-wolf' - Created subflow run 'snobbish-rottweiler' for flow 'Subflow'\n\n\n\nSubflow says: Hello Marvin!\n\n\n18:41:20.056 | INFO    | Flow run 'snobbish-rottweiler' - Finished in state Completed()\n\n\n\n18:41:20.084 | INFO    | Flow run 'wonderful-wolf' - Finished in state Completed('All states completed.')\n\n\n\n[Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `str`')),\n Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `str`')),\n Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `str`')),\n Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `NoneType`')),\n Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `NoneType`')),\n Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `NoneType`'))]\n\n\n!!! tip ‚ÄúSubflows or tasks?‚Äù In Prefect you can call tasks or subflows to do work within your workflow, including passing results from other tasks to your subflow. So a common question is:\n\"When should I use a subflow instead of a task?\"\n\nWe recommend writing tasks that do a discrete, specific piece of work in your workflow: calling an API, performing a database operation, analyzing or transforming a data point. \nPrefect tasks are well suited to parallel or distributed execution using distributed computation frameworks such as Dask or Ray. \nFor troubleshooting, the more granular you create your tasks, the easier it is to find and fix issues should a task fail.\n\nSubflows enable you to group related tasks within your workflow. \nHere are some scenarios where you might choose to use a subflow rather than calling tasks individually:\n\n- Observability: Subflows, like any other flow run, have first-class observability within the Prefect UI and Prefect Cloud. You'll see subflow status in the **Flow Runs** dashboard rather than having to dig down into the tasks within a specific flow run. See [Final state determination](#final-state-determination) for some examples of leveraging task state within flows.\n- Conditional flows: If you have a group of tasks that run only under certain conditions, you can group them within a subflow and conditionally run the subflow rather than each task individually.\n- Parameters: Flows have first-class support for parameterization, making it easy to run the same group of tasks in different use cases by simply passing different parameters to the subflow in which they run.\n- Task runners: Subflows enable you to specify the task runner used for tasks within the flow. For example, if you want to optimize parallel execution of certain tasks with Dask, you can group them in a subflow that uses the Dask task runner. You can use a different task runner for each subflow.\n\nfrom prefect import flow\nfrom datetime import datetime\n\n@flow\ndef what_day_is_it(date: datetime = None):\n    if date is None:\n        date = datetime.now(timezone.utc)\n    print(f\"It was {date.strftime('%A')} on {date.isoformat()}\")\n\nwhat_day_is_it(\"2021-01-01T02:00:19.180906\")\n# It was Friday on 2021-01-01T02:00:19.180906\n\n18:49:42.898 | INFO    | prefect.engine - Created flow run 'vermilion-spider' for flow 'what-day-is-it'\n\n\n\nIt was Friday on 2021-01-01T02:00:19.180906\n\n\n18:49:42.963 | INFO    | Flow run 'vermilion-spider' - Finished in state Completed()",
    "crumbs": [
      "Blog",
      "Prefect"
    ]
  },
  {
    "objectID": "prefect.html#tasks",
    "href": "prefect.html#tasks",
    "title": "Prefect",
    "section": "Tasks",
    "text": "Tasks",
    "crumbs": [
      "Blog",
      "Prefect"
    ]
  },
  {
    "objectID": "prefect.html#task-arguments",
    "href": "prefect.html#task-arguments",
    "title": "Prefect",
    "section": "Task arguments",
    "text": "Task arguments\nTasks allow for customization through optional arguments:\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nname\nAn optional name for the task. If not provided, the name will be inferred from the function name.\n\n\ndescription\nAn optional string description for the task. If not provided, the description will be pulled from the docstring for the decorated function.\n\n\ntags\nAn optional set of tags to be associated with runs of this task. These tags are combined with any tags defined by a prefect.tags context at task runtime.\n\n\ncache_key_fn\nAn optional callable that, given the task run context and call parameters, generates a string key. If the key matches a previous completed state, that state result will be restored instead of running the task again.\n\n\ncache_expiration\nAn optional amount of time indicating how long cached states for this task should be restorable; if not provided, cached states will never expire.\n\n\nretries\nAn optional number of times to retry on task run failure.\n\n\nretry_delay_seconds\nAn optional number of seconds to wait before retrying the task after failure. This is only applicable if retries is nonzero.\n\n\nlog_prints\nAn optional boolean indicating whether to log print statements.\n\n\npersist_result\nAn optional boolean indicating whether to persist the result of the task run to storage.\n\n\n\n\nfrom prefect import flow, task\n\n@task\ndef my_first_task(msg):\n    print(f\"Hello, {msg}\")\n\n@task\ndef my_second_task(msg):\n    my_first_task.fn(msg)\n    return msg\n\n@flow(flow_run_name = \"task test1\")\ndef my_flow(msg: str = \"Trillian\"):\n    my_second_task(msg)\n    return msg\n\nmy_flow()\n\n/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/tasks.py:348: UserWarning: A task named 'my_first_task' and defined at '/tmp/ipykernel_23433/819281590.py:3' conflicts with another task. Consider specifying a unique `name` parameter in the task definition:\n\n `@task(name='my_unique_name', ...)`\n  warnings.warn(\n/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/tasks.py:348: UserWarning: A task named 'my_second_task' and defined at '/tmp/ipykernel_23433/819281590.py:7' conflicts with another task. Consider specifying a unique `name` parameter in the task definition:\n\n `@task(name='my_unique_name', ...)`\n  warnings.warn(\n/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/flows.py:357: UserWarning: A flow named 'my-flow' and defined at '/tmp/ipykernel_23433/819281590.py:12' conflicts with another flow. Consider specifying a unique `name` parameter in the flow definition:\n\n `@flow(name='my_unique_name', ...)`\n  warnings.warn(\n\n\n19:04:31.723 | INFO    | prefect.engine - Created flow run 'fluorescent-bittern' for flow 'my-flow'\n\n\n\n19:04:31.802 | INFO    | Flow run 'task test1' - Created task run 'my_second_task-0' for task 'my_second_task'\n\n\n\n19:04:31.804 | INFO    | Flow run 'task test1' - Executing 'my_second_task-0' immediately...\n\n\n\nHello, Trillian\n\n\n19:04:31.873 | INFO    | Task run 'my_second_task-0' - Finished in state Completed()\n\n\n\n19:04:31.904 | INFO    | Flow run 'fluorescent-bittern' - Finished in state Completed()\n\n\n\n'Trillian'\n\n\n\nfrom prefect import flow\nfrom prefect.runtime import flow_run, task_run\n\ndef generate_task_name():\n    flow_name = flow_run.flow_name\n    task_name = task_run.task_name\n\n    parameters = task_run.parameters\n    name = parameters[\"name\"]\n    limit = parameters[\"limit\"]\n\n    return f\"{flow_name}-{task_name}-with-{name}-and-{limit}\"\n\n@task(name=\"my-example-task\",\n      description=\"An example task for a tutorial.\",\n      task_run_name=generate_task_name)\ndef my_task(name: str, limit: int = 100):\n    pass\n\n@flow\ndef my_flow(name: str):\n    # creates a run with a name like \"my-flow-my-example-task-with-marvin-and-100\"\n    my_task(name=\"marvin\")\n\n/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/flows.py:357: UserWarning: A flow named 'my-flow' and defined at '/tmp/ipykernel_23433/732348698.py:20' conflicts with another flow. Consider specifying a unique `name` parameter in the flow definition:\n\n `@flow(name='my_unique_name', ...)`\n  warnings.warn(\n\n\n\nTags\n\n@task(name=\"hello-task\", tags=[\"test\"])\ndef my_task():\n    print(\"Hello, I'm a task\")\n\n\n\nRetries\n\nimport httpx\n\nfrom prefect import flow, task\n\n\n@task(retries=2, retry_delay_seconds=5)\ndef get_data_task(\n    url: str = \"https://api.brittle-service.com/endpoint\"\n) -&gt; dict:\n    response = httpx.get(url)\n\n    # If the response status code is anything but a 2xx, httpx will raise\n    # an exception. This task doesn't handle the exception, so Prefect will\n    # catch the exception and will consider the task run failed.\n    response.raise_for_status()\n\n    return response.json()\n\n\n@flow\ndef get_data_flow():\n    get_data_task()\n\nget_data_flow()\n\n/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/tasks.py:348: UserWarning: A task named 'get_data_task' and defined at '/tmp/ipykernel_23433/1331835922.py:6' conflicts with another task. Consider specifying a unique `name` parameter in the task definition:\n\n `@task(name='my_unique_name', ...)`\n  warnings.warn(\n/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/flows.py:357: UserWarning: A flow named 'get-data-flow' and defined at '/tmp/ipykernel_23433/1331835922.py:20' conflicts with another flow. Consider specifying a unique `name` parameter in the flow definition:\n\n `@flow(name='my_unique_name', ...)`\n  warnings.warn(\n\n\n19:08:29.596 | INFO    | prefect.engine - Created flow run 'almond-spider' for flow 'get-data-flow'\n\n\n\n19:08:29.655 | INFO    | Flow run 'almond-spider' - Created task run 'get_data_task-0' for task 'get_data_task'\n\n\n\n19:08:29.658 | INFO    | Flow run 'almond-spider' - Executing 'get_data_task-0' immediately...\n\n\n\n19:08:29.859 | ERROR   | Task run 'get_data_task-0' - Encountered exception during execution:\nTraceback (most recent call last):\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_transports/default.py\", line 69, in map_httpcore_exceptions\n    yield\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_transports/default.py\", line 233, in handle_request\n    resp = self._pool.handle_request(req)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n    raise exc from None\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n    response = connection.handle_request(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n    raise exc\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n    stream = self._connect(request)\n             ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n    stream = self._network_backend.connect_tcp(**kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n    with map_exceptions(exc_map):\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/contextlib.py\", line 155, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ConnectError: [Errno -2] Name or service not known\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/engine.py\", line 2147, in orchestrate_task_run\n    result = await call.aresult()\n             ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py\", line 327, in aresult\n    return await asyncio.wrap_future(self.future)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py\", line 352, in _run_sync\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_23433/1331835922.py\", line 10, in get_data_task\n    response = httpx.get(url)\n               ^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_api.py\", line 198, in get\n    return request(\n           ^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_api.py\", line 106, in request\n    return client.request(\n           ^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_client.py\", line 827, in request\n    return self.send(request, auth=auth, follow_redirects=follow_redirects)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_client.py\", line 914, in send\n    response = self._send_handling_auth(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_client.py\", line 942, in _send_handling_auth\n    response = self._send_handling_redirects(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_client.py\", line 979, in _send_handling_redirects\n    response = self._send_single_request(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_client.py\", line 1015, in _send_single_request\n    response = transport.handle_request(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_transports/default.py\", line 232, in handle_request\n    with map_httpcore_exceptions():\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/contextlib.py\", line 155, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_transports/default.py\", line 86, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ConnectError: [Errno -2] Name or service not known\n\n\n\n19:08:29.893 | INFO    | Task run 'get_data_task-0' - Received non-final state 'AwaitingRetry' when proposing final state 'Failed' and will attempt to run again...\n\n\n\n19:08:34.986 | ERROR   | Task run 'get_data_task-0' - Encountered exception during execution:\nTraceback (most recent call last):\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_transports/default.py\", line 69, in map_httpcore_exceptions\n    yield\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_transports/default.py\", line 233, in handle_request\n    resp = self._pool.handle_request(req)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n    raise exc from None\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n    response = connection.handle_request(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n    raise exc\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n    stream = self._connect(request)\n             ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n    stream = self._network_backend.connect_tcp(**kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n    with map_exceptions(exc_map):\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/contextlib.py\", line 155, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ConnectError: [Errno -2] Name or service not known\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/engine.py\", line 2147, in orchestrate_task_run\n    result = await call.aresult()\n             ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py\", line 327, in aresult\n    return await asyncio.wrap_future(self.future)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py\", line 352, in _run_sync\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_23433/1331835922.py\", line 10, in get_data_task\n    response = httpx.get(url)\n               ^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_api.py\", line 198, in get\n    return request(\n           ^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_api.py\", line 106, in request\n    return client.request(\n           ^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_client.py\", line 827, in request\n    return self.send(request, auth=auth, follow_redirects=follow_redirects)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_client.py\", line 914, in send\n    response = self._send_handling_auth(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_client.py\", line 942, in _send_handling_auth\n    response = self._send_handling_redirects(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_client.py\", line 979, in _send_handling_redirects\n    response = self._send_single_request(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_client.py\", line 1015, in _send_single_request\n    response = transport.handle_request(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_transports/default.py\", line 232, in handle_request\n    with map_httpcore_exceptions():\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/contextlib.py\", line 155, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_transports/default.py\", line 86, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ConnectError: [Errno -2] Name or service not known\n\n\n\n19:08:35.018 | INFO    | Task run 'get_data_task-0' - Received non-final state 'AwaitingRetry' when proposing final state 'Failed' and will attempt to run again...\n\n\n\n19:08:40.124 | ERROR   | Task run 'get_data_task-0' - Encountered exception during execution:\nTraceback (most recent call last):\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_transports/default.py\", line 69, in map_httpcore_exceptions\n    yield\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_transports/default.py\", line 233, in handle_request\n    resp = self._pool.handle_request(req)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n    raise exc from None\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n    response = connection.handle_request(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n    raise exc\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n    stream = self._connect(request)\n             ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n    stream = self._network_backend.connect_tcp(**kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n    with map_exceptions(exc_map):\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/contextlib.py\", line 155, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ConnectError: [Errno -2] Name or service not known\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/engine.py\", line 2147, in orchestrate_task_run\n    result = await call.aresult()\n             ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py\", line 327, in aresult\n    return await asyncio.wrap_future(self.future)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py\", line 352, in _run_sync\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_23433/1331835922.py\", line 10, in get_data_task\n    response = httpx.get(url)\n               ^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_api.py\", line 198, in get\n    return request(\n           ^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_api.py\", line 106, in request\n    return client.request(\n           ^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_client.py\", line 827, in request\n    return self.send(request, auth=auth, follow_redirects=follow_redirects)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_client.py\", line 914, in send\n    response = self._send_handling_auth(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_client.py\", line 942, in _send_handling_auth\n    response = self._send_handling_redirects(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_client.py\", line 979, in _send_handling_redirects\n    response = self._send_single_request(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_client.py\", line 1015, in _send_single_request\n    response = transport.handle_request(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_transports/default.py\", line 232, in handle_request\n    with map_httpcore_exceptions():\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/contextlib.py\", line 155, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_transports/default.py\", line 86, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ConnectError: [Errno -2] Name or service not known\n\n\n\n19:08:40.154 | ERROR   | Task run 'get_data_task-0' - Finished in state Failed('Task run encountered an exception ConnectError: [Errno -2] Name or service not known')\n\n\n\n19:08:40.156 | ERROR   | Flow run 'almond-spider' - Encountered exception during execution:\nTraceback (most recent call last):\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_transports/default.py\", line 69, in map_httpcore_exceptions\n    yield\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_transports/default.py\", line 233, in handle_request\n    resp = self._pool.handle_request(req)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py\", line 216, in handle_request\n    raise exc from None\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py\", line 196, in handle_request\n    response = connection.handle_request(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n    raise exc\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n    stream = self._connect(request)\n             ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpcore/_sync/connection.py\", line 122, in _connect\n    stream = self._network_backend.connect_tcp(**kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n    with map_exceptions(exc_map):\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/contextlib.py\", line 155, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ConnectError: [Errno -2] Name or service not known\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/engine.py\", line 867, in orchestrate_flow_run\n    result = await flow_call.aresult()\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py\", line 327, in aresult\n    return await asyncio.wrap_future(self.future)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py\", line 352, in _run_sync\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_23433/1331835922.py\", line 22, in get_data_flow\n    get_data_task()\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/tasks.py\", line 600, in __call__\n    return enter_task_run_engine(\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/engine.py\", line 1421, in enter_task_run_engine\n    return from_sync.wait_for_call_in_loop_thread(begin_run)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/api.py\", line 243, in wait_for_call_in_loop_thread\n    return call.result()\n           ^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py\", line 318, in result\n    return self.future.result(timeout=timeout)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py\", line 179, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py\", line 389, in _run_async\n    result = await coro\n             ^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/engine.py\", line 1601, in get_task_call_return_value\n    return await future._result()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/futures.py\", line 237, in _result\n    return await final_state.result(raise_on_failure=raise_on_failure, fetch=True)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/states.py\", line 91, in _get_state_result\n    raise await get_state_exception(state)\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/engine.py\", line 2147, in orchestrate_task_run\n    result = await call.aresult()\n             ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py\", line 327, in aresult\n    return await asyncio.wrap_future(self.future)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py\", line 352, in _run_sync\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_23433/1331835922.py\", line 10, in get_data_task\n    response = httpx.get(url)\n               ^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_api.py\", line 198, in get\n    return request(\n           ^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_api.py\", line 106, in request\n    return client.request(\n           ^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_client.py\", line 827, in request\n    return self.send(request, auth=auth, follow_redirects=follow_redirects)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_client.py\", line 914, in send\n    response = self._send_handling_auth(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_client.py\", line 942, in _send_handling_auth\n    response = self._send_handling_redirects(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_client.py\", line 979, in _send_handling_redirects\n    response = self._send_single_request(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_client.py\", line 1015, in _send_single_request\n    response = transport.handle_request(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_transports/default.py\", line 232, in handle_request\n    with map_httpcore_exceptions():\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/contextlib.py\", line 155, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_transports/default.py\", line 86, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ConnectError: [Errno -2] Name or service not known\n\n\n\n19:08:40.187 | ERROR   | Flow run 'almond-spider' - Finished in state Failed('Flow run encountered an exception. ConnectError: [Errno -2] Name or service not known')\n\n\n\n\n---------------------------------------------------------------------------\nConnectError                              Traceback (most recent call last)\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_transports/default.py:69, in map_httpcore_exceptions()\n     68 try:\n---&gt; 69     yield\n     70 except Exception as exc:\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_transports/default.py:233, in HTTPTransport.handle_request(self, request)\n    232 with map_httpcore_exceptions():\n--&gt; 233     resp = self._pool.handle_request(req)\n    235 assert isinstance(resp.stream, typing.Iterable)\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:216, in ConnectionPool.handle_request(self, request)\n    215     self._close_connections(closing)\n--&gt; 216     raise exc from None\n    218 # Return the response. Note that in this case we still have to manage\n    219 # the point at which the response is closed.\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:196, in ConnectionPool.handle_request(self, request)\n    194 try:\n    195     # Send the request on the assigned connection.\n--&gt; 196     response = connection.handle_request(\n    197         pool_request.request\n    198     )\n    199 except ConnectionNotAvailable:\n    200     # In some cases a connection may initially be available to\n    201     # handle a request, but then become unavailable.\n    202     #\n    203     # In this case we clear the connection and try again.\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/httpcore/_sync/connection.py:99, in HTTPConnection.handle_request(self, request)\n     98     self._connect_failed = True\n---&gt; 99     raise exc\n    101 return self._connection.handle_request(request)\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/httpcore/_sync/connection.py:76, in HTTPConnection.handle_request(self, request)\n     75 if self._connection is None:\n---&gt; 76     stream = self._connect(request)\n     78     ssl_object = stream.get_extra_info(\"ssl_object\")\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/httpcore/_sync/connection.py:122, in HTTPConnection._connect(self, request)\n    121 with Trace(\"connect_tcp\", logger, request, kwargs) as trace:\n--&gt; 122     stream = self._network_backend.connect_tcp(**kwargs)\n    123     trace.return_value = stream\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/httpcore/_backends/sync.py:205, in SyncBackend.connect_tcp(self, host, port, timeout, local_address, socket_options)\n    200 exc_map: ExceptionMapping = {\n    201     socket.timeout: ConnectTimeout,\n    202     OSError: ConnectError,\n    203 }\n--&gt; 205 with map_exceptions(exc_map):\n    206     sock = socket.create_connection(\n    207         address,\n    208         timeout,\n    209         source_address=source_address,\n    210     )\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/contextlib.py:155, in _GeneratorContextManager.__exit__(self, typ, value, traceback)\n    154 try:\n--&gt; 155     self.gen.throw(typ, value, traceback)\n    156 except StopIteration as exc:\n    157     # Suppress StopIteration *unless* it's the same exception that\n    158     # was passed to throw().  This prevents a StopIteration\n    159     # raised inside the \"with\" statement from being suppressed.\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/httpcore/_exceptions.py:14, in map_exceptions(map)\n     13     if isinstance(exc, from_exc):\n---&gt; 14         raise to_exc(exc) from exc\n     15 raise\n\nConnectError: [Errno -2] Name or service not known\n\nThe above exception was the direct cause of the following exception:\n\nConnectError                              Traceback (most recent call last)\nCell In[24], line 24\n     20 @flow\n     21 def get_data_flow():\n     22     get_data_task()\n---&gt; 24 get_data_flow()\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/flows.py:1224, in Flow.__call__(self, return_state, wait_for, *args, **kwargs)\n   1219 if task_viz_tracker:\n   1220     # this is a subflow, for now return a single task and do not go further\n   1221     # we can add support for exploring subflows for tasks in the future.\n   1222     return track_viz_task(self.isasync, self.name, parameters)\n-&gt; 1224 return enter_flow_run_engine_from_flow_call(\n   1225     self,\n   1226     parameters,\n   1227     wait_for=wait_for,\n   1228     return_type=return_type,\n   1229 )\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/engine.py:297, in enter_flow_run_engine_from_flow_call(flow, parameters, wait_for, return_type)\n    290     retval = from_async.wait_for_call_in_loop_thread(\n    291         begin_run,\n    292         done_callbacks=done_callbacks,\n    293         contexts=contexts,\n    294     )\n    296 else:\n--&gt; 297     retval = from_sync.wait_for_call_in_loop_thread(\n    298         begin_run,\n    299         done_callbacks=done_callbacks,\n    300         contexts=contexts,\n    301     )\n    303 return retval\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/api.py:243, in from_sync.wait_for_call_in_loop_thread(_from_sync__call, timeout, done_callbacks, contexts)\n    241     stack.enter_context(context)\n    242 waiter.wait()\n--&gt; 243 return call.result()\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py:318, in Call.result(self, timeout)\n    312 def result(self, timeout: Optional[float] = None) -&gt; T:\n    313     \"\"\"\n    314     Wait for the result of the call.\n    315 \n    316     Not safe for use from asynchronous contexts.\n    317     \"\"\"\n--&gt; 318     return self.future.result(timeout=timeout)\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py:179, in Future.result(self, timeout)\n    177     raise CancelledError()\n    178 elif self._state == FINISHED:\n--&gt; 179     return self.__get_result()\n    181 self._condition.wait(timeout)\n    183 if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:\n    184     # Raise Prefect cancelled error instead of\n    185     # `concurrent.futures._base.CancelledError`\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/concurrent/futures/_base.py:401, in Future.__get_result(self)\n    399 if self._exception:\n    400     try:\n--&gt; 401         raise self._exception\n    402     finally:\n    403         # Break a reference cycle with the exception in self._exception\n    404         self = None\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py:389, in Call._run_async(***failed resolving arguments***)\n    387 with self.future.enforce_async_deadline() as cancel_scope:\n    388     try:\n--&gt; 389         result = await coro\n    390     finally:\n    391         # Forget this call's arguments in order to free up any memory\n    392         # that may be referenced by them; after a call has happened,\n    393         # there's no need to keep a reference to them\n    394         self.args = None\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/client/utilities.py:78, in inject_client.&lt;locals&gt;.with_injected_client(*args, **kwargs)\n     76 async with context as new_client:\n     77     kwargs.setdefault(\"client\", new_client or client)\n---&gt; 78     return await fn(*args, **kwargs)\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/engine.py:400, in create_then_begin_flow_run(flow, parameters, wait_for, return_type, client, user_thread)\n    398     return state\n    399 elif return_type == \"result\":\n--&gt; 400     return await state.result(fetch=True)\n    401 else:\n    402     raise ValueError(f\"Invalid return type for flow engine {return_type!r}.\")\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/states.py:91, in _get_state_result(state, raise_on_failure)\n     84     raise UnfinishedRun(\n     85         f\"Run is in {state.type.name} state, its result is not available.\"\n     86     )\n     88 if raise_on_failure and (\n     89     state.is_crashed() or state.is_failed() or state.is_cancelled()\n     90 ):\n---&gt; 91     raise await get_state_exception(state)\n     93 if isinstance(state.data, DataDocument):\n     94     result = result_from_state_with_data_document(\n     95         state, raise_on_failure=raise_on_failure\n     96     )\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/engine.py:867, in orchestrate_flow_run(flow, flow_run, parameters, wait_for, interruptible, client, partial_flow_run_context, user_thread)\n    862         else:\n    863             from_async.call_soon_in_new_thread(\n    864                 flow_call, timeout=flow.timeout_seconds\n    865             )\n--&gt; 867         result = await flow_call.aresult()\n    869         waited_for_task_runs = await wait_for_task_runs_and_report_crashes(\n    870             flow_run_context.task_run_futures, client=client\n    871         )\n    872 except PausedRun as exc:\n    873     # could get raised either via utility or by returning Paused from a task run\n    874     # if a task run pauses, we set its state as the flow's state\n    875     # to preserve reschedule and timeout behavior\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py:327, in Call.aresult(self)\n    321 \"\"\"\n    322 Wait for the result of the call.\n    323 \n    324 For use from asynchronous contexts.\n    325 \"\"\"\n    326 try:\n--&gt; 327     return await asyncio.wrap_future(self.future)\n    328 except asyncio.CancelledError as exc:\n    329     raise CancelledError() from exc\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py:352, in Call._run_sync(***failed resolving arguments***)\n    350 with self.future.enforce_sync_deadline() as cancel_scope:\n    351     try:\n--&gt; 352         result = self.fn(*self.args, **self.kwargs)\n    353     finally:\n    354         # Forget this call's arguments in order to free up any memory\n    355         # that may be referenced by them; after a call has happened,\n    356         # there's no need to keep a reference to them\n    357         self.args = None\n\nCell In[24], line 22, in get_data_flow()\n     20 @flow\n     21 def get_data_flow():\n---&gt; 22     get_data_task()\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/tasks.py:600, in Task.__call__(self, return_state, wait_for, *args, **kwargs)\n    589     from prefect import get_client\n    591     return submit_autonomous_task_run_to_engine(\n    592         task=self,\n    593         task_run=None,\n   (...)\n    597         client=get_client(),\n    598     )\n--&gt; 600 return enter_task_run_engine(\n    601     self,\n    602     parameters=parameters,\n    603     wait_for=wait_for,\n    604     task_runner=SequentialTaskRunner(),\n    605     return_type=return_type,\n    606     mapped=False,\n    607 )\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/engine.py:1421, in enter_task_run_engine(task, parameters, wait_for, return_type, task_runner, mapped)\n   1419     return from_async.wait_for_call_in_loop_thread(begin_run)\n   1420 else:\n-&gt; 1421     return from_sync.wait_for_call_in_loop_thread(begin_run)\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/api.py:243, in from_sync.wait_for_call_in_loop_thread(_from_sync__call, timeout, done_callbacks, contexts)\n    241     stack.enter_context(context)\n    242 waiter.wait()\n--&gt; 243 return call.result()\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py:318, in Call.result(self, timeout)\n    312 def result(self, timeout: Optional[float] = None) -&gt; T:\n    313     \"\"\"\n    314     Wait for the result of the call.\n    315 \n    316     Not safe for use from asynchronous contexts.\n    317     \"\"\"\n--&gt; 318     return self.future.result(timeout=timeout)\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py:179, in Future.result(self, timeout)\n    177     raise CancelledError()\n    178 elif self._state == FINISHED:\n--&gt; 179     return self.__get_result()\n    181 self._condition.wait(timeout)\n    183 if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:\n    184     # Raise Prefect cancelled error instead of\n    185     # `concurrent.futures._base.CancelledError`\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/concurrent/futures/_base.py:401, in Future.__get_result(self)\n    399 if self._exception:\n    400     try:\n--&gt; 401         raise self._exception\n    402     finally:\n    403         # Break a reference cycle with the exception in self._exception\n    404         self = None\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py:389, in Call._run_async(***failed resolving arguments***)\n    387 with self.future.enforce_async_deadline() as cancel_scope:\n    388     try:\n--&gt; 389         result = await coro\n    390     finally:\n    391         # Forget this call's arguments in order to free up any memory\n    392         # that may be referenced by them; after a call has happened,\n    393         # there's no need to keep a reference to them\n    394         self.args = None\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/engine.py:1601, in get_task_call_return_value(task, flow_run_context, parameters, wait_for, return_type, task_runner, extra_task_inputs)\n   1599     return await future._wait()\n   1600 elif return_type == \"result\":\n-&gt; 1601     return await future._result()\n   1602 else:\n   1603     raise ValueError(f\"Invalid return type for task engine {return_type!r}.\")\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/futures.py:237, in PrefectFuture._result(self, timeout, raise_on_failure)\n    235 if not final_state:\n    236     raise TimeoutError(\"Call timed out before task finished.\")\n--&gt; 237 return await final_state.result(raise_on_failure=raise_on_failure, fetch=True)\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/states.py:91, in _get_state_result(state, raise_on_failure)\n     84     raise UnfinishedRun(\n     85         f\"Run is in {state.type.name} state, its result is not available.\"\n     86     )\n     88 if raise_on_failure and (\n     89     state.is_crashed() or state.is_failed() or state.is_cancelled()\n     90 ):\n---&gt; 91     raise await get_state_exception(state)\n     93 if isinstance(state.data, DataDocument):\n     94     result = result_from_state_with_data_document(\n     95         state, raise_on_failure=raise_on_failure\n     96     )\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/engine.py:2147, in orchestrate_task_run(task, task_run, parameters, wait_for, result_factory, log_prints, interruptible, client)\n   2140         logger.debug(\n   2141             \"Beginning execution...\", extra={\"state_message\": True}\n   2142         )\n   2144     call = from_async.call_soon_in_new_thread(\n   2145         create_call(task.fn, *args, **kwargs), timeout=task.timeout_seconds\n   2146     )\n-&gt; 2147     result = await call.aresult()\n   2149 except (CancelledError, asyncio.CancelledError) as exc:\n   2150     if not call.timedout():\n   2151         # If the task call was not cancelled by us; this is a crash\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py:327, in Call.aresult(self)\n    321 \"\"\"\n    322 Wait for the result of the call.\n    323 \n    324 For use from asynchronous contexts.\n    325 \"\"\"\n    326 try:\n--&gt; 327     return await asyncio.wrap_future(self.future)\n    328 except asyncio.CancelledError as exc:\n    329     raise CancelledError() from exc\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py:352, in Call._run_sync(***failed resolving arguments***)\n    350 with self.future.enforce_sync_deadline() as cancel_scope:\n    351     try:\n--&gt; 352         result = self.fn(*self.args, **self.kwargs)\n    353     finally:\n    354         # Forget this call's arguments in order to free up any memory\n    355         # that may be referenced by them; after a call has happened,\n    356         # there's no need to keep a reference to them\n    357         self.args = None\n\nCell In[24], line 10, in get_data_task(url)\n      6 @task(retries=2, retry_delay_seconds=5)\n      7 def get_data_task(\n      8     url: str = \"https://api.brittle-service.com/endpoint\"\n      9 ) -&gt; dict:\n---&gt; 10     response = httpx.get(url)\n     12     # If the response status code is anything but a 2xx, httpx will raise\n     13     # an exception. This task doesn't handle the exception, so Prefect will\n     14     # catch the exception and will consider the task run failed.\n     15     response.raise_for_status()\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_api.py:198, in get(url, params, headers, cookies, auth, proxy, proxies, follow_redirects, cert, verify, timeout, trust_env)\n    175 def get(\n    176     url: URLTypes,\n    177     *,\n   (...)\n    188     trust_env: bool = True,\n    189 ) -&gt; Response:\n    190     \"\"\"\n    191     Sends a `GET` request.\n    192 \n   (...)\n    196     on this function, as `GET` requests should not include a request body.\n    197     \"\"\"\n--&gt; 198     return request(\n    199         \"GET\",\n    200         url,\n    201         params=params,\n    202         headers=headers,\n    203         cookies=cookies,\n    204         auth=auth,\n    205         proxy=proxy,\n    206         proxies=proxies,\n    207         follow_redirects=follow_redirects,\n    208         cert=cert,\n    209         verify=verify,\n    210         timeout=timeout,\n    211         trust_env=trust_env,\n    212     )\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_api.py:106, in request(method, url, params, content, data, files, json, headers, cookies, auth, proxy, proxies, timeout, follow_redirects, verify, cert, trust_env)\n     46 \"\"\"\n     47 Sends an HTTP request.\n     48 \n   (...)\n     95 ```\n     96 \"\"\"\n     97 with Client(\n     98     cookies=cookies,\n     99     proxy=proxy,\n   (...)\n    104     trust_env=trust_env,\n    105 ) as client:\n--&gt; 106     return client.request(\n    107         method=method,\n    108         url=url,\n    109         content=content,\n    110         data=data,\n    111         files=files,\n    112         json=json,\n    113         params=params,\n    114         headers=headers,\n    115         auth=auth,\n    116         follow_redirects=follow_redirects,\n    117     )\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_client.py:827, in Client.request(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\n    812     warnings.warn(message, DeprecationWarning)\n    814 request = self.build_request(\n    815     method=method,\n    816     url=url,\n   (...)\n    825     extensions=extensions,\n    826 )\n--&gt; 827 return self.send(request, auth=auth, follow_redirects=follow_redirects)\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_client.py:914, in Client.send(self, request, stream, auth, follow_redirects)\n    906 follow_redirects = (\n    907     self.follow_redirects\n    908     if isinstance(follow_redirects, UseClientDefault)\n    909     else follow_redirects\n    910 )\n    912 auth = self._build_request_auth(request, auth)\n--&gt; 914 response = self._send_handling_auth(\n    915     request,\n    916     auth=auth,\n    917     follow_redirects=follow_redirects,\n    918     history=[],\n    919 )\n    920 try:\n    921     if not stream:\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_client.py:942, in Client._send_handling_auth(self, request, auth, follow_redirects, history)\n    939 request = next(auth_flow)\n    941 while True:\n--&gt; 942     response = self._send_handling_redirects(\n    943         request,\n    944         follow_redirects=follow_redirects,\n    945         history=history,\n    946     )\n    947     try:\n    948         try:\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_client.py:979, in Client._send_handling_redirects(self, request, follow_redirects, history)\n    976 for hook in self._event_hooks[\"request\"]:\n    977     hook(request)\n--&gt; 979 response = self._send_single_request(request)\n    980 try:\n    981     for hook in self._event_hooks[\"response\"]:\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_client.py:1015, in Client._send_single_request(self, request)\n   1010     raise RuntimeError(\n   1011         \"Attempted to send an async request with a sync Client instance.\"\n   1012     )\n   1014 with request_context(request=request):\n-&gt; 1015     response = transport.handle_request(request)\n   1017 assert isinstance(response.stream, SyncByteStream)\n   1019 response.request = request\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_transports/default.py:232, in HTTPTransport.handle_request(self, request)\n    218 assert isinstance(request.stream, SyncByteStream)\n    220 req = httpcore.Request(\n    221     method=request.method,\n    222     url=httpcore.URL(\n   (...)\n    230     extensions=request.extensions,\n    231 )\n--&gt; 232 with map_httpcore_exceptions():\n    233     resp = self._pool.handle_request(req)\n    235 assert isinstance(resp.stream, typing.Iterable)\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/contextlib.py:155, in _GeneratorContextManager.__exit__(self, typ, value, traceback)\n    153     value = typ()\n    154 try:\n--&gt; 155     self.gen.throw(typ, value, traceback)\n    156 except StopIteration as exc:\n    157     # Suppress StopIteration *unless* it's the same exception that\n    158     # was passed to throw().  This prevents a StopIteration\n    159     # raised inside the \"with\" statement from being suppressed.\n    160     return exc is not value\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_transports/default.py:86, in map_httpcore_exceptions()\n     83     raise\n     85 message = str(exc)\n---&gt; 86 raise mapped_exc(message) from exc\n\nConnectError: [Errno -2] Name or service not known\n\n\n\n\nimport httpx\nfrom prefect import flow, task\n\ndef retry_handler(task, task_run, state) -&gt; bool:\n    \"\"\"This is a custom retry handler to handle when we want to retry a task\"\"\"\n    try:\n        # Attempt to get the result of the task\n        state.result()\n    except httpx.HTTPStatusError as exc:\n        # Retry on any HTTP status code that is not 401 or 404\n        do_not_retry_on_these_codes = [401, 404]\n        return exc.response.status_code not in do_not_retry_on_these_codes\n    except httpx.ConnectError:\n        # Do not retry\n        return False\n    except:\n        # For any other exception, retry\n        return True\n\n@task(retries=1, retry_condition_fn=retry_handler)\ndef my_api_call_task(url):\n    response = httpx.get(url)\n    response.raise_for_status()\n    return response.json()\n\n@flow\ndef get_data_flow(url):\n    my_api_call_task(url=url)\n\nif __name__ == \"__main__\":\n    get_data_flow(url=\"https://httpbin.org/status/503\")\n\n/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/flows.py:357: UserWarning: A flow named 'get-data-flow' and defined at '/tmp/ipykernel_23433/2972459076.py:26' conflicts with another flow. Consider specifying a unique `name` parameter in the flow definition:\n\n `@flow(name='my_unique_name', ...)`\n  warnings.warn(\n\n\n19:16:36.208 | INFO    | prefect.engine - Created flow run 'brilliant-bustard' for flow 'get-data-flow'\n\n\n\n19:16:36.271 | INFO    | Flow run 'brilliant-bustard' - Created task run 'my_api_call_task-0' for task 'my_api_call_task'\n\n\n\n19:16:36.273 | INFO    | Flow run 'brilliant-bustard' - Executing 'my_api_call_task-0' immediately...\n\n\n\n19:16:37.330 | ERROR   | Task run 'my_api_call_task-0' - Encountered exception during execution:\nTraceback (most recent call last):\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/engine.py\", line 2147, in orchestrate_task_run\n    result = await call.aresult()\n             ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py\", line 327, in aresult\n    return await asyncio.wrap_future(self.future)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py\", line 352, in _run_sync\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_23433/2972459076.py\", line 23, in my_api_call_task\n    response.raise_for_status()\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_models.py\", line 761, in raise_for_status\n    raise HTTPStatusError(message, request=request, response=self)\nhttpx.HTTPStatusError: Server error '503 SERVICE UNAVAILABLE' for url 'https://httpbin.org/status/503'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/503\n\n\n\n19:16:37.360 | INFO    | Task run 'my_api_call_task-0' - Received non-final state 'AwaitingRetry' when proposing final state 'Failed' and will attempt to run again...\n\n\n\n19:16:38.386 | ERROR   | Task run 'my_api_call_task-0' - Encountered exception during execution:\nTraceback (most recent call last):\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/engine.py\", line 2147, in orchestrate_task_run\n    result = await call.aresult()\n             ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py\", line 327, in aresult\n    return await asyncio.wrap_future(self.future)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py\", line 352, in _run_sync\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_23433/2972459076.py\", line 23, in my_api_call_task\n    response.raise_for_status()\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_models.py\", line 761, in raise_for_status\n    raise HTTPStatusError(message, request=request, response=self)\nhttpx.HTTPStatusError: Server error '503 SERVICE UNAVAILABLE' for url 'https://httpbin.org/status/503'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/503\n\n\n\n19:16:38.415 | ERROR   | Task run 'my_api_call_task-0' - Finished in state Failed(\"Task run encountered an exception HTTPStatusError: Server error '503 SERVICE UNAVAILABLE' for url 'https://httpbin.org/status/503'\\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/503\")\n\n\n\n19:16:38.418 | ERROR   | Flow run 'brilliant-bustard' - Encountered exception during execution:\nTraceback (most recent call last):\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/engine.py\", line 867, in orchestrate_flow_run\n    result = await flow_call.aresult()\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py\", line 327, in aresult\n    return await asyncio.wrap_future(self.future)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py\", line 352, in _run_sync\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_23433/2972459076.py\", line 28, in get_data_flow\n    my_api_call_task(url=url)\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/tasks.py\", line 600, in __call__\n    return enter_task_run_engine(\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/engine.py\", line 1421, in enter_task_run_engine\n    return from_sync.wait_for_call_in_loop_thread(begin_run)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/api.py\", line 243, in wait_for_call_in_loop_thread\n    return call.result()\n           ^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py\", line 318, in result\n    return self.future.result(timeout=timeout)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py\", line 179, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py\", line 389, in _run_async\n    result = await coro\n             ^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/engine.py\", line 1601, in get_task_call_return_value\n    return await future._result()\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/futures.py\", line 237, in _result\n    return await final_state.result(raise_on_failure=raise_on_failure, fetch=True)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/states.py\", line 91, in _get_state_result\n    raise await get_state_exception(state)\n  File \"/tmp/ipykernel_23433/2972459076.py\", line 8, in retry_handler\n    state.result()\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/client/schemas/objects.py\", line 224, in result\n    return get_state_result(self, raise_on_failure=raise_on_failure, fetch=fetch)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/states.py\", line 71, in get_state_result\n    return _get_state_result(state, raise_on_failure=raise_on_failure)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/utilities/asyncutils.py\", line 259, in coroutine_wrapper\n    return call()\n           ^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py\", line 432, in __call__\n    return self.result()\n           ^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py\", line 318, in result\n    return self.future.result(timeout=timeout)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py\", line 179, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py\", line 389, in _run_async\n    result = await coro\n             ^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/states.py\", line 91, in _get_state_result\n    raise await get_state_exception(state)\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/engine.py\", line 2147, in orchestrate_task_run\n    result = await call.aresult()\n             ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py\", line 327, in aresult\n    return await asyncio.wrap_future(self.future)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py\", line 352, in _run_sync\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_23433/2972459076.py\", line 23, in my_api_call_task\n    response.raise_for_status()\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_models.py\", line 761, in raise_for_status\n    raise HTTPStatusError(message, request=request, response=self)\nhttpx.HTTPStatusError: Server error '503 SERVICE UNAVAILABLE' for url 'https://httpbin.org/status/503'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/503\n\n\n\n19:16:38.449 | ERROR   | Flow run 'brilliant-bustard' - Finished in state Failed(\"Flow run encountered an exception. HTTPStatusError: Server error '503 SERVICE UNAVAILABLE' for url 'https://httpbin.org/status/503'\\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/503\")\n\n\n\n\n---------------------------------------------------------------------------\nHTTPStatusError                           Traceback (most recent call last)\nCell In[26], line 31\n     28     my_api_call_task(url=url)\n     30 if __name__ == \"__main__\":\n---&gt; 31     get_data_flow(url=\"https://httpbin.org/status/503\")\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/flows.py:1224, in Flow.__call__(self, return_state, wait_for, *args, **kwargs)\n   1219 if task_viz_tracker:\n   1220     # this is a subflow, for now return a single task and do not go further\n   1221     # we can add support for exploring subflows for tasks in the future.\n   1222     return track_viz_task(self.isasync, self.name, parameters)\n-&gt; 1224 return enter_flow_run_engine_from_flow_call(\n   1225     self,\n   1226     parameters,\n   1227     wait_for=wait_for,\n   1228     return_type=return_type,\n   1229 )\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/engine.py:297, in enter_flow_run_engine_from_flow_call(flow, parameters, wait_for, return_type)\n    290     retval = from_async.wait_for_call_in_loop_thread(\n    291         begin_run,\n    292         done_callbacks=done_callbacks,\n    293         contexts=contexts,\n    294     )\n    296 else:\n--&gt; 297     retval = from_sync.wait_for_call_in_loop_thread(\n    298         begin_run,\n    299         done_callbacks=done_callbacks,\n    300         contexts=contexts,\n    301     )\n    303 return retval\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/api.py:243, in from_sync.wait_for_call_in_loop_thread(_from_sync__call, timeout, done_callbacks, contexts)\n    241     stack.enter_context(context)\n    242 waiter.wait()\n--&gt; 243 return call.result()\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py:318, in Call.result(self, timeout)\n    312 def result(self, timeout: Optional[float] = None) -&gt; T:\n    313     \"\"\"\n    314     Wait for the result of the call.\n    315 \n    316     Not safe for use from asynchronous contexts.\n    317     \"\"\"\n--&gt; 318     return self.future.result(timeout=timeout)\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py:179, in Future.result(self, timeout)\n    177     raise CancelledError()\n    178 elif self._state == FINISHED:\n--&gt; 179     return self.__get_result()\n    181 self._condition.wait(timeout)\n    183 if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:\n    184     # Raise Prefect cancelled error instead of\n    185     # `concurrent.futures._base.CancelledError`\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/concurrent/futures/_base.py:401, in Future.__get_result(self)\n    399 if self._exception:\n    400     try:\n--&gt; 401         raise self._exception\n    402     finally:\n    403         # Break a reference cycle with the exception in self._exception\n    404         self = None\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py:389, in Call._run_async(***failed resolving arguments***)\n    387 with self.future.enforce_async_deadline() as cancel_scope:\n    388     try:\n--&gt; 389         result = await coro\n    390     finally:\n    391         # Forget this call's arguments in order to free up any memory\n    392         # that may be referenced by them; after a call has happened,\n    393         # there's no need to keep a reference to them\n    394         self.args = None\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/client/utilities.py:78, in inject_client.&lt;locals&gt;.with_injected_client(*args, **kwargs)\n     76 async with context as new_client:\n     77     kwargs.setdefault(\"client\", new_client or client)\n---&gt; 78     return await fn(*args, **kwargs)\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/engine.py:400, in create_then_begin_flow_run(flow, parameters, wait_for, return_type, client, user_thread)\n    398     return state\n    399 elif return_type == \"result\":\n--&gt; 400     return await state.result(fetch=True)\n    401 else:\n    402     raise ValueError(f\"Invalid return type for flow engine {return_type!r}.\")\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/states.py:91, in _get_state_result(state, raise_on_failure)\n     84     raise UnfinishedRun(\n     85         f\"Run is in {state.type.name} state, its result is not available.\"\n     86     )\n     88 if raise_on_failure and (\n     89     state.is_crashed() or state.is_failed() or state.is_cancelled()\n     90 ):\n---&gt; 91     raise await get_state_exception(state)\n     93 if isinstance(state.data, DataDocument):\n     94     result = result_from_state_with_data_document(\n     95         state, raise_on_failure=raise_on_failure\n     96     )\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/engine.py:867, in orchestrate_flow_run(flow, flow_run, parameters, wait_for, interruptible, client, partial_flow_run_context, user_thread)\n    862         else:\n    863             from_async.call_soon_in_new_thread(\n    864                 flow_call, timeout=flow.timeout_seconds\n    865             )\n--&gt; 867         result = await flow_call.aresult()\n    869         waited_for_task_runs = await wait_for_task_runs_and_report_crashes(\n    870             flow_run_context.task_run_futures, client=client\n    871         )\n    872 except PausedRun as exc:\n    873     # could get raised either via utility or by returning Paused from a task run\n    874     # if a task run pauses, we set its state as the flow's state\n    875     # to preserve reschedule and timeout behavior\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py:327, in Call.aresult(self)\n    321 \"\"\"\n    322 Wait for the result of the call.\n    323 \n    324 For use from asynchronous contexts.\n    325 \"\"\"\n    326 try:\n--&gt; 327     return await asyncio.wrap_future(self.future)\n    328 except asyncio.CancelledError as exc:\n    329     raise CancelledError() from exc\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py:352, in Call._run_sync(***failed resolving arguments***)\n    350 with self.future.enforce_sync_deadline() as cancel_scope:\n    351     try:\n--&gt; 352         result = self.fn(*self.args, **self.kwargs)\n    353     finally:\n    354         # Forget this call's arguments in order to free up any memory\n    355         # that may be referenced by them; after a call has happened,\n    356         # there's no need to keep a reference to them\n    357         self.args = None\n\nCell In[26], line 28, in get_data_flow(url)\n     26 @flow\n     27 def get_data_flow(url):\n---&gt; 28     my_api_call_task(url=url)\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/tasks.py:600, in Task.__call__(self, return_state, wait_for, *args, **kwargs)\n    589     from prefect import get_client\n    591     return submit_autonomous_task_run_to_engine(\n    592         task=self,\n    593         task_run=None,\n   (...)\n    597         client=get_client(),\n    598     )\n--&gt; 600 return enter_task_run_engine(\n    601     self,\n    602     parameters=parameters,\n    603     wait_for=wait_for,\n    604     task_runner=SequentialTaskRunner(),\n    605     return_type=return_type,\n    606     mapped=False,\n    607 )\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/engine.py:1421, in enter_task_run_engine(task, parameters, wait_for, return_type, task_runner, mapped)\n   1419     return from_async.wait_for_call_in_loop_thread(begin_run)\n   1420 else:\n-&gt; 1421     return from_sync.wait_for_call_in_loop_thread(begin_run)\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/api.py:243, in from_sync.wait_for_call_in_loop_thread(_from_sync__call, timeout, done_callbacks, contexts)\n    241     stack.enter_context(context)\n    242 waiter.wait()\n--&gt; 243 return call.result()\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py:318, in Call.result(self, timeout)\n    312 def result(self, timeout: Optional[float] = None) -&gt; T:\n    313     \"\"\"\n    314     Wait for the result of the call.\n    315 \n    316     Not safe for use from asynchronous contexts.\n    317     \"\"\"\n--&gt; 318     return self.future.result(timeout=timeout)\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py:179, in Future.result(self, timeout)\n    177     raise CancelledError()\n    178 elif self._state == FINISHED:\n--&gt; 179     return self.__get_result()\n    181 self._condition.wait(timeout)\n    183 if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:\n    184     # Raise Prefect cancelled error instead of\n    185     # `concurrent.futures._base.CancelledError`\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/concurrent/futures/_base.py:401, in Future.__get_result(self)\n    399 if self._exception:\n    400     try:\n--&gt; 401         raise self._exception\n    402     finally:\n    403         # Break a reference cycle with the exception in self._exception\n    404         self = None\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py:389, in Call._run_async(***failed resolving arguments***)\n    387 with self.future.enforce_async_deadline() as cancel_scope:\n    388     try:\n--&gt; 389         result = await coro\n    390     finally:\n    391         # Forget this call's arguments in order to free up any memory\n    392         # that may be referenced by them; after a call has happened,\n    393         # there's no need to keep a reference to them\n    394         self.args = None\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/engine.py:1601, in get_task_call_return_value(task, flow_run_context, parameters, wait_for, return_type, task_runner, extra_task_inputs)\n   1599     return await future._wait()\n   1600 elif return_type == \"result\":\n-&gt; 1601     return await future._result()\n   1602 else:\n   1603     raise ValueError(f\"Invalid return type for task engine {return_type!r}.\")\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/futures.py:237, in PrefectFuture._result(self, timeout, raise_on_failure)\n    235 if not final_state:\n    236     raise TimeoutError(\"Call timed out before task finished.\")\n--&gt; 237 return await final_state.result(raise_on_failure=raise_on_failure, fetch=True)\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/states.py:91, in _get_state_result(state, raise_on_failure)\n     84     raise UnfinishedRun(\n     85         f\"Run is in {state.type.name} state, its result is not available.\"\n     86     )\n     88 if raise_on_failure and (\n     89     state.is_crashed() or state.is_failed() or state.is_cancelled()\n     90 ):\n---&gt; 91     raise await get_state_exception(state)\n     93 if isinstance(state.data, DataDocument):\n     94     result = result_from_state_with_data_document(\n     95         state, raise_on_failure=raise_on_failure\n     96     )\n\nCell In[26], line 8, in retry_handler(task, task_run, state)\n      5 \"\"\"This is a custom retry handler to handle when we want to retry a task\"\"\"\n      6 try:\n      7     # Attempt to get the result of the task\n----&gt; 8     state.result()\n      9 except httpx.HTTPStatusError as exc:\n     10     # Retry on any HTTP status code that is not 401 or 404\n     11     do_not_retry_on_these_codes = [401, 404]\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/client/schemas/objects.py:224, in State.result(self, raise_on_failure, fetch)\n    152 \"\"\"\n    153 Retrieve the result attached to this state.\n    154 \n   (...)\n    220     hello\n    221 \"\"\"\n    222 from prefect.states import get_state_result\n--&gt; 224 return get_state_result(self, raise_on_failure=raise_on_failure, fetch=fetch)\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/states.py:71, in get_state_result(state, raise_on_failure, fetch)\n     69         return state.data\n     70 else:\n---&gt; 71     return _get_state_result(state, raise_on_failure=raise_on_failure)\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/utilities/asyncutils.py:259, in sync_compatible.&lt;locals&gt;.coroutine_wrapper(*args, **kwargs)\n    257 # Run in a new event loop, but use a `Call` for nested context detection\n    258 call = create_call(async_fn, *args, **kwargs)\n--&gt; 259 return call()\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py:432, in Call.__call__(self)\n    430     return run_and_return_result()\n    431 else:\n--&gt; 432     return self.result()\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py:318, in Call.result(self, timeout)\n    312 def result(self, timeout: Optional[float] = None) -&gt; T:\n    313     \"\"\"\n    314     Wait for the result of the call.\n    315 \n    316     Not safe for use from asynchronous contexts.\n    317     \"\"\"\n--&gt; 318     return self.future.result(timeout=timeout)\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py:179, in Future.result(self, timeout)\n    177     raise CancelledError()\n    178 elif self._state == FINISHED:\n--&gt; 179     return self.__get_result()\n    181 self._condition.wait(timeout)\n    183 if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:\n    184     # Raise Prefect cancelled error instead of\n    185     # `concurrent.futures._base.CancelledError`\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/concurrent/futures/_base.py:401, in Future.__get_result(self)\n    399 if self._exception:\n    400     try:\n--&gt; 401         raise self._exception\n    402     finally:\n    403         # Break a reference cycle with the exception in self._exception\n    404         self = None\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py:389, in Call._run_async(***failed resolving arguments***)\n    387 with self.future.enforce_async_deadline() as cancel_scope:\n    388     try:\n--&gt; 389         result = await coro\n    390     finally:\n    391         # Forget this call's arguments in order to free up any memory\n    392         # that may be referenced by them; after a call has happened,\n    393         # there's no need to keep a reference to them\n    394         self.args = None\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/states.py:91, in _get_state_result(state, raise_on_failure)\n     84     raise UnfinishedRun(\n     85         f\"Run is in {state.type.name} state, its result is not available.\"\n     86     )\n     88 if raise_on_failure and (\n     89     state.is_crashed() or state.is_failed() or state.is_cancelled()\n     90 ):\n---&gt; 91     raise await get_state_exception(state)\n     93 if isinstance(state.data, DataDocument):\n     94     result = result_from_state_with_data_document(\n     95         state, raise_on_failure=raise_on_failure\n     96     )\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/engine.py:2147, in orchestrate_task_run(task, task_run, parameters, wait_for, result_factory, log_prints, interruptible, client)\n   2140         logger.debug(\n   2141             \"Beginning execution...\", extra={\"state_message\": True}\n   2142         )\n   2144     call = from_async.call_soon_in_new_thread(\n   2145         create_call(task.fn, *args, **kwargs), timeout=task.timeout_seconds\n   2146     )\n-&gt; 2147     result = await call.aresult()\n   2149 except (CancelledError, asyncio.CancelledError) as exc:\n   2150     if not call.timedout():\n   2151         # If the task call was not cancelled by us; this is a crash\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py:327, in Call.aresult(self)\n    321 \"\"\"\n    322 Wait for the result of the call.\n    323 \n    324 For use from asynchronous contexts.\n    325 \"\"\"\n    326 try:\n--&gt; 327     return await asyncio.wrap_future(self.future)\n    328 except asyncio.CancelledError as exc:\n    329     raise CancelledError() from exc\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py:352, in Call._run_sync(***failed resolving arguments***)\n    350 with self.future.enforce_sync_deadline() as cancel_scope:\n    351     try:\n--&gt; 352         result = self.fn(*self.args, **self.kwargs)\n    353     finally:\n    354         # Forget this call's arguments in order to free up any memory\n    355         # that may be referenced by them; after a call has happened,\n    356         # there's no need to keep a reference to them\n    357         self.args = None\n\nCell In[26], line 23, in my_api_call_task(url)\n     20 @task(retries=1, retry_condition_fn=retry_handler)\n     21 def my_api_call_task(url):\n     22     response = httpx.get(url)\n---&gt; 23     response.raise_for_status()\n     24     return response.json()\n\nFile ~/mambaforge/envs/cfast/lib/python3.11/site-packages/httpx/_models.py:761, in Response.raise_for_status(self)\n    759 error_type = error_types.get(status_class, \"Invalid status code\")\n    760 message = message.format(self, error_type=error_type)\n--&gt; 761 raise HTTPStatusError(message, request=request, response=self)\n\nHTTPStatusError: Server error '503 SERVICE UNAVAILABLE' for url 'https://httpbin.org/status/503'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/503",
    "crumbs": [
      "Blog",
      "Prefect"
    ]
  },
  {
    "objectID": "prefect.html#timeouts",
    "href": "prefect.html#timeouts",
    "title": "Prefect",
    "section": "Timeouts",
    "text": "Timeouts\n\nfrom prefect import task, get_run_logger\nimport time\n\n@task(timeout_seconds=1)\ndef show_timeouts():\n    logger = get_run_logger()\n    logger.info(\"I will execute\")\n    time.sleep(5)\n    logger.info(\"I will not execute\")",
    "crumbs": [
      "Blog",
      "Prefect"
    ]
  },
  {
    "objectID": "prefect.html#wait-for",
    "href": "prefect.html#wait-for",
    "title": "Prefect",
    "section": "Wait for",
    "text": "Wait for\n\n@task\ndef task_1():\n    pass\n\n@task\ndef task_2():\n    pass\n\n@flow\ndef my_flow():\n    x = task_1()\n\n    # task 2 will wait for task_1 to complete\n    y = task_2(wait_for=[x])\n\n/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/flows.py:357: UserWarning: A flow named 'my-flow' and defined at '/tmp/ipykernel_23433/1697639020.py:9' conflicts with another flow. Consider specifying a unique `name` parameter in the flow definition:\n\n `@flow(name='my_unique_name', ...)`\n  warnings.warn(",
    "crumbs": [
      "Blog",
      "Prefect"
    ]
  },
  {
    "objectID": "prefect.html#maps",
    "href": "prefect.html#maps",
    "title": "Prefect",
    "section": "Maps",
    "text": "Maps\n\nfrom prefect import flow, task\n\n@task\ndef print_nums(nums):\n    for n in nums:\n        print(n)\n\n@task\ndef square_num(num):\n    return num**2\n\n@flow\ndef map_flow(nums):\n    print_nums(nums)\n    squared_nums = square_num.map(nums) \n    print_nums(squared_nums)\n\nmap_flow([1,2,3,5,8,13])\n\n19:23:30.843 | INFO    | prefect.engine - Created flow run 'stereotyped-wolf' for flow 'map-flow'\n\n\n\n19:23:30.904 | INFO    | Flow run 'stereotyped-wolf' - Created task run 'print_nums-0' for task 'print_nums'\n\n\n\n19:23:30.906 | INFO    | Flow run 'stereotyped-wolf' - Executing 'print_nums-0' immediately...\n\n\n\n1\n2\n3\n5\n8\n13\n\n\n19:23:30.981 | INFO    | Task run 'print_nums-0' - Finished in state Completed()\n\n\n\n19:23:31.067 | INFO    | Flow run 'stereotyped-wolf' - Created task run 'square_num-3' for task 'square_num'\n\n\n\n19:23:31.069 | INFO    | Flow run 'stereotyped-wolf' - Submitted task run 'square_num-3' for execution.\n\n\n\n19:23:31.085 | INFO    | Flow run 'stereotyped-wolf' - Created task run 'square_num-2' for task 'square_num'\n\n\n\n19:23:31.087 | INFO    | Flow run 'stereotyped-wolf' - Submitted task run 'square_num-2' for execution.\n\n\n\n19:23:31.105 | INFO    | Flow run 'stereotyped-wolf' - Created task run 'square_num-4' for task 'square_num'\n\n\n\n19:23:31.106 | INFO    | Flow run 'stereotyped-wolf' - Submitted task run 'square_num-4' for execution.\n\n\n\n19:23:31.176 | INFO    | Flow run 'stereotyped-wolf' - Created task run 'square_num-1' for task 'square_num'\n\n\n\n19:23:31.179 | INFO    | Flow run 'stereotyped-wolf' - Submitted task run 'square_num-1' for execution.\n\n\n\n19:23:31.216 | INFO    | Task run 'square_num-3' - Finished in state Completed()\n\n\n\n19:23:31.233 | INFO    | Task run 'square_num-4' - Finished in state Completed()\n\n\n\n19:23:31.244 | INFO    | Flow run 'stereotyped-wolf' - Created task run 'square_num-5' for task 'square_num'\n\n\n\n19:23:31.246 | INFO    | Flow run 'stereotyped-wolf' - Submitted task run 'square_num-5' for execution.\n\n\n\n19:23:31.331 | INFO    | Task run 'square_num-5' - Finished in state Completed()\n\n\n\n19:23:31.352 | INFO    | Task run 'square_num-1' - Finished in state Completed()\n\n\n\n19:23:31.396 | INFO    | Flow run 'stereotyped-wolf' - Created task run 'square_num-0' for task 'square_num'\n\n\n\n19:23:31.399 | INFO    | Flow run 'stereotyped-wolf' - Submitted task run 'square_num-0' for execution.\n\n\n\n19:23:31.452 | INFO    | Flow run 'stereotyped-wolf' - Created task run 'print_nums-1' for task 'print_nums'\n\n\n\n19:23:31.453 | INFO    | Flow run 'stereotyped-wolf' - Executing 'print_nums-1' immediately...\n\n\n\n19:23:31.477 | INFO    | Task run 'square_num-0' - Finished in state Completed()\n\n\n\n19:23:31.615 | INFO    | Task run 'square_num-2' - Finished in state Completed()\n\n\n\n1\n4\n9\n25\n64\n169\n\n\n19:23:31.681 | INFO    | Task run 'print_nums-1' - Finished in state Completed()\n\n\n\n19:23:31.710 | INFO    | Flow run 'stereotyped-wolf' - Finished in state Completed('All states completed.')\n\n\n\n[Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `NoneType`')),\n Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `int`')),\n Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `int`')),\n Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `int`')),\n Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `int`')),\n Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `int`')),\n Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `int`')),\n Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `NoneType`'))]",
    "crumbs": [
      "Blog",
      "Prefect"
    ]
  },
  {
    "objectID": "prefect.html#async",
    "href": "prefect.html#async",
    "title": "Prefect",
    "section": "Async",
    "text": "Async\n\nimport asyncio\n\nfrom prefect import task, flow\n\n@task\nasync def print_values(values):\n    for value in values:\n        await asyncio.sleep(1) # yield\n        print(value, end=\" \")\n\n@flow\nasync def async_flow():\n    await print_values([1, 2])  # runs immediately\n    coros = [print_values(\"abcd\"), print_values(\"6789\")]\n\n    # asynchronously gather the tasks\n    await asyncio.gather(*coros)\n\nasyncio.run(async_flow())\n\nfrom prefect import get_client\n\nasync with get_client() as client:\n    # set a concurrency limit of 10 on the 'small_instance' tag\n    limit_id = await client.create_concurrency_limit(\n        tag=\"small_instance\", \n        concurrency_limit=10\n        )\n\n\n!prefect concurrency-limit inspect small_instance\n\n‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ\n‚îÇ        Concurrency Limit ID: 879f2e40-8387-47c5-af34-0b164f7ea8bc        ‚îÇ\n‚îÇ ‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì ‚îÇ\n‚îÇ ‚îÉ Tag            ‚îÉ Concurrency Limit ‚îÉ Created        ‚îÉ Updated        ‚îÉ ‚îÇ\n‚îÇ ‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î© ‚îÇ\n‚îÇ ‚îÇ small_instance ‚îÇ 10                ‚îÇ '1 minute ago' ‚îÇ '1 minute ago' ‚îÇ ‚îÇ\n‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ\n‚îÇ ‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì                                                  ‚îÇ\n‚îÇ ‚îÉ Active Task Run IDs ‚îÉ                                                  ‚îÇ\n‚îÇ ‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©                                                  ‚îÇ\n‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                                  ‚îÇ\n‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ",
    "crumbs": [
      "Blog",
      "Prefect"
    ]
  },
  {
    "objectID": "prefect.html#deployments",
    "href": "prefect.html#deployments",
    "title": "Prefect",
    "section": "Deployments",
    "text": "Deployments\nname: prefect.yaml\n# Welcome to your prefect.yaml file! You can use this file for storing and managing\n# configuration for deploying your flows. We recommend committing this file to source\n# control along with your flow code.\n\n# Generic metadata about this project\nname: nbs\nprefect-version: 2.16.8\n\n# build section allows you to manage and build docker images\nbuild:\n\n# push section allows you to manage if and how this project is uploaded to remote locations\npush:\n\n# pull section allows you to provide instructions for cloning this project in remote locations\npull:\n- prefect.deployments.steps.git_clone:\n    repository: git@github.com:bthek1/MLtools.git\n    branch: main\n\n# the deployments section allows you to provide configuration for deploying flows\ndeployments:\n- name: slow_flow\n  version:\n  tags: []\n  description: Sleepy flow - sleeps the provided amount of time (in seconds).\n  entrypoint: nbs/prefect_deployment_serve.py:slow_flow\n  parameters: {}\n  work_pool:\n    name: test-pool\n    work_queue_name:\n    job_variables: {}\n  schedules:\n  - interval: 30.0\n    anchor_date: '2024-04-03T13:38:23.549390+00:00'\n    timezone: UTC\n    active: true\n- name: fast_flow\n  version:\n  tags: []\n  description: Fastest flow this side of the Mississippi.\n  entrypoint: nbs/prefect_deployment_serve.py:fast_flow\n  parameters: {}\n  work_pool:\n    name: test-pool\n    work_queue_name:\n    job_variables: {}\n  schedules:\n  - interval: 60.0\n    anchor_date: '2024-04-03T14:13:30.384393+00:00'\n    timezone: UTC\n    active: true\n  - interval: 150.0\n    anchor_date: '2024-04-03T14:13:45.806620+00:00'\n    timezone: UTC\n    active: false",
    "crumbs": [
      "Blog",
      "Prefect"
    ]
  },
  {
    "objectID": "prefect.html#work-pools-to-do",
    "href": "prefect.html#work-pools-to-do",
    "title": "Prefect",
    "section": "Work Pools : To do",
    "text": "Work Pools : To do\nWork pool overview¬∂\nWork pools organize work for execution. Work pools have types corresponding to the infrastructure that will execute the flow code, as well as the delivery method of work to that environment. Pull work pools require workers (or less ideally, agents) to poll the work pool for flow runs to execute. Push work pools can submit runs directly to your serverless infrastructure providers such as Google Cloud Run, Azure Container Instances, and AWS ECS without the need for an agent or worker.\nprefect work-pool create test-pool\n\n!prefect work-pool ls\n\n                                   Work Pools                                   \n‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ Name      ‚îÉ Type   ‚îÉ                                   ID ‚îÉ Concurrency Lim‚Ä¶ ‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ test-pool ‚îÇ proce‚Ä¶ ‚îÇ 5d41c025-ec45-4e64-9ef6-3ca91b9684e0 ‚îÇ None             ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                           (**) denotes a paused pool                           \n\n\n\n!prefect work-pool inspect 'test-pool'\n\nWorkPool(\n    id='5d41c025-ec45-4e64-9ef6-3ca91b9684e0',\n    created=DateTime(2024, 4, 3, 10, 12, 27, 298785, tzinfo=Timezone('+00:00')),\n    updated=DateTime(2024, 4, 3, 10, 12, 27, 306000, tzinfo=Timezone('+00:00')),\n    name='test-pool',\n    type='process',\n    base_job_template={\n        'job_configuration': {\n            'command': '{{ command }}',\n            'env': '{{ env }}',\n            'labels': '{{ labels }}',\n            'name': '{{ name }}',\n            'stream_output': '{{ stream_output }}',\n            'working_dir': '{{ working_dir }}'\n        },\n        'variables': {\n            'type': 'object',\n            'properties': {\n                'name': {\n                    'title': 'Name',\n                    'description': 'Name given to infrastructure created by a \nworker.',\n                    'type': 'string'\n                },\n                'env': {\n                    'title': 'Environment Variables',\n                    'description': 'Environment variables to set when starting a\nflow run.',\n                    'type': 'object',\n                    'additionalProperties': {'type': 'string'}\n                },\n                'labels': {\n                    'title': 'Labels',\n                    'description': 'Labels applied to infrastructure created by \na worker.',\n                    'type': 'object',\n                    'additionalProperties': {'type': 'string'}\n                },\n                'command': {\n                    'title': 'Command',\n                    'description': 'The command to use when starting a flow run.\nIn most cases, this should be left blank and the command will be automatically \ngenerated by the worker.',\n                    'type': 'string'\n                },\n                'stream_output': {\n                    'title': 'Stream Output',\n                    'description': 'If enabled, workers will stream output from \nflow run processes to local standard output.',\n                    'default': True,\n                    'type': 'boolean'\n                },\n                'working_dir': {\n                    'title': 'Working Directory',\n                    'description': 'If provided, workers will open flow run \nprocesses within the specified path as the working directory. Otherwise, a \ntemporary directory will be created.',\n                    'type': 'string',\n                    'format': 'path'\n                }\n            }\n        }\n    },\n    status=WorkPoolStatus.NOT_READY,\n    default_queue_id='12cd8c55-db98-4e1c-baf6-ffffcfbb613f'\n)",
    "crumbs": [
      "Blog",
      "Prefect"
    ]
  },
  {
    "objectID": "prefect.html#schedules-to-do",
    "href": "prefect.html#schedules-to-do",
    "title": "Prefect",
    "section": "Schedules : To do",
    "text": "Schedules : To do\nPrefect supports several types of schedules that cover a wide range of use cases and offer a large degree of customization:\n\nCron is most appropriate for users who are already familiar with cron from previous use.\nInterval is best suited for deployments that need to run at some consistent cadence that isn‚Äôt related to absolute time.\nRRule is best suited for deployments that rely on calendar logic for simple recurring schedules, irregular intervals, exclusions, or day-of-month adjustments.\n\n!!! tip ‚ÄúSchedules can be inactive‚Äù When you create or edit a schedule, you can set the active property to False in Python (or false in a YAML file) to deactivate the schedule. This is useful if you want to keep the schedule configuration but temporarily stop the schedule from creating new flow runs.",
    "crumbs": [
      "Blog",
      "Prefect"
    ]
  },
  {
    "objectID": "prefect.html#results",
    "href": "prefect.html#results",
    "title": "Prefect",
    "section": "Results",
    "text": "Results\n\nfrom prefect import flow, task\n\n@task\ndef my_task():\n    return 1\n\n@flow\ndef my_flow():\n    future = my_task.submit()\n    return future.result() + 1\n\nresult = my_flow()\nassert result == 2\n\n/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/tasks.py:348: UserWarning: A task named 'my_task' and defined at '/tmp/ipykernel_44036/1506838836.py:3' conflicts with another task. Consider specifying a unique `name` parameter in the task definition:\n\n `@task(name='my_unique_name', ...)`\n  warnings.warn(\n/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/flows.py:357: UserWarning: A flow named 'my-flow' and defined at '/tmp/ipykernel_44036/1506838836.py:7' conflicts with another flow. Consider specifying a unique `name` parameter in the flow definition:\n\n `@flow(name='my_unique_name', ...)`\n  warnings.warn(\n\n\n21:13:16.692 | INFO    | prefect.engine - Created flow run 'ultra-capuchin' for flow 'my-flow'\n\n\n\n21:13:16.756 | INFO    | Flow run 'ultra-capuchin' - Created task run 'my_task-0' for task 'my_task'\n\n\n\n21:13:16.758 | INFO    | Flow run 'ultra-capuchin' - Submitted task run 'my_task-0' for execution.\n\n\n\n21:13:16.833 | INFO    | Task run 'my_task-0' - Finished in state Completed()\n\n\n\n21:13:16.862 | INFO    | Flow run 'ultra-capuchin' - Finished in state Completed()\n\n\n\n\nError handling\n\nfrom prefect import flow, task\n\n@task\ndef my_task():\n    raise ValueError()\n\n@flow\ndef my_flow():\n    state = my_task(return_state=True)\n\n    if state.is_failed():\n        print(\"Oh no! The task failed. Falling back to '1'.\")\n        result = 1\n    else:\n        result = state.result()\n\n    return result + 1\n\nresult = my_flow()\nassert result == 2\n\n/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/tasks.py:348: UserWarning: A task named 'my_task' and defined at '/tmp/ipykernel_44036/2193582311.py:3' conflicts with another task. Consider specifying a unique `name` parameter in the task definition:\n\n `@task(name='my_unique_name', ...)`\n  warnings.warn(\n/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/flows.py:357: UserWarning: A flow named 'my-flow' and defined at '/tmp/ipykernel_44036/2193582311.py:7' conflicts with another flow. Consider specifying a unique `name` parameter in the flow definition:\n\n `@flow(name='my_unique_name', ...)`\n  warnings.warn(\n\n\n21:24:04.344 | INFO    | prefect.engine - Created flow run 'active-flamingo' for flow 'my-flow'\n\n\n\n21:24:04.406 | INFO    | Flow run 'active-flamingo' - Created task run 'my_task-0' for task 'my_task'\n\n\n\n21:24:04.407 | INFO    | Flow run 'active-flamingo' - Executing 'my_task-0' immediately...\n\n\n\n21:24:04.454 | ERROR   | Task run 'my_task-0' - Encountered exception during execution:\nTraceback (most recent call last):\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/engine.py\", line 2147, in orchestrate_task_run\n    result = await call.aresult()\n             ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py\", line 327, in aresult\n    return await asyncio.wrap_future(self.future)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/_internal/concurrency/calls.py\", line 352, in _run_sync\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_44036/2193582311.py\", line 5, in my_task\n    raise ValueError()\nValueError\n\n\n\n21:24:04.485 | ERROR   | Task run 'my_task-0' - Finished in state Failed('Task run encountered an exception ValueError: ')\n\n\n\nOh no! The task failed. Falling back to '1'.\n\n\n21:24:04.516 | INFO    | Flow run 'active-flamingo' - Finished in state Completed()",
    "crumbs": [
      "Blog",
      "Prefect"
    ]
  },
  {
    "objectID": "prefect.html#artifacts",
    "href": "prefect.html#artifacts",
    "title": "Prefect",
    "section": "Artifacts",
    "text": "Artifacts\n\nfrom prefect import flow, task\nfrom prefect.artifacts import create_link_artifact\n\n@task\ndef my_first_task():\n    create_link_artifact(\n        key=\"create-link-artifact\",\n        link=\"my_first_task\",\n        description=\"## my_first_task\",\n    )\n\n@task\ndef my_second_task():\n    create_link_artifact(\n        key=\"create-link-artifact\",\n        link=\"my_second_task\",\n        description=\"## my_second_task\",\n    )\n\n@flow\ndef my_flow():\n    create_link_artifact(\n        key=\"create-link-artifact\",\n        link=\"my_flow\",\n        description=\"## my_flow\",\n)\n    my_first_task()\n    my_second_task()\n\nif __name__ == \"__main__\":\n    my_flow()\n\n/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/tasks.py:348: UserWarning: A task named 'my_first_task' and defined at '/tmp/ipykernel_44036/2726054530.py:4' conflicts with another task. Consider specifying a unique `name` parameter in the task definition:\n\n `@task(name='my_unique_name', ...)`\n  warnings.warn(\n/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/tasks.py:348: UserWarning: A task named 'my_second_task' and defined at '/tmp/ipykernel_44036/2726054530.py:12' conflicts with another task. Consider specifying a unique `name` parameter in the task definition:\n\n `@task(name='my_unique_name', ...)`\n  warnings.warn(\n/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/flows.py:357: UserWarning: A flow named 'my-flow' and defined at '/tmp/ipykernel_44036/2726054530.py:20' conflicts with another flow. Consider specifying a unique `name` parameter in the flow definition:\n\n `@flow(name='my_unique_name', ...)`\n  warnings.warn(\n\n\n21:31:10.608 | INFO    | prefect.engine - Created flow run 'important-limpet' for flow 'my-flow'\n\n\n\n21:31:10.688 | INFO    | Flow run 'important-limpet' - Created task run 'my_first_task-0' for task 'my_first_task'\n\n\n\n21:31:10.690 | INFO    | Flow run 'important-limpet' - Executing 'my_first_task-0' immediately...\n\n\n\n21:31:10.782 | INFO    | Task run 'my_first_task-0' - Finished in state Completed()\n\n\n\n21:31:10.803 | INFO    | Flow run 'important-limpet' - Created task run 'my_second_task-0' for task 'my_second_task'\n\n\n\n21:31:10.805 | INFO    | Flow run 'important-limpet' - Executing 'my_second_task-0' immediately...\n\n\n\n21:31:10.903 | INFO    | Task run 'my_second_task-0' - Finished in state Completed()\n\n\n\n21:31:10.932 | INFO    | Flow run 'important-limpet' - Finished in state Completed('All states completed.')\n\n\n\n\nfrom prefect import flow\nfrom prefect.artifacts import create_link_artifact\n\n@flow\ndef my_flow():\n    create_link_artifact(\n        key=\"my-important-link\",\n        link=\"https://www.prefect.io/\",\n        link_text=\"Prefect\",\n    )\n\nif __name__ == \"__main__\":\n    my_flow()\n\n/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/flows.py:357: UserWarning: A flow named 'my-flow' and defined at '/tmp/ipykernel_44036/1748943510.py:4' conflicts with another flow. Consider specifying a unique `name` parameter in the flow definition:\n\n `@flow(name='my_unique_name', ...)`\n  warnings.warn(\n\n\n21:57:21.601 | INFO    | prefect.engine - Created flow run 'tomato-eagle' for flow 'my-flow'\n\n\n\n21:57:21.688 | INFO    | Flow run 'tomato-eagle' - Finished in state Completed()\n\n\n\n\nfrom prefect import flow, task\nfrom prefect.artifacts import create_markdown_artifact\n\n@task\ndef markdown_task():\n    na_revenue = 500000\n    markdown_report = f\"\"\"# Sales Report\n\n## Summary\n\nIn the past quarter, our company saw a significant increase in sales, with a total revenue of $1,000,000. \nThis represents a 20% increase over the same period last year.\n\n## Sales by Region\n\n| Region        | Revenue |\n|:--------------|-------:|\n| North America | ${na_revenue:,} |\n| Europe        | $250,000 |\n| Asia          | $150,000 |\n| South America | $75,000 |\n| Africa        | $25,000 |\n\n## Top Products\n\n1. Product A - $300,000 in revenue\n2. Product B - $200,000 in revenue\n3. Product C - $150,000 in revenue\n\n## Conclusion\n\nOverall, these results are very encouraging and demonstrate the success of our sales team in increasing revenue \nacross all regions. However, we still have room for improvement and should focus on further increasing sales in \nthe coming quarter.\n\"\"\"\n    create_markdown_artifact(\n        key=\"gtm-report\",\n        markdown=markdown_report,\n        description=\"Quarterly Sales Report\",\n    )\n\n@flow()\ndef my_flow():\n    markdown_task()\n\n\nif __name__ == \"__main__\":\n    my_flow()\n\n/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/flows.py:357: UserWarning: A flow named 'my-flow' and defined at '/tmp/ipykernel_44036/3501414838.py:42' conflicts with another flow. Consider specifying a unique `name` parameter in the flow definition:\n\n `@flow(name='my_unique_name', ...)`\n  warnings.warn(\n\n\n21:58:42.196 | INFO    | prefect.engine - Created flow run 'sociable-jaguarundi' for flow 'my-flow'\n\n\n\n21:58:42.266 | INFO    | Flow run 'sociable-jaguarundi' - Created task run 'markdown_task-0' for task 'markdown_task'\n\n\n\n21:58:42.267 | INFO    | Flow run 'sociable-jaguarundi' - Executing 'markdown_task-0' immediately...\n\n\n\n21:58:42.360 | INFO    | Task run 'markdown_task-0' - Finished in state Completed()\n\n\n\n21:58:42.392 | INFO    | Flow run 'sociable-jaguarundi' - Finished in state Completed('All states completed.')",
    "crumbs": [
      "Blog",
      "Prefect"
    ]
  },
  {
    "objectID": "prefect.html#states",
    "href": "prefect.html#states",
    "title": "Prefect",
    "section": "States",
    "text": "States\nWhen calling a task or a flow, there are three types of returned values:\n\nData: A Python object (such as int, str, dict, list, and so on).\nState: A Prefect object indicating the state of a flow or task run.\nPrefectFuture: A Prefect object that contains both data and State.\n\nReturning data‚Ää is the default behavior any time you call your_task().\nReturning Prefect State occurs anytime you call your task or flow with the argument return_state=True.\nReturning PrefectFuture is achieved by calling your_task.submit().\n\nfrom prefect import flow\n\ndef my_success_hook(flow, flow_run, state):\n    print(\"Flow run succeeded!\")\n\n@flow(on_completion=[my_success_hook])\ndef my_flow():\n    return 42\n\nmy_flow()\n\n/home/ben/mambaforge/envs/cfast/lib/python3.11/site-packages/prefect/flows.py:357: UserWarning: A flow named 'my-flow' and defined at '/tmp/ipykernel_44036/2923164121.py:6' conflicts with another flow. Consider specifying a unique `name` parameter in the flow definition:\n\n `@flow(name='my_unique_name', ...)`\n  warnings.warn(\n\n\n22:27:55.866 | INFO    | prefect.engine - Created flow run 'lime-bullmastiff' for flow 'my-flow'\n\n\n\n22:27:55.935 | INFO    | Flow run 'lime-bullmastiff' - Running hook 'my_success_hook' in response to entering state 'Completed'\n\n\n\nFlow run succeeded!\n\n\n22:27:55.939 | INFO    | Flow run 'lime-bullmastiff' - Hook 'my_success_hook' finished running successfully\n\n\n\n22:27:55.941 | INFO    | Flow run 'lime-bullmastiff' - Finished in state Completed()\n\n\n\n42\n\n\nCreate flow run state change hooks¬∂\ndef my_flow_hook(flow: Flow, flow_run: FlowRun, state: State):\n    \"\"\"This is the required signature for a flow run state\n    change hook. This hook can only be passed into flows.\n    \"\"\"\n\n# pass hook as a list of callables\n@flow(on_completion=[my_flow_hook])\nCreate task run state change hooks¬∂\ndef my_task_hook(task: Task, task_run: TaskRun, state: State):\n    \"\"\"This is the required signature for a task run state change\n    hook. This hook can only be passed into tasks.\n    \"\"\"\n\n# pass hook as a list of callables\n@task(on_failure=[my_task_hook])",
    "crumbs": [
      "Blog",
      "Prefect"
    ]
  },
  {
    "objectID": "prefect.html#serve",
    "href": "prefect.html#serve",
    "title": "Prefect",
    "section": "Serve",
    "text": "Serve\nfrom prefect import flow\n\n\n@flow(log_prints=True)\ndef hello_world(name: str = \"world\", goodbye: bool = False):\n    print(f\"Hello {name} from Prefect! ü§ó\")\n\n    if goodbye:\n        print(f\"Goodbye {name}!\")\n\n\nif __name__ == \"__main__\":\n    # creates a deployment and stays running to monitor for work instructions generated on the server\n\n    hello_world.serve(name=\"my-first-deployment\",\n                      tags=[\"onboarding\"],\n                      parameters={\"goodbye\": True},\n                      interval=60)\n\nimport time\nfrom prefect import flow, serve\n\n\n@flow\ndef slow_flow(sleep: int = 60):\n    \"Sleepy flow - sleeps the provided amount of time (in seconds).\"\n    time.sleep(sleep)\n\n\n@flow\ndef fast_flow():\n    \"Fastest flow this side of the Mississippi.\"\n    return\n\n\nif __name__ == \"__main__\":\n    slow_deploy = slow_flow.to_deployment(name=\"sleeper\", interval=45)\n    fast_deploy = fast_flow.to_deployment(name=\"fast\")\n    serve(slow_deploy, fast_deploy)",
    "crumbs": [
      "Blog",
      "Prefect"
    ]
  },
  {
    "objectID": "wireshark.html",
    "href": "wireshark.html",
    "title": "Wireshark",
    "section": "",
    "text": "sudo apt install wireshark",
    "crumbs": [
      "Blog",
      "Wireshark"
    ]
  },
  {
    "objectID": "wireshark.html#install",
    "href": "wireshark.html#install",
    "title": "Wireshark",
    "section": "",
    "text": "sudo apt install wireshark",
    "crumbs": [
      "Blog",
      "Wireshark"
    ]
  },
  {
    "objectID": "nookal.html",
    "href": "nookal.html",
    "title": "Nookal",
    "section": "",
    "text": "import os\nfrom dotenv import load_dotenv\nimport requests\n\n# Load environment variables from the .env file\nload_dotenv()\n\n# Retrieve environment variables\nnookal_id = os.getenv('NOOKAL_ID')\nnookal_email = os.getenv('NOOKAL_EMAIL')\nnookal_password = os.getenv('NOOKAL_PASSWORD')\nnookal_api_key = os.getenv('NOOKAL_API_KEY')\n\n# Print the variables to ensure they are loaded correctly (optional, remove in production)\nprint(f\"NOOKAL_ID: {nookal_id}\")\nprint(f\"NOOKAL_EMAIL: {nookal_email}\")\nprint(f\"NOOKAL_PASSWORD: {nookal_password}\")\nprint(f\"NOOKAL_API_KEY: {nookal_api_key}\")\n\nNOOKAL_ID: RM\nNOOKAL_EMAIL: ben@recoverymetrics.com.au\nNOOKAL_PASSWORD: Rmetrics\nNOOKAL_API_KEY: 7eB1e304-33AE-041F-816B-164CcCF5b721\nimport os\nfrom dotenv import load_dotenv\n\nprint(load_dotenv())\n\napi_key = os.getenv('API_KEY')\n\nTrue",
    "crumbs": [
      "Blog",
      "Nookal"
    ]
  },
  {
    "objectID": "nookal.html#parameters-needed",
    "href": "nookal.html#parameters-needed",
    "title": "Nookal",
    "section": "Parameters Needed",
    "text": "Parameters Needed\n\nAPI key needed in params\n\n\nimport requests\n\nBASE_URL = 'https://api.nookal.com/production/v2'\n\nparams = {\n    'api_key': nookal_api_key\n}\n\nheaders = {\n    'Content-Type': 'application/json'\n}\n\n\nverify = f'{BASE_URL}/verify'\n\nverify, headers\n\n('https://api.nookal.com/production/v2/verify',\n {'Content-Type': 'application/json'})\n\n\n\nresponse = requests.get(verify, headers=headers, params=params)\n\nprint(response.status_code)\nresponse.json()\n\n200\n\n\n{'status': 'success',\n 'data': {'api_call': 'verify',\n  'results': {'verify': True,\n   'accountID': 48499,\n   'apiUrl': 'https://api.nookal.com/'}},\n 'details': {'totalItems': 1, 'currentItems': 1},\n 'settings': {'currentPage': 1, 'nextPage': None, 'pageLength': 1}}",
    "crumbs": [
      "Blog",
      "Nookal"
    ]
  },
  {
    "objectID": "nookal.html#example-api-classs",
    "href": "nookal.html#example-api-classs",
    "title": "Nookal",
    "section": "Example API Classs",
    "text": "Example API Classs\n\nimport requests\n\nclass NookalAPI:\n    def __init__(self, api_key, base='https://api.nookal.com/production/v2/'):\n        self.api_key = api_key\n        self.base = base\n        self.params = {\n            'api_key': self.api_key\n        }\n        self.headers = {\n            'Content-Type': 'application/json'\n        }\n\n    def make_request(self, query_type='verify', method='GET', data=None):\n        url = f'{self.base}{query_type}'\n        if method == 'GET':\n            response = requests.get(url, headers=self.headers, params=self.params)\n        elif method == 'POST':\n            response = requests.post(url, headers=self.headers, params=self.params, json=data)\n        else:\n            raise ValueError(f'Unsupported HTTP method: {method}')\n        \n        if response.status_code == 200:\n            return response.json()\n        else:\n            print(f'Error: {response.status_code}')\n            return None\n\n    def verify(self):\n        return self.make_request('verify')\n\n    def __str__(self):\n        return f'str: {self.verify()}'\n\n    def __repr__(self):\n        return f'repr: {self.verify()}'\n    \n    def __call__(self):\n        return f\"call: {self.verify()}\"\n\n    def get_locations(self):\n        \"\"\"Retrieve all locations.\"\"\"\n        return self.make_request('getLocations')\n        \n    def get_practitioners(self):\n        return self.make_request('getPractitioners')\n\n    def get_patients(self):\n        return self.make_request('getPatients')\n        \n    def get_appointments(self):\n        return self.make_request('getAppointments')\n\n    def add_location(self, data):\n        \"\"\"Add a new location.\"\"\"\n        return self.make_request('addLocation', method='POST', data=data)\n\n    def add_practitioner(self, data):\n        \"\"\"Add a new practitioner.\"\"\"\n        return self.make_request('addPractitioner', method='POST', data=data)\n\n    def add_appointment(self, data):\n        \"\"\"Create a new appointment.\"\"\"\n        return self.make_request('addAppointment', method='POST', data=data)\n\n    def add_patient(self, data):\n        \"\"\"Add a new patient.\"\"\"\n        return self.make_request('addPatient', method='POST', data=data)\n\n# Example usage:\n# api = NookalAPI(api_key='your_api_key_here')\n# practitioners = api.get_practitioners()\n# print(practitioners)\n\n\nnookal = NookalAPI(nookal_api_key)\n\n\nnookal.verify()\n\n{'status': 'success',\n 'data': {'api_call': 'verify',\n  'results': {'verify': True,\n   'accountID': 48499,\n   'apiUrl': 'https://api.nookal.com/'}},\n 'details': {'totalItems': 1, 'currentItems': 1},\n 'settings': {'currentPage': 1, 'nextPage': None, 'pageLength': 1}}\n\n\nnookal.get_appointments()\n\nnookal.get_practitioners()\n\n{'status': 'success',\n 'data': {'api_call': 'getPractitioners',\n  'results': {'practitioners': [{'ID': '1',\n     'FirstName': 'Ben',\n     'LastName': 'Thek',\n     'Speciality': 'Practitioner',\n     'ShowInDiary': '1',\n     'status': '1',\n     'Title': '',\n     'Email': 'ben@recoverymetrics.com.au',\n     'locations': ['1']},\n    {'ID': '2',\n     'FirstName': 'Brett',\n     'LastName': 'Beeson',\n     'Speciality': 'Practitioner',\n     'ShowInDiary': '1',\n     'status': '1',\n     'Title': 'Mr',\n     'Email': 'bthekkel1@gmail.com',\n     'locations': ['1']}]}},\n 'details': {'totalItems': 2, 'currentItems': 2},\n 'settings': {'currentPage': 1, 'nextPage': None, 'pageLength': 2}}\n\n\n\nnookal.get_appointments()\n\n{'status': 'success',\n 'data': {'api_call': 'getAppointments', 'results': {'appointments': []}},\n 'details': {'totalItems': 0, 'currentItems': 0},\n 'settings': {'currentPage': 1, 'nextPage': None, 'pageLength': 100}}\n\n\n\ndata = {\n    'first_name': 'first_name',\n    'last_name': 'last_name',\n    'email': 'email',\n    'phone': 'phone'\n}\nnookal.add_practitioner(data)\n\nError: 404\n\n\n\ndata = {\n    'practitioner_id': 'practitioner_id',\n    'client_id': 'client_id',\n    'date': 'date',\n    'time': 'time',\n    'duration': 'duration',\n    'notes': 'notes'\n}\nnookal.add_appointment(data)\n\nError: 404\n\n\n\nimport os\nfrom dotenv import load_dotenv\n\nprint(load_dotenv())\n\nTrue\n\n\n\nclass Nookaltest():\n    def __init__(self, *args, **kwargs):\n        self.base_url = 'https://api.nookal.com/production/v2/'\n        self.crm_key = os.getenv('NOOKAL_API_KEY')\n\n    def make_request(self, endpoint, method='GET', data=None):\n        \"\"\"\n        Generic method to make requests to the Nookal API\n        \"\"\"\n        url = f\"{self.base_url}{endpoint}\"\n        headers = {\n            'Content-Type': 'application/json',\n        }\n        params = {'api_key': self.crm_key} if method == 'GET' else {}\n        response = requests.request(method, url, headers=headers, params=params, json=data)\n        response.raise_for_status()  # This will raise an exception for non-200 responses\n        return response.json()\n    def verify(self):\n        \"\"\"\n        Verify the API key's validity by making a test request to the Nookal API.\n        \"\"\"\n        try:\n            response = self.make_request('verify')\n            return {'status': 'success', 'message': 'API key is valid.', 'response': f'{response}'}\n        except requests.exceptions.HTTPError as e:\n            return {'status': 'error', 'message': str(e)}\n\n    def sync_locations(self):\n        \"\"\"\n        Synchronize locations from Nookal to the local Location model.\n        \"\"\"\n        locations_data = self.make_request('getLocations')\n        locations = locations_data.get('data', {}).get('results', {}).get('locations', [])\n        for i, location in enumerate(locations):\n            keys = location.keys()\n            full_address = ', '.join(filter(None, [\n                    location.get('AddressLine1', ''),\n                    location.get('AddressLine2', ''),\n                    location.get('AddressLine3', ''),\n                    location.get('City', ''),\n                    location.get('State', ''),\n                    location.get('Postcode', ''),\n                    location.get('Country', ''),\n            ])).strip(', ')\n                        \n            print({'address': full_address, 'phone_number': location.get('Telephone',''), 'email': location.get('Email', '')})\n        return keys\n\n\n    def sync_practitioners(self):\n        \"\"\"\n        Synchronize practitioners from Nookal to the local Practitioner model.\n        \"\"\"\n        practitioners_data = self.make_request('getPractitioners')\n        practitioners = practitioners_data.get('data', {}).get('results', {}).get('practitioners', [])\n        for practitioner in practitioners:\n            keys = practitioner.keys()\n            # print(practitioner)\n\n        return keys\n        # return practitioners\n    \n\n    def sync_clients(self):\n        \"\"\"\n        Synchronize clients from Nookal to the local Client model.\n        \"\"\"\n        clients_data = self.make_request('getPatients')\n        clients = clients_data.get('data', {}).get('results', {}).get('patients', [])\n        for client in clients:\n            keys = client.keys()\n        #     Client.objects.update_or_create(\n        #         email=client['email'],\n        #         defaults={\n        #             'first_name': client['first_name'],\n        #             'last_name': client['last_name'],\n        #             'phone_number': client.get('phone_number', ''),\n        #             'address': client.get('address', ''),\n        #             'dob': client.get('dob'),  # Assumed correct format\n        #             'sex': client.get('sex', 'O'),  # Default to 'Other'\n        #             'crm_id': client.get('id')\n        #         }\n        #     )\n        # self.synced_at = timezone.now()\n        # self.save()\n        return clients\n\n    def sync_appointments(self):\n        \"\"\"\n        Synchronize appointments from Nookal to the local Appointment model.\n        \"\"\"\n        appointments_data = self.make_request('getAppointments')\n        if appointments_data.get('status') == 'success' and 'results' in appointments_data['data']:\n            appointments = appointments_data['data']['results']['appointments']\n\n            for appointment_data in appointments:\n                keys = appointment_data.keys()\n                # client = Client.objects.get(email=appointment['client_email'])\n                # practitioner = Practitioner.objects.get(user__email=appointment['practitioner_email'])\n                # Appointment.objects.update_or_create(\n                #     client=client,\n                #     practitioner=practitioner,\n                #     date=appointment['date'],\n                #     defaults={\n                #         'reason': appointment.get('reason', '')\n                #     }\n                # )\n            # self.synced_at = timezone.now()\n            # self.save()\n            # return keys\n            return keys\n\n\nnew = Nookaltest()\n\n\nnew.verify()\n\n{'status': 'success',\n 'message': 'API key is valid.',\n 'response': \"{'status': 'success', 'data': {'api_call': 'verify', 'results': {'verify': True, 'accountID': 48499, 'apiUrl': 'https://api.nookal.com/'}}, 'details': {'totalItems': 1, 'currentItems': 1}, 'settings': {'currentPage': 1, 'nextPage': None, 'pageLength': 1}}\"}\n\n\n\nnew.sync_locations()\n\n{'address': '0, Australia', 'phone_number': '0415051025', 'email': 'ben@recoverymetrics.com.au'}\n\n\ndict_keys(['ID', 'Name', 'AddressLine1', 'AddressLine2', 'AddressLine3', 'City', 'State', 'Telephone', 'Email', 'Website', 'Postcode', 'Timezone', 'lockNewPatientsToLocation', 'countryID', 'Country'])\n\n\n\nnew.sync_practitioners()\n\ndict_keys(['ID', 'FirstName', 'LastName', 'Speciality', 'ShowInDiary', 'status', 'Title', 'Email', 'locations'])\n\n\n\nnew.sync_clients()\n\n[{'ID': '1',\n  'Title': '',\n  'FirstName': 'cli',\n  'MiddleName': '',\n  'Nickname': '',\n  'LastName': 'test',\n  'Notes': '',\n  'Alerts': '',\n  'DOB': None,\n  'Gender': '',\n  'DateCreated': '2024-10-15 06:50:30',\n  'DateModified': '2024-10-15 06:50:56',\n  'RegistrationDate': '2024-10-15 16:50:30',\n  'onlineQuickCode': 'NBDURW',\n  'consent': {'reminder': {'sms': 0, 'email': 0},\n   'marketing': {'sms': 0, 'email': 0},\n   'integration': {'sms': 0, 'email': 0},\n   'parent': '',\n   'history': []},\n  'Occupation': '',\n  'Employer': '',\n  'category': '',\n  'LocationID': '0',\n  'allowOnlineBookings': '1',\n  'HealthFundData': None,\n  'PrivateHealthType': None,\n  'PrivateHealthNo': None,\n  'PensionNo': None,\n  'allergies': None,\n  'active': '1',\n  'deceased': '0',\n  'NextOfKin': None,\n  'Doctor': '',\n  'Email': '',\n  'Mobile': '0415051025',\n  'Home': '',\n  'Work': '',\n  'Fax': '',\n  'Addr1': '',\n  'Addr2': '',\n  'Addr3': '',\n  'City': '',\n  'Country': 'Australia',\n  'State': '',\n  'Postcode': '',\n  'Postal_Addr1': '',\n  'Postal_Addr2': '',\n  'Postal_Addr3': '',\n  'Postal_City': '',\n  'Postal_Country': '',\n  'Postal_State': '',\n  'Postal_Postcode': ''}]\n\n\n\nnew.sync_appointments()",
    "crumbs": [
      "Blog",
      "Nookal"
    ]
  },
  {
    "objectID": "makefile.html",
    "href": "makefile.html",
    "title": "Makefile",
    "section": "",
    "text": ".PHONY: help pull-deploy push-deploy makemigrations migrate runserver superuser collectstatic test install-nginx uninstall-nginx install-gunicorn uninstall-gunicorn\n\n# Makefile\n\nhelp:           ## Show this help.\n    @echo \"Available commands:\"\n    @grep -E '^[a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | awk 'BEGIN {FS = \":.*?## \"}; {printf \"\\033[36m%-20s\\033[0m %s\\n\", $$1, $$2}'\n\nmakemigrations: ## Make migrations\n    python manage.py makemigrations\n\nmigrate: makemigrations ## Apply migrations\n    python manage.py migrate\n\nrunserver: migrate ## Run the Django development server\n    python manage.py runserver\n\nsuperuser: ## Create a superuser\n    python manage.py createsuperuser --no-input\n\ncollectstatic: ## Collect static files\n    python manage.py collectstatic --noinput\n\ntest: ## Run tests\n    python manage.py test\n\nDJANGO_ENVIRONMENT ?= development\nCONFIG_DIR := deploy/$(DJANGO_ENVIRONMENT)\n\npull-deploy:    ## Pull Nginx and Gunicorn config into $(CONFIG_DIR)/\n    @mkdir -p $(CONFIG_DIR)\n    @if [ -f /etc/nginx/sites-available/todo ]; then cp /etc/nginx/sites-available/todo $(CONFIG_DIR)/; fi\n    @if [ -f /etc/systemd/system/todocorn.service ]; then cp /etc/systemd/system/todocorn.service $(CONFIG_DIR)/; fi\n\npush-deploy:    ## Push Nginx and Gunicorn config to system\n    @echo \"You are about to deploy to the '$(DJANGO_ENVIRONMENT)' environment.\"\n    @read -p \"Is this correct? [y/N] \" confirm; \\\n    if [ \"$$confirm\" != \"y\" ] && [ \"$$confirm\" != \"Y\" ]; then \\\n        echo \"Deployment aborted.\"; \\\n        exit 1; \\\n    fi\n\n    @echo \"Proceeding with $(DJANGO_ENVIRONMENT) deployment...\"\n    @if [ -f $(CONFIG_DIR)/todo ]; then \\\n        sudo cp $(CONFIG_DIR)/todo /etc/nginx/sites-available/; \\\n        sudo ln -sf /etc/nginx/sites-available/todo /etc/nginx/sites-enabled/todo; \\\n        sudo systemctl restart nginx; \\\n    fi\n    @if [ -f $(CONFIG_DIR)/todocorn.service ]; then \\\n        sudo cp $(CONFIG_DIR)/todocorn.service /etc/systemd/system; \\\n        sudo systemctl daemon-reload; \\\n        sudo systemctl restart todocorn; \\\n        sudo systemctl enable todocorn; \\\n    fi\n\nrun-gunicorn: install-gunicorn ## Run Gunicorn\n    gunicorn -c gunicorn_config.py config.wsgi\n\n\nreload-deploy: ## Reload deploy\n    sudo systemctl daemon-reload; \\\n    sudo systemctl restart todocorn; \\\n    sudo systemctl enable todocorn; \\\n    sudo systemctl restart nginx; \n\ninstall-nginx: ## Install Nginx\n    ./scripts/install_nginx.sh\n\ninstall-gunicorn: ## Install Gunicorn\n    poetry add gunicorn\n\ninstall-db: ## Install Postgres\n    ./scripts/install_db.sh\n\nsetup-db: ## Create the database\n    python scripts/setup_db.py &gt; ./scripts/createdb.sql\n    sudo -u postgres psql &lt; ./scripts/createdb.sql\n    rm ./scripts/createdb.sql # it contains sensitive information!\n\n\nuninstall-nginx: ## Uninstall Nginx\n    ./scripts/uninstall_nginx.sh\n\nuninstall-gunicorn: ## Uninstall Gunicorn\n    ./scripts/uninstall_gunicorn.sh\n\nuninstall-todocorn: ## Uninstall Todocorn\n    ./scripts/uninstall_todocorn.sh\n\nuninstall-db: ## Uninstall Postgres\n    ./scripts/uninstall_db.sh\n\n\ncheck_deploy: ## Check status\n    ./scripts/check_deploy_status.sh\n\n\n\n Back to top",
    "crumbs": [
      "Blog",
      "Makefile"
    ]
  },
  {
    "objectID": "Cloud/AWS/router_53.html",
    "href": "Cloud/AWS/router_53.html",
    "title": "Router 53",
    "section": "",
    "text": "1. Core Features of Route 53\n\na. DNS Management\nRoute 53 provides scalable and authoritative DNS services. It can route traffic based on domain names, IP addresses, and more. Route 53 supports all major DNS record types.\n\nDNS Record Types Supported:\n\nA (Address Record): Maps a domain name to an IPv4 address.\nAAAA (IPv6 Address Record): Maps a domain name to an IPv6 address.\nCNAME (Canonical Name Record): Maps one domain name (alias) to another.\nMX (Mail Exchange Record): Directs email traffic to mail servers.\nTXT (Text Record): Allows arbitrary text to be stored (e.g., for domain verification).\nNS (Name Server Record): Specifies the authoritative name servers for a domain.\nSOA (Start of Authority Record): Contains administrative information about the domain.\nPTR (Pointer Record): Used for reverse DNS lookups (mapping IP to a domain name).\nSRV (Service Record): Defines the location of a service, such as SIP servers.\n\n\n\n\nb. Traffic Flow and Routing Policies\nRoute 53 supports several routing policies that allow you to direct user traffic based on various conditions. Here are the major routing policies:\n\nSimple Routing: All traffic is routed to a single resource. Typically used when you have one IP address or a single web server.\nWeighted Routing: Distribute traffic across multiple resources (e.g., servers) based on weights you assign to each resource.\nLatency-based Routing: Route users to the resource that has the lowest network latency (fastest response time) based on their geographic location.\nFailover Routing: Automatically route traffic to a healthy resource if the primary resource becomes unavailable (e.g., to a secondary data center).\nGeolocation Routing: Route traffic based on the geographical location of the user (e.g., direct European users to a server in Europe).\nGeoproximity Routing: Routes traffic based on the location of your resources and optionally shifts traffic to specific regions (requires AWS Global Accelerator).\nMulti-value Answer Routing: Route traffic to multiple resources, returning multiple records, and allowing DNS resolvers to choose.\n\n\n\nc.¬†Health Checks\nRoute 53 can monitor the health of resources and route traffic only to healthy resources. Health checks can be used for failover and load balancing.\n\nHTTP, HTTPS, TCP Health Checks: Route 53 periodically sends health check requests to the specified endpoints. If a health check fails, Route 53 can stop routing traffic to that endpoint.\nFailover with Health Checks: Use Route 53 to route traffic away from unhealthy resources. For example, you can configure a primary and secondary endpoint, and if the primary fails, Route 53 routes traffic to the secondary.\n\n\n\nd.¬†Domain Registration\nRoute 53 can register domains and automatically configure DNS records for them. AWS is a domain registrar for various top-level domains (TLDs).\n\nDomain Registration: Allows you to register and manage domain names directly from the AWS console. Supported TLDs include .com, .net, .org, .io, and more.\nAuto-renewal: Route 53 supports automatic domain renewal to prevent expiration.\n\n\n\n\n2. How Route 53 Works\n\na. Basic Flow of DNS Requests\nWhen a user visits a domain managed by Route 53, the following steps occur:\n\nDNS Resolver: The user enters the domain name in the browser. The request goes to a DNS resolver (typically an ISP).\nRecursive Lookup: The DNS resolver queries the root name server for the top-level domain (TLD) and gets the authoritative name servers for the domain.\nRoute 53 Name Server: The DNS resolver queries the Route 53 name server for the domain. Route 53 returns the appropriate DNS records.\nResponse: The DNS resolver caches the result and returns the IP address to the user‚Äôs browser, which connects to the web server.\n\n\n\nb. Hosted Zones\nA hosted zone in Route 53 is a container that holds DNS records for a domain.\n\nPublic Hosted Zone: Manages DNS records that are publicly accessible on the internet.\nPrivate Hosted Zone: Manages DNS records accessible only within an Amazon VPC.\n\nEach hosted zone has an associated set of name servers, which Route 53 uses to resolve queries.\n\n\nc.¬†Record Sets\nRecord sets are the individual DNS records that define how traffic should be routed.\n\nAlias Record: A special Route 53 record set that allows you to map a domain directly to AWS resources (like CloudFront distributions, S3 buckets, or Elastic Load Balancers) without additional DNS lookup costs.\nTTL (Time to Live): The duration (in seconds) that a DNS resolver caches a response from Route 53 before querying again. Lower TTLs provide fresher data, while higher TTLs reduce DNS lookup load.\n\n\n\n\n3. Routing Traffic to AWS Resources\nRoute 53 integrates deeply with AWS services, making it easy to route traffic to AWS resources.\n\nAmazon EC2 Instances: You can create an A or AAAA record that points to an Elastic IP associated with an EC2 instance.\nElastic Load Balancer (ELB): Use an Alias record to route traffic to an ELB.\nAmazon S3: You can use Route 53 to route traffic to an S3 bucket for static website hosting.\nAmazon CloudFront: Route 53 can be used with CloudFront to route traffic through a content delivery network (CDN) for faster content delivery.\nAWS Global Accelerator: Route 53 can route traffic based on AWS Global Accelerator, providing low-latency, fault-tolerant global traffic routing.\n\n\n\n4. Domain Registration and DNSSEC Support\n\na. Domain Registration\nYou can register and manage domain names using Route 53. AWS supports various TLDs, and you can manage DNS records for your registered domain in Route 53.\n\n\nb. DNSSEC (Domain Name System Security Extensions)\nDNSSEC adds a layer of security by ensuring that the DNS responses originate from the correct DNS servers and haven‚Äôt been tampered with.\n\nSigning DNS Zones: Route 53 supports DNSSEC signing for hosted zones, ensuring that responses from Route 53 are authenticated.\nDomain Registrar Support: To use DNSSEC, the domain registrar must support DNSSEC, and you must configure the DS (Delegation Signer) records.\n\n\n\n\n5. Pricing\nRoute 53 pricing is based on several factors: - Hosted Zones: You pay for each hosted zone you manage in Route 53. - DNS Queries: Pricing is based on the number of DNS queries Route 53 resolves. - Health Checks: Additional charges apply for health checks. - Domain Registration: The cost of registering and renewing domains depends on the TLD.\n\n\n6. Integration with Other AWS Services\nRoute 53 integrates with several other AWS services: - Amazon CloudFront: For global content delivery, Route 53 can route traffic to CloudFront distributions. - Elastic Load Balancer: You can use Alias records to route traffic to Elastic Load Balancers. - AWS Global Accelerator: With Geoproximity Routing, Route 53 integrates with Global Accelerator to improve latency. - AWS CloudWatch: You can monitor Route 53 health checks and DNS queries using CloudWatch metrics. - AWS Lambda: You can trigger Lambda functions when health checks fail or for custom DNS failover logic.\n\n\n7. Route 53 Tools\n\na. Traffic Flow\nRoute 53 Traffic Flow allows you to build sophisticated routing configurations using visual editors.\n\nTraffic Policies: You can create policies for different routing strategies (e.g., failover, geolocation) and manage them easily using the visual interface.\nTraffic Policy Versioning: Route 53 Traffic Flow supports versioning, allowing you to maintain multiple versions of a traffic policy and roll back if needed.\n\n\n\nb. Amazon Route 53 Resolver\nRoute 53 Resolver provides DNS resolution for resources in your VPC and forwards DNS queries between VPCs and on-premises networks.\n\nOutbound Endpoints: Forward DNS queries from a VPC to your network.\nInbound Endpoints: Allow your network to forward DNS queries to Route 53 Resolver in a VPC.\n\n\n\n\n8. Health Checks and Failover\nRoute 53 allows for both DNS-based failover and application-based failover, ensuring that traffic is always routed to healthy endpoints.\n\na. Types of Health Checks\n\nEndpoint Health Checks: Verify the availability of an HTTP, HTTPS, or TCP endpoint.\nCalculated Health Checks: Combine results from multiple health checks to determine the health of a group of endpoints.\nLatency-based Health Checks: Monitor the latency of responses from different resources.\n\n\n\nb. Failover Routing\nRoute 53 can automatically failover to a secondary resource if the primary resource is unhealthy. For example, if an EC2 instance fails, Route 53 can route traffic to another instance or region.\n\n\n\n9. Route 53 API and Automation\nRoute 53 provides a powerful API to manage DNS records, hosted zones, and health checks programmatically.\n\nBoto3 (AWS SDK for Python): Use the Boto3 library to interact with Route 53. Example:\n\nimport boto3\n\nclient = boto3.client('route53')\n\n# Create a new hosted zone\nresponse = client.create_hosted_zone(\n    Name='example.com',\n    CallerReference='unique-string',\n    HostedZoneConfig={\n        'Comment': 'This is a sample hosted zone',\n        'PrivateZone': False\n    }\n)\nprint(response)\n\nCloudFormation: You can define Route 53 resources in CloudFormation templates for automated deployment.\n\n\n\n10. Best Practices\n\nUse Alias Records: Alias records in Route 53 are more efficient than standard CNAME records when routing to AWS resources.\nUse Latency-based Routing for Global Applications: For applications serving users globally, latency-based routing ensures that users connect to the closest endpoint.\nSet Proper TTL Values: Use appropriate TTL values to balance the trade-off between caching and the responsiveness of DNS changes.\nMonitor DNS Queries and Health Checks: Use CloudWatch to monitor Route 53 health checks and DNS queries to maintain the availability and performance of your application.\nEnable DNSSEC for Security: Use DNSSEC to protect your DNS records from tampering and ensure authenticity.\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Blog",
      "Cloud",
      "AWS",
      "Router 53"
    ]
  },
  {
    "objectID": "Cloud/AWS/aws-amazon.html",
    "href": "Cloud/AWS/aws-amazon.html",
    "title": "AMS - Amazon",
    "section": "",
    "text": "Back to top",
    "crumbs": [
      "Blog",
      "Cloud",
      "AWS",
      "AMS - Amazon"
    ]
  },
  {
    "objectID": "Cloud/AWS/iam.html",
    "href": "Cloud/AWS/iam.html",
    "title": "IAM",
    "section": "",
    "text": "Specifc Individuals, can receive personal logins",
    "crumbs": [
      "Blog",
      "Cloud",
      "AWS",
      "IAM"
    ]
  },
  {
    "objectID": "Cloud/AWS/iam.html#users",
    "href": "Cloud/AWS/iam.html#users",
    "title": "IAM",
    "section": "",
    "text": "Specifc Individuals, can receive personal logins",
    "crumbs": [
      "Blog",
      "Cloud",
      "AWS",
      "IAM"
    ]
  },
  {
    "objectID": "Cloud/AWS/iam.html#groups",
    "href": "Cloud/AWS/iam.html#groups",
    "title": "IAM",
    "section": "Groups",
    "text": "Groups\n\nCollection of Users",
    "crumbs": [
      "Blog",
      "Cloud",
      "AWS",
      "IAM"
    ]
  },
  {
    "objectID": "Cloud/AWS/iam.html#roles",
    "href": "Cloud/AWS/iam.html#roles",
    "title": "IAM",
    "section": "Roles",
    "text": "Roles\n\nCollection polices (DB Read, DB Write)",
    "crumbs": [
      "Blog",
      "Cloud",
      "AWS",
      "IAM"
    ]
  },
  {
    "objectID": "Cloud/AWS/iam.html#policy",
    "href": "Cloud/AWS/iam.html#policy",
    "title": "IAM",
    "section": "Policy",
    "text": "Policy\n\nSpecific Polices",
    "crumbs": [
      "Blog",
      "Cloud",
      "AWS",
      "IAM"
    ]
  },
  {
    "objectID": "nginx.html",
    "href": "nginx.html",
    "title": "Nginx",
    "section": "",
    "text": "Admin site\nObject-relational mapper\nAuthentication\nCaching\n\nHTTP : Hypertext Transfer Protocol",
    "crumbs": [
      "Blog",
      "Nginx"
    ]
  },
  {
    "objectID": "nginx.html#features",
    "href": "nginx.html#features",
    "title": "Nginx",
    "section": "",
    "text": "Admin site\nObject-relational mapper\nAuthentication\nCaching\n\nHTTP : Hypertext Transfer Protocol",
    "crumbs": [
      "Blog",
      "Nginx"
    ]
  },
  {
    "objectID": "nginx.html#why-use-nginx-with-django",
    "href": "nginx.html#why-use-nginx-with-django",
    "title": "Nginx",
    "section": "Why Use Nginx with Django?",
    "text": "Why Use Nginx with Django?\n\nReverse Proxy: Nginx can serve as a reverse proxy, forwarding client requests to a Django application server and serving responses back to the client.\nStatic and Media File Handling: Nginx can serve static and media files more efficiently than Django‚Äôs built-in server.\nLoad Balancing: Nginx can distribute incoming traffic across multiple instances of your Django application.\nSecurity and Performance: Nginx can handle SSL/TLS termination, provide rate limiting, and improve overall performance through caching and compression.",
    "crumbs": [
      "Blog",
      "Nginx"
    ]
  },
  {
    "objectID": "nginx.html#installation",
    "href": "nginx.html#installation",
    "title": "Nginx",
    "section": "Installation",
    "text": "Installation\nsudo apt update\nsudo apt install nginx\n\nStart\nsudo systemctl start nginx\n\n\nStatus\nsudo systemctl status nginx\n\n\nStop\nsudo systemctl stop nginx\n\n\nReload\nsudo nginx -s reload",
    "crumbs": [
      "Blog",
      "Nginx"
    ]
  },
  {
    "objectID": "nginx.html#default-html-file-in",
    "href": "nginx.html#default-html-file-in",
    "title": "Nginx",
    "section": "Default html file in",
    "text": "Default html file in\ncd /var/www/html",
    "crumbs": [
      "Blog",
      "Nginx"
    ]
  },
  {
    "objectID": "nginx.html#nginx",
    "href": "nginx.html#nginx",
    "title": "Nginx",
    "section": "Nginx",
    "text": "Nginx\ncd /etc/nginx/sites-enables\n\nCreate a new configuration file for your Django project in /etc/nginx/sites-available/\nsudo nano /etc/nginx/sites-available/myproject\n\n\nAdd the following basic configuration\nserver {\n    listen 80;\n    server_name example.com www.example.com;  # Replace with your domain\n\n    location = /favicon.ico { access_log off; log_not_found off; }\n    location /static/ {\n        root /path/to/your/static/files;  # Replace with your static files path\n    }\n\n    location /media/ {\n        root /path/to/your/media/files;  # Replace with your media files path\n    }\n\n    location / {\n        include proxy_params;\n        proxy_pass http://unix:/path/to/your/project.sock;  # Replace with your socket file path\n    }\n}\n\n\nserver_name: Replace with your domain name.\nroot: Set the paths to your static and media files.\nproxy_pass: This should point to your application server (e.g., Gunicorn) using a Unix socket or an IP address and port.",
    "crumbs": [
      "Blog",
      "Nginx"
    ]
  },
  {
    "objectID": "nginx.html#allow-http-port-to-device",
    "href": "nginx.html#allow-http-port-to-device",
    "title": "Nginx",
    "section": "Allow http port to device",
    "text": "Allow http port to device\n\nOracle\n\nsudo iptables -I INPUT 6 -m state --state NEW -p tcp --dport 80 -j ACCEPT\n\nLink the Configuration and Test Nginx\n\nLink your configuration file to the sites-enabled directory\n\nsudo ln -s /etc/nginx/sites-available/&lt;myproject&gt; /etc/nginx/sites-enabled",
    "crumbs": [
      "Blog",
      "Nginx"
    ]
  },
  {
    "objectID": "nginx.html#test-the-nginx-configuration-for-syntax-errors",
    "href": "nginx.html#test-the-nginx-configuration-for-syntax-errors",
    "title": "Nginx",
    "section": "Test the Nginx configuration for syntax errors",
    "text": "Test the Nginx configuration for syntax errors\nsudo nginx -t\n\nIf the test is successful, reload Nginx\nsudo systemctl reload nginx",
    "crumbs": [
      "Blog",
      "Nginx"
    ]
  },
  {
    "objectID": "nginx.html#serving-static-and-media-files",
    "href": "nginx.html#serving-static-and-media-files",
    "title": "Nginx",
    "section": "Serving Static and Media Files",
    "text": "Serving Static and Media Files\n\nFor production, Django doesn‚Äôt serve static files; Nginx handles them. Set up Django to collect all static files into a single directory\n\n\nIn settings.py\nSTATIC_URL = '/static/'\nSTATIC_ROOT = '/path/to/your/static/files'\n\nMEDIA_URL = '/media/'\nMEDIA_ROOT = '/path/to/your/media/files'\n\n\nRun the command to collect static files\npython manage.py collectstatic",
    "crumbs": [
      "Blog",
      "Nginx"
    ]
  },
  {
    "objectID": "nginx.html#django-using-gunicorn-with-nginx",
    "href": "nginx.html#django-using-gunicorn-with-nginx",
    "title": "Nginx",
    "section": "Django: Using Gunicorn with Nginx",
    "text": "Django: Using Gunicorn with Nginx\n\nGunicorn is a WSGI HTTP server for Python applications. To use Gunicorn with Nginx\n\n\nSecuring Your Django Project with Nginx\n\nSSL/TLS: Use Let‚Äôs Encrypt to obtain a free SSL/TLS certificate and configure Nginx to use HTTPS.\nSecurity Headers: Add security headers like Content-Security-Policy, X-Content-Type-Options, X-Frame-Options, and X-XSS-Protection to enhance security.\nRate Limiting: Implement rate limiting to protect your site from brute force attacks.\n\n\n\nOptimizing Performance\n\nCaching: Use Nginx to cache static files and other resources.\nCompression: Enable gzip compression in Nginx to reduce the size of responses.\n\n\n\nMonitoring and Logging\n\nNginx provides extensive logging capabilities. Configure access and error logs for monitoring\n\naccess_log /var/log/nginx/myproject_access.log;\nerror_log /var/log/nginx/myproject_error.log;\n\n\nUsing Nginx with Django can significantly improve your project‚Äôs performance, scalability, and security. Make sure to test your configuration thoroughly before deploying it to production.\n\n\n\nServing Static and Media Files\n\nGunicorn does not serve static or media files in production. Use a web server like Nginx to handle static files and reverse proxy requests to Gunicorn\n\n\nExample Nginx configuration in /etc/nginx/sites-available/todo\n\nserver {\n    listen 80;\n    server_name your_domain_or_IP;\n\n    location / {\n        proxy_pass http://unix:/path/to/your/project/gunicorn.sock;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n    }\n\n    location /static/ {\n        alias /path/to/your/project/static/;\n    }\n\n    location /media/ {\n        alias /path/to/your/project/media/;\n    }\n}\n\n\nExample Django Project\n\nserver {\n    listen 80;\n    server_name 172.22.251.200;\n\n    location /static/ {\n        alias /home/ben-24/Example_project/django_todo_postgres/static/;\n    }\n\n    location / {\n        # include proxy_params;\n        proxy_pass http://unix:/home/ben-24/Example_project/django_todo_postgres/gunicorn.sock;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n    }\n}\n\n\n\n\nLink the site\nsudo ln -s /etc/nginx/sites-available/todo /etc/nginx/sites-enabled\n\n\nAllow http port to device\n\nOracle\n\nsudo iptables -I INPUT 6 -m state --state NEW -p tcp --dport 80 -j ACCEPT\n\n\nEdit nginx.conf\n\nin `/etc/nginx/nginx.conf\n\n\nuser root;\nworker_processes auto;\npid /run/nginx.pid;\nerror_log /var/log/nginx/error.log;\ninclude /etc/nginx/modules-enabled/*.conf;\n## main\nworker_processes auto;\n\nerror_log /path/to/error error;\n\n\nhttp {\n    server {\n        listen 80;\n        server_name mydomain.com ww.mydomain.com;\n\n        location / {\n            root /path/to/folder;\n            index index.html\n        }\n    \n    }\n\n}\n```nginx http { server { listen 443 ssl; server_name mydomain.com www.mydomain.com;\n    location / {\n        root /path/to/folder;\n        index index.html\n    }\n\n    ssl_sertification /path/to/certificate;\n    ssl_certification_key /path/to/key;\n\nserver {\n\n\n    listen 80;\n    server_name mydomain.com www.mydomain.com;\n\n    return 301 https://$server_name$request_uri;\n\n}\n}\n```nginx ## main worker_processes auto;\nerror_log /path/to/error error;\nhttp { server { listen 443 ssl; server_name mydomain.com www.mydomain.com;\n    location /static {\n        alias /path/to/root;\n    }\n\n    location / {\n        proxy_pass http://127.0.0.1:8000;\n        proxy_set_header Host $host;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    }\n\n\n\n\n    ssl_sertification /path/to/certificate;\n    ssl_certification_key /path/to/key;\n\n\nserver {\n    listen 80;\n    server_name mydomain.com www.mydomain.com;\n\n    return 301 https://$server_name$request_uri;\n\n}\n}",
    "crumbs": [
      "Blog",
      "Nginx"
    ]
  },
  {
    "objectID": "ssh&vnc&ftp.html",
    "href": "ssh&vnc&ftp.html",
    "title": "SSH, VNC and FTP",
    "section": "",
    "text": "sudo apt install openssh-server openssh-client\nsudo systemctl restart sshd\nsudo systemctl status sshd\n\n\nedit\ncat ~/.ssh/config\nadd\nHost &lt;code name&gt;\n        HostName 192.168.1.108\n        User &lt;user name&gt;\n        Port 22\nssh &lt;code name&gt;",
    "crumbs": [
      "Blog",
      "SSH, VNC and FTP"
    ]
  },
  {
    "objectID": "ssh&vnc&ftp.html#install-ssh",
    "href": "ssh&vnc&ftp.html#install-ssh",
    "title": "SSH, VNC and FTP",
    "section": "",
    "text": "sudo apt install openssh-server openssh-client\nsudo systemctl restart sshd\nsudo systemctl status sshd\n\n\nedit\ncat ~/.ssh/config\nadd\nHost &lt;code name&gt;\n        HostName 192.168.1.108\n        User &lt;user name&gt;\n        Port 22\nssh &lt;code name&gt;",
    "crumbs": [
      "Blog",
      "SSH, VNC and FTP"
    ]
  },
  {
    "objectID": "ssh&vnc&ftp.html#install-tightvnc",
    "href": "ssh&vnc&ftp.html#install-tightvnc",
    "title": "SSH, VNC and FTP",
    "section": "Install tightVNC",
    "text": "Install tightVNC\n\nonline install on windows\n\nsudo apt update\nsudo apt install lightdm\nsudo reboot\nsudo apt install x11vnc\nsudo nano /lib/systemd/system/x11vnc.service\n\nCopy and paste these commands - change the password\n[Unit]\nDescription=x11vnc service\nAfter=display-manager.service network.target syslog.target\n\n[Service]\nType=simple\nExecStart=/usr/bin/x11vnc -forever -display :0 -auth guess -passwd password\nExecStop=/usr/bin/killall x11vnc\nRestart=on-failure\n\n[Install]\nWantedBy=multi-user.target\n\n\nRun these commands after\nsystemctl daemon-reload\nsystemctl enable x11vnc.service\nsystemctl start x11vnc.service\nsystemctl status x11vnc.service\n\n\nTo connect\nuse ipaddress: 192.168.1.108\nuse",
    "crumbs": [
      "Blog",
      "SSH, VNC and FTP"
    ]
  },
  {
    "objectID": "ssh&vnc&ftp.html#transfer-files",
    "href": "ssh&vnc&ftp.html#transfer-files",
    "title": "SSH, VNC and FTP",
    "section": "Transfer Files",
    "text": "Transfer Files\nrsync filename username@ip_address:/home/username",
    "crumbs": [
      "Blog",
      "SSH, VNC and FTP"
    ]
  },
  {
    "objectID": "ssh&vnc&ftp.html#ftp",
    "href": "ssh&vnc&ftp.html#ftp",
    "title": "SSH, VNC and FTP",
    "section": "FTP",
    "text": "FTP\n\nhttps://linuxconfig.org/setup-ftp-server-on-linux\n\nInstall FTP server\nsudo apt install vsftpd\ncreate a backup copy\nsudo mv /etc/vsftpd.conf /etc/vsftpd.conf_orig\nedit the config file\nsudo nano /etc/vsftpd.conf\nlisten=NO\nlisten_ipv6=YES\nanonymous_enable=NO\nlocal_enable=YES\nwrite_enable=YES\nlocal_umask=022\ndirmessage_enable=YES\nuse_localtime=YES\nxferlog_enable=YES\nconnect_from_port_20=YES\nchroot_local_user=YES\nsecure_chroot_dir=/var/run/vsftpd/empty\npam_service_name=vsftpd\nrsa_cert_file=/etc/ssl/certs/ssl-cert-snakeoil.pem\nrsa_private_key_file=/etc/ssl/private/ssl-cert-snakeoil.key\nssl_enable=NO\npasv_enable=Yes\npasv_min_port=10000\npasv_max_port=10100\nallow_writeable_chroot=YES\ncreate a user (optional)\n$ sudo useradd -m ftpuser\n$ sudo passwd ftpuser\nNew password: \nRetype new password: \npasswd: password updated successfully",
    "crumbs": [
      "Blog",
      "SSH, VNC and FTP"
    ]
  },
  {
    "objectID": "pip&git_release.html",
    "href": "pip&git_release.html",
    "title": "PIP and GIT release",
    "section": "",
    "text": "create ssh on computer\nssh-keygen -t ed25519 -C \"your_email@example.com\"\nAdd it to ssh agent\nssh-add /c/Users/YOU/.ssh/id_ed25519\nConnect it to github\nssh -T git@github.com",
    "crumbs": [
      "Blog",
      "PIP and GIT release"
    ]
  },
  {
    "objectID": "pip&git_release.html#github-connection",
    "href": "pip&git_release.html#github-connection",
    "title": "PIP and GIT release",
    "section": "",
    "text": "create ssh on computer\nssh-keygen -t ed25519 -C \"your_email@example.com\"\nAdd it to ssh agent\nssh-add /c/Users/YOU/.ssh/id_ed25519\nConnect it to github\nssh -T git@github.com",
    "crumbs": [
      "Blog",
      "PIP and GIT release"
    ]
  },
  {
    "objectID": "pip&git_release.html#github-release",
    "href": "pip&git_release.html#github-release",
    "title": "PIP and GIT release",
    "section": "Github release",
    "text": "Github release\nAdd github token to .bashrc\nGenerate personal access classic token from github\nexport GITHUB_TOKEN=&lt;github_token&gt;\nbump version\nnbdev_bump_version\nnbdev_release_git",
    "crumbs": [
      "Blog",
      "PIP and GIT release"
    ]
  },
  {
    "objectID": "pip&git_release.html#install-twine",
    "href": "pip&git_release.html#install-twine",
    "title": "PIP and GIT release",
    "section": "Install twine",
    "text": "Install twine\npip install twine",
    "crumbs": [
      "Blog",
      "PIP and GIT release"
    ]
  },
  {
    "objectID": "pip&git_release.html#add-pypi-token-to-.pypirc",
    "href": "pip&git_release.html#add-pypi-token-to-.pypirc",
    "title": "PIP and GIT release",
    "section": "Add pypi token to ./pypirc",
    "text": "Add pypi token to ./pypirc\nGenerate token from Pypi\n[pypi]\n  username = __token__\n  password = &lt;pypi-token&gt;",
    "crumbs": [
      "Blog",
      "PIP and GIT release"
    ]
  },
  {
    "objectID": "pip&git_release.html#nbdev-command",
    "href": "pip&git_release.html#nbdev-command",
    "title": "PIP and GIT release",
    "section": "Nbdev Command",
    "text": "Nbdev Command\n\nFirst bump version\nnbdev_bump_version\n\n\npip upload\nnbdev_pypi",
    "crumbs": [
      "Blog",
      "PIP and GIT release"
    ]
  }
]